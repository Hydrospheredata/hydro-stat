Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
111
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.09      1.00      0.17         2\n'
         '         2.0       1.00      0.44      0.62        36\n'
         '\n'
         '    accuracy                           0.47        38\n'
         '   macro avg       0.55      0.72      0.39        38\n'
         'weighted avg       0.95      0.47      0.59        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.80      1.00      0.89        48\n'
          '         2.0       1.00      0.14      0.25        14\n'
          '\n'
          '    accuracy                           0.89       111\n'
          '   macro avg       0.93      0.71      0.71       111\n'
          'weighted avg       0.91      0.89      0.86       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
108
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.94      0.62      0.75        24\n'
         '         2.0       0.64      0.94      0.76        17\n'
         '\n'
         '    accuracy                           0.76        41\n'
         '   macro avg       0.79      0.78      0.76        41\n'
         'weighted avg       0.81      0.76      0.75        41\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      1.00      0.98        26\n'
          '         2.0       1.00      0.97      0.98        33\n'
          '\n'
          '    accuracy                           0.99       108\n'
          '   macro avg       0.99      0.99      0.99       108\n'
          'weighted avg       0.99      0.99      0.99       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        26\n'
         '\n'
         '    accuracy                           1.00        26\n'
         '   macro avg       1.00      1.00      1.00        26\n'
         'weighted avg       1.00      1.00      1.00        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        23\n'
          '         1.0       0.94      0.94      0.94        50\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.95       123\n'
          '   macro avg       0.96      0.96      0.96       123\n'
          'weighted avg       0.95      0.95      0.95       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
87
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.60      0.75        48\n'
         '         2.0       0.48      1.00      0.65        14\n'
         '\n'
         '    accuracy                           0.69        62\n'
         '   macro avg       0.49      0.53      0.47        62\n'
         'weighted avg       0.88      0.69      0.73        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         2\n'
          '         2.0       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           1.00        87\n'
          '   macro avg       1.00      1.00      1.00        87\n'
          'weighted avg       1.00      1.00      1.00        87\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           1.00        12\n'
         '   macro avg       1.00      1.00      1.00        12\n'
         'weighted avg       1.00      1.00      1.00        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00        38\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00       137\n'
          '   macro avg       1.00      1.00      1.00       137\n'
          'weighted avg       1.00      1.00      1.00       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         1.0       0.00      0.00      0.00       3.0\n'
         '         2.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      52.0\n'
         '   macro avg       0.00      0.00      0.00      52.0\n'
         'weighted avg       0.00      0.00      0.00      52.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.00      0.00      0.00        47\n'
          '         2.0       0.52      1.00      0.68        50\n'
          '\n'
          '    accuracy                           0.52        97\n'
          '   macro avg       0.26      0.50      0.34        97\n'
          'weighted avg       0.27      0.52      0.35        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.98      0.94      0.96        47\n'
          '         2.0       0.94      0.98      0.96        50\n'
          '\n'
          '    accuracy                           0.96        97\n'
          '   macro avg       0.96      0.96      0.96        97\n'
          'weighted avg       0.96      0.96      0.96        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
111
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.12      1.00      0.22         2\n'
         '         2.0       1.00      0.61      0.76        36\n'
         '\n'
         '    accuracy                           0.63        38\n'
         '   macro avg       0.56      0.81      0.49        38\n'
         'weighted avg       0.95      0.63      0.73        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.96      0.98        48\n'
          '         2.0       0.88      1.00      0.93        14\n'
          '\n'
          '    accuracy                           0.98       111\n'
          '   macro avg       0.96      0.99      0.97       111\n'
          'weighted avg       0.98      0.98      0.98       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       0.79      0.70      0.74        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.34        97\n'
         '   macro avg       0.26      0.23      0.25        97\n'
         'weighted avg       0.38      0.34      0.36        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      0.67      0.12         3\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.04        52\n'
         '   macro avg       0.02      0.22      0.04        52\n'
         'weighted avg       0.00      0.04      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
126
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        23\n'
         '\n'
         '    accuracy                           1.00        23\n'
         '   macro avg       1.00      1.00      1.00        23\n'
         'weighted avg       1.00      1.00      1.00        23\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.87      1.00      0.93        26\n'
          '         1.0       0.98      0.86      0.91        50\n'
          '         2.0       0.94      0.98      0.96        50\n'
          '\n'
          '    accuracy                           0.94       126\n'
          '   macro avg       0.93      0.95      0.93       126\n'
          'weighted avg       0.94      0.94      0.94       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           1.00        12\n'
         '   macro avg       1.00      1.00      1.00        12\n'
         'weighted avg       1.00      1.00      1.00        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.94      0.98      0.96        50\n'
          '         2.0       0.97      0.92      0.95        38\n'
          '\n'
          '    accuracy                           0.97       137\n'
          '   macro avg       0.97      0.97      0.97       137\n'
          'weighted avg       0.97      0.97      0.97       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       0.50      1.00      0.67        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.17      0.33      0.22        97\n'
         'weighted avg       0.24      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
126
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        23\n'
         '\n'
         '    accuracy                           1.00        23\n'
         '   macro avg       1.00      1.00      1.00        23\n'
         'weighted avg       1.00      1.00      1.00        23\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        26\n'
          '         1.0       0.94      0.94      0.94        50\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.95       126\n'
          '   macro avg       0.96      0.96      0.96       126\n'
          'weighted avg       0.95      0.95      0.95       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.48      1.00      0.65        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.24      0.50      0.33        97\n'
         'weighted avg       0.23      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '         2.0       1.00      0.92      0.96        12\n'
         '\n'
         '    accuracy                           0.92        12\n'
         '   macro avg       0.50      0.46      0.48        12\n'
         'weighted avg       1.00      0.92      0.96        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00        50\n'
          '         2.0       1.00      1.00      1.00        38\n'
          '\n'
          '    accuracy                           1.00       137\n'
          '   macro avg       1.00      1.00      1.00       137\n'
          'weighted avg       1.00      1.00      1.00       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
100
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         2.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      49.0\n'
         '   macro avg       0.00      0.00      0.00      49.0\n'
         'weighted avg       0.00      0.00      0.00      49.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.00      0.00      0.00        50\n'
          '         2.0       0.50      1.00      0.67        50\n'
          '\n'
          '    accuracy                           0.50       100\n'
          '   macro avg       0.25      0.50      0.33       100\n'
          'weighted avg       0.25      0.50      0.33       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.98      0.94      0.96        47\n'
          '         2.0       0.94      0.98      0.96        50\n'
          '\n'
          '    accuracy                           0.96        97\n'
          '   macro avg       0.96      0.96      0.96        97\n'
          'weighted avg       0.96      0.96      0.96        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
125
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        24\n'
         '\n'
         '    accuracy                           1.00        24\n'
         '   macro avg       1.00      1.00      1.00        24\n'
         'weighted avg       1.00      1.00      1.00        24\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.96      0.98        50\n'
          '         2.0       0.93      1.00      0.96        26\n'
          '\n'
          '    accuracy                           0.98       125\n'
          '   macro avg       0.98      0.99      0.98       125\n'
          'weighted avg       0.99      0.98      0.98       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
125
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        24\n'
         '\n'
         '    accuracy                           1.00        24\n'
         '   macro avg       1.00      1.00      1.00        24\n'
         'weighted avg       1.00      1.00      1.00        24\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.92      0.96      0.94        50\n'
          '         2.0       0.92      0.85      0.88        26\n'
          '\n'
          '    accuracy                           0.95       125\n'
          '   macro avg       0.95      0.94      0.94       125\n'
          'weighted avg       0.95      0.95      0.95       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      0.67      0.12         3\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.04        52\n'
         '   macro avg       0.02      0.22      0.04        52\n'
         'weighted avg       0.00      0.04      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
125
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        24\n'
         '\n'
         '    accuracy                           1.00        24\n'
         '   macro avg       1.00      1.00      1.00        24\n'
         'weighted avg       1.00      1.00      1.00        24\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.96      1.00      0.98        25\n'
          '         1.0       0.96      0.90      0.93        50\n'
          '         2.0       0.92      0.96      0.94        50\n'
          '\n'
          '    accuracy                           0.94       125\n'
          '   macro avg       0.95      0.95      0.95       125\n'
          'weighted avg       0.94      0.94      0.94       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
100
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         1.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      49.0\n'
         '   macro avg       0.00      0.00      0.00      49.0\n'
         'weighted avg       0.00      0.00      0.00      49.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.98      0.94      0.96        50\n'
          '         2.0       0.94      0.98      0.96        50\n'
          '\n'
          '    accuracy                           0.96       100\n'
          '   macro avg       0.96      0.96      0.96       100\n'
          'weighted avg       0.96      0.96      0.96       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       0.50      1.00      0.67        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.17      0.33      0.22        97\n'
         'weighted avg       0.24      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
110
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.92      0.46      0.62        26\n'
         '         2.0       0.46      0.92      0.62        13\n'
         '\n'
         '    accuracy                           0.62        39\n'
         '   macro avg       0.69      0.69      0.62        39\n'
         'weighted avg       0.77      0.62      0.62        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      1.00      0.98        24\n'
          '         2.0       1.00      0.97      0.99        37\n'
          '\n'
          '    accuracy                           0.99       110\n'
          '   macro avg       0.99      0.99      0.99       110\n'
          'weighted avg       0.99      0.99      0.99       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
121
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.96      0.98        27\n'
         '         2.0       1.00      1.00      1.00         1\n'
         '\n'
         '    accuracy                           0.96        28\n'
         '   macro avg       0.67      0.65      0.66        28\n'
         'weighted avg       1.00      0.96      0.98        28\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.95      0.87      0.91        23\n'
          '         2.0       0.94      0.98      0.96        49\n'
          '\n'
          '    accuracy                           0.97       121\n'
          '   macro avg       0.96      0.95      0.96       121\n'
          'weighted avg       0.97      0.97      0.97       121\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '         2.0       1.00      0.92      0.96        12\n'
         '\n'
         '    accuracy                           0.92        12\n'
         '   macro avg       0.50      0.46      0.48        12\n'
         'weighted avg       1.00      0.92      0.96        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00        50\n'
          '         2.0       1.00      1.00      1.00        38\n'
          '\n'
          '    accuracy                           1.00       137\n'
          '   macro avg       1.00      1.00      1.00       137\n'
          'weighted avg       1.00      1.00      1.00       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
110
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.82      0.35      0.49        26\n'
         '         2.0       0.39      0.85      0.54        13\n'
         '\n'
         '    accuracy                           0.51        39\n'
         '   macro avg       0.61      0.60      0.51        39\n'
         'weighted avg       0.68      0.51      0.50        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.96      0.98        24\n'
          '         2.0       0.97      1.00      0.99        37\n'
          '\n'
          '    accuracy                           0.99       110\n'
          '   macro avg       0.99      0.99      0.99       110\n'
          'weighted avg       0.99      0.99      0.99       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
117
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '         2.0       1.00      0.78      0.88        32\n'
         '\n'
         '    accuracy                           0.78        32\n'
         '   macro avg       0.50      0.39      0.44        32\n'
         'weighted avg       1.00      0.78      0.88        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.82      1.00      0.90        50\n'
          '         2.0       1.00      0.39      0.56        18\n'
          '\n'
          '    accuracy                           0.91       117\n'
          '   macro avg       0.94      0.80      0.82       117\n'
          'weighted avg       0.92      0.91      0.89       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
121
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00        27\n'
         '         2.0       1.00      1.00      1.00         1\n'
         '\n'
         '    accuracy                           1.00        28\n'
         '   macro avg       1.00      1.00      1.00        28\n'
         'weighted avg       1.00      1.00      1.00        28\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.91      0.95        23\n'
          '         2.0       0.96      1.00      0.98        49\n'
          '\n'
          '    accuracy                           0.98       121\n'
          '   macro avg       0.99      0.97      0.98       121\n'
          'weighted avg       0.98      0.98      0.98       121\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
124
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        25\n'
         '\n'
         '    accuracy                           1.00        25\n'
         '   macro avg       1.00      1.00      1.00        25\n'
         'weighted avg       1.00      1.00      1.00        25\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        24\n'
          '         1.0       0.94      0.94      0.94        50\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.95       124\n'
          '   macro avg       0.96      0.96      0.96       124\n'
          'weighted avg       0.95      0.95      0.95       124\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
117
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '         2.0       1.00      0.97      0.98        32\n'
         '\n'
         '    accuracy                           0.97        32\n'
         '   macro avg       0.50      0.48      0.49        32\n'
         'weighted avg       1.00      0.97      0.98        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      0.98      0.97        50\n'
          '         2.0       0.94      0.89      0.91        18\n'
          '\n'
          '    accuracy                           0.97       117\n'
          '   macro avg       0.97      0.96      0.96       117\n'
          'weighted avg       0.97      0.97      0.97       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
109
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.86      0.78      0.82        23\n'
         '         2.0       0.74      0.82      0.78        17\n'
         '\n'
         '    accuracy                           0.80        40\n'
         '   macro avg       0.80      0.80      0.80        40\n'
         'weighted avg       0.81      0.80      0.80        40\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00        27\n'
          '         2.0       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           1.00       109\n'
          '   macro avg       1.00      1.00      1.00       109\n'
          'weighted avg       1.00      1.00      1.00       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         1.0       0.00      0.00      0.00       3.0\n'
         '         2.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      52.0\n'
         '   macro avg       0.00      0.00      0.00      52.0\n'
         'weighted avg       0.00      0.00      0.00      52.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.00      0.00      0.00        47\n'
          '         2.0       0.52      1.00      0.68        50\n'
          '\n'
          '    accuracy                           0.52        97\n'
          '   macro avg       0.26      0.50      0.34        97\n'
          'weighted avg       0.27      0.52      0.35        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.48      1.00      0.65        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.24      0.50      0.33        97\n'
         'weighted avg       0.23      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
128
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        21\n'
         '\n'
         '    accuracy                           1.00        21\n'
         '   macro avg       1.00      1.00      1.00        21\n'
         'weighted avg       1.00      1.00      1.00        21\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        28\n'
          '         1.0       0.98      0.96      0.97        50\n'
          '         2.0       0.96      0.98      0.97        50\n'
          '\n'
          '    accuracy                           0.98       128\n'
          '   macro avg       0.98      0.98      0.98       128\n'
          'weighted avg       0.98      0.98      0.98       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
111
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.05      0.50      0.10         2\n'
         '         2.0       0.95      0.50      0.65        36\n'
         '\n'
         '    accuracy                           0.50        38\n'
         '   macro avg       0.50      0.50      0.37        38\n'
         'weighted avg       0.90      0.50      0.63        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      0.94      0.95        48\n'
          '         2.0       0.80      0.86      0.83        14\n'
          '\n'
          '    accuracy                           0.95       111\n'
          '   macro avg       0.92      0.93      0.92       111\n'
          'weighted avg       0.96      0.95      0.96       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.48      1.00      0.65        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.24      0.50      0.33        97\n'
         'weighted avg       0.23      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
147
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00         2\n'
         '\n'
         '    accuracy                           1.00         2\n'
         '   macro avg       1.00      1.00      1.00         2\n'
         'weighted avg       1.00      1.00      1.00         2\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.98      1.00      0.99        50\n'
          '         2.0       1.00      0.98      0.99        48\n'
          '\n'
          '    accuracy                           0.99       147\n'
          '   macro avg       0.99      0.99      0.99       147\n'
          'weighted avg       0.99      0.99      0.99       147\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
121
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.67      0.80        27\n'
         '         2.0       0.00      0.00      0.00         1\n'
         '\n'
         '    accuracy                           0.64        28\n'
         '   macro avg       0.33      0.22      0.27        28\n'
         'weighted avg       0.96      0.64      0.77        28\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.87      0.93        23\n'
          '         2.0       0.94      1.00      0.97        49\n'
          '\n'
          '    accuracy                           0.98       121\n'
          '   macro avg       0.98      0.96      0.97       121\n'
          'weighted avg       0.98      0.98      0.97       121\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        26\n'
         '\n'
         '    accuracy                           1.00        26\n'
         '   macro avg       1.00      1.00      1.00        26\n'
         'weighted avg       1.00      1.00      1.00        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        23\n'
          '         1.0       0.96      0.92      0.94        50\n'
          '         2.0       0.92      0.96      0.94        50\n'
          '\n'
          '    accuracy                           0.95       123\n'
          '   macro avg       0.96      0.96      0.96       123\n'
          'weighted avg       0.95      0.95      0.95       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.98      0.96      0.97        47\n'
          '         2.0       0.96      0.98      0.97        50\n'
          '\n'
          '    accuracy                           0.97        97\n'
          '   macro avg       0.97      0.97      0.97        97\n'
          'weighted avg       0.97      0.97      0.97        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        26\n'
         '\n'
         '    accuracy                           1.00        26\n'
         '   macro avg       1.00      1.00      1.00        26\n'
         'weighted avg       1.00      1.00      1.00        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        23\n'
          '         1.0       0.94      0.94      0.94        50\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.95       123\n'
          '   macro avg       0.96      0.96      0.96       123\n'
          'weighted avg       0.95      0.95      0.95       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
100
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         1.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      49.0\n'
         '   macro avg       0.00      0.00      0.00      49.0\n'
         'weighted avg       0.00      0.00      0.00      49.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        50\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00       100\n'
          '   macro avg       1.00      1.00      1.00       100\n'
          'weighted avg       1.00      1.00      1.00       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
117
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '         2.0       1.00      0.19      0.32        32\n'
         '\n'
         '    accuracy                           0.19        32\n'
         '   macro avg       0.50      0.09      0.16        32\n'
         'weighted avg       1.00      0.19      0.32        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.98      1.00      0.99        50\n'
          '         2.0       1.00      0.94      0.97        18\n'
          '\n'
          '    accuracy                           0.99       117\n'
          '   macro avg       0.99      0.98      0.99       117\n'
          'weighted avg       0.99      0.99      0.99       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
125
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        24\n'
         '\n'
         '    accuracy                           1.00        24\n'
         '   macro avg       1.00      1.00      1.00        24\n'
         'weighted avg       1.00      1.00      1.00        24\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.98      0.90      0.94        50\n'
          '         2.0       0.83      0.96      0.89        26\n'
          '\n'
          '    accuracy                           0.95       125\n'
          '   macro avg       0.94      0.95      0.94       125\n'
          'weighted avg       0.96      0.95      0.95       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
112
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.80      0.17      0.28        24\n'
         '         2.0       0.38      0.92      0.53        13\n'
         '\n'
         '    accuracy                           0.43        37\n'
         '   macro avg       0.59      0.54      0.40        37\n'
         'weighted avg       0.65      0.43      0.37        37\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      1.00      0.98        26\n'
          '         2.0       1.00      0.97      0.99        37\n'
          '\n'
          '    accuracy                           0.99       112\n'
          '   macro avg       0.99      0.99      0.99       112\n'
          'weighted avg       0.99      0.99      0.99       112\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
136
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        13\n'
         '\n'
         '    accuracy                           1.00        13\n'
         '   macro avg       1.00      1.00      1.00        13\n'
         'weighted avg       1.00      1.00      1.00        13\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.96      0.98        50\n'
          '         2.0       0.95      1.00      0.97        37\n'
          '\n'
          '    accuracy                           0.99       136\n'
          '   macro avg       0.98      0.99      0.98       136\n'
          'weighted avg       0.99      0.99      0.99       136\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
130
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.50      0.75      0.60         4\n'
         '         2.0       0.92      0.80      0.86        15\n'
         '\n'
         '    accuracy                           0.79        19\n'
         '   macro avg       0.71      0.78      0.73        19\n'
         'weighted avg       0.83      0.79      0.80        19\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.98      0.98      0.98        46\n'
          '         2.0       0.97      0.97      0.97        35\n'
          '\n'
          '    accuracy                           0.98       130\n'
          '   macro avg       0.98      0.98      0.98       130\n'
          'weighted avg       0.98      0.98      0.98       130\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
111
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.88      0.60      0.71        25\n'
         '         2.0       0.52      0.85      0.65        13\n'
         '\n'
         '    accuracy                           0.68        38\n'
         '   macro avg       0.70      0.72      0.68        38\n'
         'weighted avg       0.76      0.68      0.69        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      1.00      0.98        25\n'
          '         2.0       1.00      0.97      0.99        37\n'
          '\n'
          '    accuracy                           0.99       111\n'
          '   macro avg       0.99      0.99      0.99       111\n'
          'weighted avg       0.99      0.99      0.99       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.48      1.00      0.65        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.24      0.50      0.33        97\n'
         'weighted avg       0.23      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00       0.0\n'
         '         1.0       0.00      0.00      0.00      47.0\n'
         '         2.0       0.00      0.00      0.00      50.0\n'
         '\n'
         '    accuracy                           0.00      97.0\n'
         '   macro avg       0.00      0.00      0.00      97.0\n'
         'weighted avg       0.00      0.00      0.00      97.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.00      0.00      0.00         3\n'
          '\n'
          '    accuracy                           0.94        52\n'
          '   macro avg       0.47      0.50      0.49        52\n'
          'weighted avg       0.89      0.94      0.91        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
110
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.80      0.15      0.26        26\n'
         '         2.0       0.35      0.92      0.51        13\n'
         '\n'
         '    accuracy                           0.41        39\n'
         '   macro avg       0.58      0.54      0.38        39\n'
         'weighted avg       0.65      0.41      0.34        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      1.00      0.98        24\n'
          '         2.0       1.00      0.97      0.99        37\n'
          '\n'
          '    accuracy                           0.99       110\n'
          '   macro avg       0.99      0.99      0.99       110\n'
          'weighted avg       0.99      0.99      0.99       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
110
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.42      0.59        26\n'
         '         2.0       0.46      1.00      0.63        13\n'
         '\n'
         '    accuracy                           0.62        39\n'
         '   macro avg       0.73      0.71      0.61        39\n'
         'weighted avg       0.82      0.62      0.61        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      1.00      0.98        24\n'
          '         2.0       1.00      0.97      0.99        37\n'
          '\n'
          '    accuracy                           0.99       110\n'
          '   macro avg       0.99      0.99      0.99       110\n'
          'weighted avg       0.99      0.99      0.99       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
127
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        22\n'
         '\n'
         '    accuracy                           1.00        22\n'
         '   macro avg       1.00      1.00      1.00        22\n'
         'weighted avg       1.00      1.00      1.00        22\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.94      0.96      0.95        50\n'
          '         2.0       0.93      0.89      0.91        28\n'
          '\n'
          '    accuracy                           0.96       127\n'
          '   macro avg       0.96      0.95      0.95       127\n'
          'weighted avg       0.96      0.96      0.96       127\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.48      1.00      0.65        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.24      0.50      0.33        97\n'
         'weighted avg       0.23      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
87
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       0.82      0.83      0.82        48\n'
         '         2.0       0.83      0.36      0.50        14\n'
         '\n'
         '    accuracy                           0.73        62\n'
         '   macro avg       0.55      0.40      0.44        62\n'
         'weighted avg       0.82      0.73      0.75        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         2\n'
          '         2.0       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           1.00        87\n'
          '   macro avg       1.00      1.00      1.00        87\n'
          'weighted avg       1.00      1.00      1.00        87\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
109
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.85      0.48      0.61        23\n'
         '         2.0       0.56      0.88      0.68        17\n'
         '\n'
         '    accuracy                           0.65        40\n'
         '   macro avg       0.70      0.68      0.65        40\n'
         'weighted avg       0.72      0.65      0.64        40\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      1.00      0.98        27\n'
          '         2.0       1.00      0.97      0.98        33\n'
          '\n'
          '    accuracy                           0.99       109\n'
          '   macro avg       0.99      0.99      0.99       109\n'
          'weighted avg       0.99      0.99      0.99       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
129
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        20\n'
         '\n'
         '    accuracy                           1.00        20\n'
         '   macro avg       1.00      1.00      1.00        20\n'
         'weighted avg       1.00      1.00      1.00        20\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        29\n'
          '         1.0       0.96      0.88      0.92        50\n'
          '         2.0       0.89      0.96      0.92        50\n'
          '\n'
          '    accuracy                           0.94       129\n'
          '   macro avg       0.95      0.95      0.95       129\n'
          'weighted avg       0.94      0.94      0.94       129\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       0.50      1.00      0.67        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.17      0.33      0.22        97\n'
         'weighted avg       0.24      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
126
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        23\n'
         '\n'
         '    accuracy                           1.00        23\n'
         '   macro avg       1.00      1.00      1.00        23\n'
         'weighted avg       1.00      1.00      1.00        23\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        26\n'
          '         1.0       0.94      0.94      0.94        50\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.95       126\n'
          '   macro avg       0.96      0.96      0.96       126\n'
          'weighted avg       0.95      0.95      0.95       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      0.67      0.12         3\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.04        52\n'
         '   macro avg       0.02      0.22      0.04        52\n'
         'weighted avg       0.00      0.04      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.18      0.67      0.29         3\n'
         '         2.0       0.86      0.40      0.55        15\n'
         '\n'
         '    accuracy                           0.44        18\n'
         '   macro avg       0.52      0.53      0.42        18\n'
         'weighted avg       0.74      0.44      0.50        18\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.98      1.00      0.99        47\n'
          '         2.0       1.00      0.97      0.99        35\n'
          '\n'
          '    accuracy                           0.99       131\n'
          '   macro avg       0.99      0.99      0.99       131\n'
          'weighted avg       0.99      0.99      0.99       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
130
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.11      0.19        19\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.11        19\n'
         '   macro avg       0.50      0.05      0.10        19\n'
         'weighted avg       1.00      0.11      0.19        19\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.93      0.87      0.90        31\n'
          '         2.0       0.92      0.96      0.94        50\n'
          '\n'
          '    accuracy                           0.95       130\n'
          '   macro avg       0.95      0.94      0.95       130\n'
          'weighted avg       0.95      0.95      0.95       130\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
111
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.12      1.00      0.22         2\n'
         '         2.0       1.00      0.61      0.76        36\n'
         '\n'
         '    accuracy                           0.63        38\n'
         '   macro avg       0.56      0.81      0.49        38\n'
         'weighted avg       0.95      0.63      0.73        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.96      0.98        48\n'
          '         2.0       0.88      1.00      0.93        14\n'
          '\n'
          '    accuracy                           0.98       111\n'
          '   macro avg       0.96      0.99      0.97       111\n'
          'weighted avg       0.98      0.98      0.98       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.94      0.94      0.94        47\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.94        97\n'
          '   macro avg       0.94      0.94      0.94        97\n'
          'weighted avg       0.94      0.94      0.94        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
125
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '         2.0       1.00      0.96      0.98        24\n'
         '\n'
         '    accuracy                           0.96        24\n'
         '   macro avg       0.50      0.48      0.49        24\n'
         'weighted avg       1.00      0.96      0.98        24\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      0.94      0.95        50\n'
          '         2.0       0.89      0.92      0.91        26\n'
          '\n'
          '    accuracy                           0.96       125\n'
          '   macro avg       0.95      0.95      0.95       125\n'
          'weighted avg       0.96      0.96      0.96       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
127
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        22\n'
         '\n'
         '    accuracy                           1.00        22\n'
         '   macro avg       1.00      1.00      1.00        22\n'
         'weighted avg       1.00      1.00      1.00        22\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.98      1.00      0.99        50\n'
          '         2.0       1.00      0.96      0.98        28\n'
          '\n'
          '    accuracy                           0.99       127\n'
          '   macro avg       0.99      0.99      0.99       127\n'
          'weighted avg       0.99      0.99      0.99       127\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
139
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        10\n'
         '\n'
         '    accuracy                           1.00        10\n'
         '   macro avg       1.00      1.00      1.00        10\n'
         'weighted avg       1.00      1.00      1.00        10\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.91      0.96      0.93        50\n'
          '         2.0       0.95      0.88      0.91        40\n'
          '\n'
          '    accuracy                           0.95       139\n'
          '   macro avg       0.95      0.94      0.95       139\n'
          'weighted avg       0.95      0.95      0.95       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
125
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        24\n'
         '\n'
         '    accuracy                           1.00        24\n'
         '   macro avg       1.00      1.00      1.00        24\n'
         'weighted avg       1.00      1.00      1.00        24\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.86      0.98      0.92        50\n'
          '         2.0       0.95      0.69      0.80        26\n'
          '\n'
          '    accuracy                           0.93       125\n'
          '   macro avg       0.94      0.89      0.91       125\n'
          'weighted avg       0.93      0.93      0.92       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
128
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        21\n'
         '\n'
         '    accuracy                           1.00        21\n'
         '   macro avg       1.00      1.00      1.00        21\n'
         'weighted avg       1.00      1.00      1.00        21\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        28\n'
          '         1.0       0.98      0.96      0.97        50\n'
          '         2.0       0.96      0.98      0.97        50\n'
          '\n'
          '    accuracy                           0.98       128\n'
          '   macro avg       0.98      0.98      0.98       128\n'
          'weighted avg       0.98      0.98      0.98       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.94      0.94      0.94        47\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.94        97\n'
          '   macro avg       0.94      0.94      0.94        97\n'
          'weighted avg       0.94      0.94      0.94        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           1.00        12\n'
         '   macro avg       1.00      1.00      1.00        12\n'
         'weighted avg       1.00      1.00      1.00        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      0.94      0.95        50\n'
          '         2.0       0.92      0.95      0.94        38\n'
          '\n'
          '    accuracy                           0.96       137\n'
          '   macro avg       0.96      0.96      0.96       137\n'
          'weighted avg       0.96      0.96      0.96       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      0.67      0.12         3\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.04        52\n'
         '   macro avg       0.02      0.22      0.04        52\n'
         'weighted avg       0.00      0.04      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00       0.0\n'
         '         1.0       0.00      0.00      0.00      47.0\n'
         '         2.0       0.00      0.00      0.00      50.0\n'
         '\n'
         '    accuracy                           0.00      97.0\n'
         '   macro avg       0.00      0.00      0.00      97.0\n'
         'weighted avg       0.00      0.00      0.00      97.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.00      0.00      0.00         3\n'
          '\n'
          '    accuracy                           0.94        52\n'
          '   macro avg       0.47      0.50      0.49        52\n'
          'weighted avg       0.89      0.94      0.91        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
109
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.67      0.26      0.38        23\n'
         '         2.0       0.45      0.82      0.58        17\n'
         '\n'
         '    accuracy                           0.50        40\n'
         '   macro avg       0.56      0.54      0.48        40\n'
         'weighted avg       0.58      0.50      0.46        40\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      1.00      0.98        27\n'
          '         2.0       1.00      0.97      0.98        33\n'
          '\n'
          '    accuracy                           0.99       109\n'
          '   macro avg       0.99      0.99      0.99       109\n'
          'weighted avg       0.99      0.99      0.99       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
100
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         1.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      49.0\n'
         '   macro avg       0.00      0.00      0.00      49.0\n'
         'weighted avg       0.00      0.00      0.00      49.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.98      0.96      0.97        50\n'
          '         2.0       0.96      0.98      0.97        50\n'
          '\n'
          '    accuracy                           0.97       100\n'
          '   macro avg       0.97      0.97      0.97       100\n'
          'weighted avg       0.97      0.97      0.97       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           1.00        12\n'
         '   macro avg       1.00      1.00      1.00        12\n'
         'weighted avg       1.00      1.00      1.00        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      0.92      0.94        50\n'
          '         2.0       0.90      0.95      0.92        38\n'
          '\n'
          '    accuracy                           0.96       137\n'
          '   macro avg       0.95      0.96      0.95       137\n'
          'weighted avg       0.96      0.96      0.96       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      0.67      0.12         3\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.04        52\n'
         '   macro avg       0.02      0.22      0.04        52\n'
         'weighted avg       0.00      0.04      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00       0.0\n'
         '         1.0       0.00      0.00      0.00      47.0\n'
         '         2.0       0.00      0.00      0.00      50.0\n'
         '\n'
         '    accuracy                           0.00      97.0\n'
         '   macro avg       0.00      0.00      0.00      97.0\n'
         'weighted avg       0.00      0.00      0.00      97.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.00      0.00      0.00         3\n'
          '\n'
          '    accuracy                           0.94        52\n'
          '   macro avg       0.47      0.50      0.49        52\n'
          'weighted avg       0.89      0.94      0.91        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        26\n'
         '\n'
         '    accuracy                           1.00        26\n'
         '   macro avg       1.00      1.00      1.00        26\n'
         'weighted avg       1.00      1.00      1.00        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        23\n'
          '         1.0       0.96      0.92      0.94        50\n'
          '         2.0       0.92      0.96      0.94        50\n'
          '\n'
          '    accuracy                           0.95       123\n'
          '   macro avg       0.96      0.96      0.96       123\n'
          'weighted avg       0.95      0.95      0.95       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
100
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         1.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      49.0\n'
         '   macro avg       0.00      0.00      0.00      49.0\n'
         'weighted avg       0.00      0.00      0.00      49.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.98      0.96      0.97        50\n'
          '         2.0       0.96      0.98      0.97        50\n'
          '\n'
          '    accuracy                           0.97       100\n'
          '   macro avg       0.97      0.97      0.97       100\n'
          'weighted avg       0.97      0.97      0.97       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
124
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.75      0.86        24\n'
         '         2.0       0.14      1.00      0.25         1\n'
         '\n'
         '    accuracy                           0.76        25\n'
         '   macro avg       0.57      0.88      0.55        25\n'
         'weighted avg       0.97      0.76      0.83        25\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.92      0.92      0.92        26\n'
          '         2.0       0.96      0.96      0.96        49\n'
          '\n'
          '    accuracy                           0.97       124\n'
          '   macro avg       0.96      0.96      0.96       124\n'
          'weighted avg       0.97      0.97      0.97       124\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
140
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00         9\n'
         '\n'
         '    accuracy                           1.00         9\n'
         '   macro avg       1.00      1.00      1.00         9\n'
         'weighted avg       1.00      1.00      1.00         9\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00        50\n'
          '         2.0       1.00      1.00      1.00        41\n'
          '\n'
          '    accuracy                           1.00       140\n'
          '   macro avg       1.00      1.00      1.00       140\n'
          'weighted avg       1.00      1.00      1.00       140\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
135
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.93      1.00      0.96        13\n'
         '         2.0       0.00      0.00      0.00         1\n'
         '\n'
         '    accuracy                           0.93        14\n'
         '   macro avg       0.46      0.50      0.48        14\n'
         'weighted avg       0.86      0.93      0.89        14\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.97      1.00      0.99        37\n'
          '         2.0       1.00      0.98      0.99        49\n'
          '\n'
          '    accuracy                           0.99       135\n'
          '   macro avg       0.99      0.99      0.99       135\n'
          'weighted avg       0.99      0.99      0.99       135\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00       0.0\n'
         '         1.0       0.00      0.00      0.00      47.0\n'
         '         2.0       0.00      0.00      0.00      50.0\n'
         '\n'
         '    accuracy                           0.00      97.0\n'
         '   macro avg       0.00      0.00      0.00      97.0\n'
         'weighted avg       0.00      0.00      0.00      97.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.00      0.00      0.00         3\n'
          '\n'
          '    accuracy                           0.94        52\n'
          '   macro avg       0.47      0.50      0.49        52\n'
          'weighted avg       0.89      0.94      0.91        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           1.00        12\n'
         '   macro avg       1.00      1.00      1.00        12\n'
         'weighted avg       1.00      1.00      1.00        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.94      0.98      0.96        50\n'
          '         2.0       0.97      0.92      0.95        38\n'
          '\n'
          '    accuracy                           0.97       137\n'
          '   macro avg       0.97      0.97      0.97       137\n'
          'weighted avg       0.97      0.97      0.97       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        26\n'
         '\n'
         '    accuracy                           1.00        26\n'
         '   macro avg       1.00      1.00      1.00        26\n'
         'weighted avg       1.00      1.00      1.00        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        23\n'
          '         1.0       0.98      0.96      0.97        50\n'
          '         2.0       0.96      0.98      0.97        50\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.98      0.98      0.98       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.94      0.94      0.94        47\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.94        97\n'
          '   macro avg       0.94      0.94      0.94        97\n'
          'weighted avg       0.94      0.94      0.94        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           1.00        12\n'
         '   macro avg       1.00      1.00      1.00        12\n'
         'weighted avg       1.00      1.00      1.00        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00        38\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00       137\n'
          '   macro avg       1.00      1.00      1.00       137\n'
          'weighted avg       1.00      1.00      1.00       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.48      1.00      0.65        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.24      0.50      0.33        97\n'
         'weighted avg       0.23      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
110
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.82      0.35      0.49        26\n'
         '         2.0       0.39      0.85      0.54        13\n'
         '\n'
         '    accuracy                           0.51        39\n'
         '   macro avg       0.61      0.60      0.51        39\n'
         'weighted avg       0.68      0.51      0.50        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.96      0.98        24\n'
          '         2.0       0.97      1.00      0.99        37\n'
          '\n'
          '    accuracy                           0.99       110\n'
          '   macro avg       0.99      0.99      0.99       110\n'
          'weighted avg       0.99      0.99      0.99       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         2.0       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           1.00        12\n'
         '   macro avg       1.00      1.00      1.00        12\n'
         'weighted avg       1.00      1.00      1.00        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.94      0.98      0.96        50\n'
          '         2.0       0.97      0.92      0.95        38\n'
          '\n'
          '    accuracy                           0.97       137\n'
          '   macro avg       0.97      0.97      0.97       137\n'
          'weighted avg       0.97      0.97      0.97       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
129
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        20\n'
         '\n'
         '    accuracy                           1.00        20\n'
         '   macro avg       1.00      1.00      1.00        20\n'
         'weighted avg       1.00      1.00      1.00        20\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        29\n'
          '         1.0       0.98      0.96      0.97        50\n'
          '         2.0       0.96      0.98      0.97        50\n'
          '\n'
          '    accuracy                           0.98       129\n'
          '   macro avg       0.98      0.98      0.98       129\n'
          'weighted avg       0.98      0.98      0.98       129\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.40      0.67      0.50         3\n'
         '         2.0       0.92      0.80      0.86        15\n'
         '\n'
         '    accuracy                           0.78        18\n'
         '   macro avg       0.66      0.73      0.68        18\n'
         'weighted avg       0.84      0.78      0.80        18\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.98      0.98      0.98        47\n'
          '         2.0       0.97      0.97      0.97        35\n'
          '\n'
          '    accuracy                           0.98       131\n'
          '   macro avg       0.98      0.98      0.98       131\n'
          'weighted avg       0.98      0.98      0.98       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
125
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '         2.0       1.00      0.96      0.98        24\n'
         '\n'
         '    accuracy                           0.96        24\n'
         '   macro avg       0.50      0.48      0.49        24\n'
         'weighted avg       1.00      0.96      0.98        24\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.96      0.94      0.95        50\n'
          '         2.0       0.89      0.92      0.91        26\n'
          '\n'
          '    accuracy                           0.96       125\n'
          '   macro avg       0.95      0.95      0.95       125\n'
          'weighted avg       0.96      0.96      0.96       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      0.67      0.12         3\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.04        52\n'
         '   macro avg       0.02      0.22      0.04        52\n'
         'weighted avg       0.00      0.04      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
100
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         2.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      49.0\n'
         '   macro avg       0.00      0.00      0.00      49.0\n'
         'weighted avg       0.00      0.00      0.00      49.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.00      0.00      0.00        50\n'
          '         2.0       0.50      1.00      0.67        50\n'
          '\n'
          '    accuracy                           0.50       100\n'
          '   macro avg       0.25      0.50      0.33       100\n'
          'weighted avg       0.25      0.50      0.33       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
111
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.09      1.00      0.17         2\n'
         '         2.0       1.00      0.44      0.62        36\n'
         '\n'
         '    accuracy                           0.47        38\n'
         '   macro avg       0.55      0.72      0.39        38\n'
         'weighted avg       0.95      0.47      0.59        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.80      1.00      0.89        48\n'
          '         2.0       1.00      0.14      0.25        14\n'
          '\n'
          '    accuracy                           0.89       111\n'
          '   macro avg       0.93      0.71      0.71       111\n'
          'weighted avg       0.91      0.89      0.86       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.20      1.00      0.33         3\n'
         '         2.0       1.00      0.20      0.33        15\n'
         '\n'
         '    accuracy                           0.33        18\n'
         '   macro avg       0.60      0.60      0.33        18\n'
         'weighted avg       0.87      0.33      0.33        18\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.98      1.00      0.99        47\n'
          '         2.0       1.00      0.97      0.99        35\n'
          '\n'
          '    accuracy                           0.99       131\n'
          '   macro avg       0.99      0.99      0.99       131\n'
          'weighted avg       0.99      0.99      0.99       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.94      0.94      0.94        47\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.94        97\n'
          '   macro avg       0.94      0.94      0.94        97\n'
          'weighted avg       0.94      0.94      0.94        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      0.67      0.12         3\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.04        52\n'
         '   macro avg       0.02      0.22      0.04        52\n'
         'weighted avg       0.00      0.04      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       1.00      1.00      1.00        47\n'
          '         2.0       1.00      1.00      1.00        50\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
111
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.05      1.00      0.10         2\n'
         '         2.0       0.00      0.00      0.00        36\n'
         '\n'
         '    accuracy                           0.05        38\n'
         '   macro avg       0.03      0.50      0.05        38\n'
         'weighted avg       0.00      0.05      0.01        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.77      1.00      0.87        48\n'
          '         2.0       0.00      0.00      0.00        14\n'
          '\n'
          '    accuracy                           0.87       111\n'
          '   macro avg       0.59      0.67      0.62       111\n'
          'weighted avg       0.78      0.87      0.82       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
121
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.67      0.80        27\n'
         '         2.0       0.33      1.00      0.50         1\n'
         '\n'
         '    accuracy                           0.68        28\n'
         '   macro avg       0.44      0.56      0.43        28\n'
         'weighted avg       0.98      0.68      0.79        28\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.57      0.72        23\n'
          '         2.0       0.83      1.00      0.91        49\n'
          '\n'
          '    accuracy                           0.92       121\n'
          '   macro avg       0.94      0.86      0.88       121\n'
          'weighted avg       0.93      0.92      0.91       121\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
121
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00        27\n'
         '         2.0       1.00      1.00      1.00         1\n'
         '\n'
         '    accuracy                           1.00        28\n'
         '   macro avg       1.00      1.00      1.00        28\n'
         'weighted avg       1.00      1.00      1.00        28\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.91      0.95        23\n'
          '         2.0       0.96      1.00      0.98        49\n'
          '\n'
          '    accuracy                           0.98       121\n'
          '   macro avg       0.99      0.97      0.98       121\n'
          'weighted avg       0.98      0.98      0.98       121\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
143
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00         6\n'
         '\n'
         '    accuracy                           1.00         6\n'
         '   macro avg       1.00      1.00      1.00         6\n'
         'weighted avg       1.00      1.00      1.00         6\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.93      0.95      0.94        44\n'
          '         2.0       0.96      0.94      0.95        50\n'
          '\n'
          '    accuracy                           0.97       143\n'
          '   macro avg       0.96      0.96      0.96       143\n'
          'weighted avg       0.97      0.97      0.97       143\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
52
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.48      1.00      0.65        47\n'
         '         2.0       0.00      0.00      0.00        50\n'
         '\n'
         '    accuracy                           0.48        97\n'
         '   macro avg       0.24      0.50      0.33        97\n'
         'weighted avg       0.23      0.48      0.32        97\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         3\n'
          '\n'
          '    accuracy                           1.00        52\n'
          '   macro avg       1.00      1.00      1.00        52\n'
          'weighted avg       1.00      1.00      1.00        52\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
128
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        21\n'
         '\n'
         '    accuracy                           1.00        21\n'
         '   macro avg       1.00      1.00      1.00        21\n'
         'weighted avg       1.00      1.00      1.00        21\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        28\n'
          '         1.0       0.98      1.00      0.99        50\n'
          '         2.0       1.00      0.98      0.99        50\n'
          '\n'
          '    accuracy                           0.99       128\n'
          '   macro avg       0.99      0.99      0.99       128\n'
          'weighted avg       0.99      0.99      0.99       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
124
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       0.96      0.96      0.96        24\n'
         '         2.0       0.00      0.00      0.00         1\n'
         '\n'
         '    accuracy                           0.92        25\n'
         '   macro avg       0.32      0.32      0.32        25\n'
         'weighted avg       0.92      0.92      0.92        25\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.88      0.94        26\n'
          '         2.0       0.94      1.00      0.97        49\n'
          '\n'
          '    accuracy                           0.98       124\n'
          '   macro avg       0.98      0.96      0.97       124\n'
          'weighted avg       0.98      0.98      0.98       124\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.98      0.94      0.96        47\n'
          '         2.0       0.94      0.98      0.96        50\n'
          '\n'
          '    accuracy                           0.96        97\n'
          '   macro avg       0.96      0.96      0.96        97\n'
          'weighted avg       0.96      0.96      0.96        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
97
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.06      1.00      0.11         3\n'
         '\n'
         '    accuracy                           0.06        52\n'
         '   macro avg       0.03      0.50      0.05        52\n'
         'weighted avg       0.00      0.06      0.01        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.98      0.96      0.97        47\n'
          '         2.0       0.96      0.98      0.97        50\n'
          '\n'
          '    accuracy                           0.97        97\n'
          '   macro avg       0.97      0.97      0.97        97\n'
          'weighted avg       0.97      0.97      0.97        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
100
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00      49.0\n'
         '         1.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00      49.0\n'
         '   macro avg       0.00      0.00      0.00      49.0\n'
         'weighted avg       0.00      0.00      0.00      49.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         1.0       0.94      0.94      0.94        50\n'
          '         2.0       0.94      0.94      0.94        50\n'
          '\n'
          '    accuracy                           0.94       100\n'
          '   macro avg       0.94      0.94      0.94       100\n'
          'weighted avg       0.94      0.94      0.94       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
139
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.90      0.95        10\n'
         '         2.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.90        10\n'
         '   macro avg       0.50      0.45      0.47        10\n'
         'weighted avg       1.00      0.90      0.95        10\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       0.97      0.93      0.95        40\n'
          '         2.0       0.94      0.98      0.96        50\n'
          '\n'
          '    accuracy                           0.97       139\n'
          '   macro avg       0.97      0.97      0.97       139\n'
          'weighted avg       0.97      0.97      0.97       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
137
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '         2.0       1.00      0.92      0.96        12\n'
         '\n'
         '    accuracy                           0.92        12\n'
         '   macro avg       0.50      0.46      0.48        12\n'
         'weighted avg       1.00      0.92      0.96        12\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00        50\n'
          '         2.0       1.00      1.00      1.00        38\n'
          '\n'
          '    accuracy                           1.00       137\n'
          '   macro avg       1.00      1.00      1.00       137\n'
          'weighted avg       1.00      1.00      1.00       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
110
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.82      0.35      0.49        26\n'
         '         2.0       0.39      0.85      0.54        13\n'
         '\n'
         '    accuracy                           0.51        39\n'
         '   macro avg       0.61      0.60      0.51        39\n'
         'weighted avg       0.68      0.51      0.50        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      0.96      0.98        24\n'
          '         2.0       0.97      1.00      0.99        37\n'
          '\n'
          '    accuracy                           0.99       110\n'
          '   macro avg       0.99      0.99      0.99       110\n'
          'weighted avg       0.99      0.99      0.99       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
97
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        18\n'
         '           1       0.93      0.78      0.85        18\n'
         '           2       0.79      0.94      0.86        16\n'
         '\n'
         '    accuracy                           0.90        52\n'
         '   macro avg       0.91      0.91      0.90        52\n'
         'weighted avg       0.91      0.90      0.90        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       0.97      0.91      0.94        32\n'
          '           2       0.92      0.97      0.94        34\n'
          '\n'
          '    accuracy                           0.96        97\n'
          '   macro avg       0.96      0.96      0.96        97\n'
          'weighted avg       0.96      0.96      0.96        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
99
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        15\n'
         '           1       1.00      0.94      0.97        16\n'
         '           2       0.95      1.00      0.97        19\n'
         '\n'
         '    accuracy                           0.98        50\n'
         '   macro avg       0.98      0.98      0.98        50\n'
         'weighted avg       0.98      0.98      0.98        50\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        34\n'
          '           1       1.00      0.94      0.97        34\n'
          '           2       0.94      1.00      0.97        31\n'
          '\n'
          '    accuracy                           0.98        99\n'
          '   macro avg       0.98      0.98      0.98        99\n'
          'weighted avg       0.98      0.98      0.98        99\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
102
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       1.00      0.89      0.94        18\n'
         '           2       0.88      1.00      0.94        15\n'
         '\n'
         '    accuracy                           0.96        47\n'
         '   macro avg       0.96      0.96      0.96        47\n'
         'weighted avg       0.96      0.96      0.96        47\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       0.91      0.94      0.92        32\n'
          '           2       0.94      0.91      0.93        35\n'
          '\n'
          '    accuracy                           0.95       102\n'
          '   macro avg       0.95      0.95      0.95       102\n'
          'weighted avg       0.95      0.95      0.95       102\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
100
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        20\n'
         '           1       1.00      0.92      0.96        13\n'
         '           2       0.94      1.00      0.97        16\n'
         '\n'
         '    accuracy                           0.98        49\n'
         '   macro avg       0.98      0.97      0.98        49\n'
         'weighted avg       0.98      0.98      0.98        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        29\n'
          '           1       0.97      0.95      0.96        37\n'
          '           2       0.94      0.97      0.96        34\n'
          '\n'
          '    accuracy                           0.97       100\n'
          '   macro avg       0.97      0.97      0.97       100\n'
          'weighted avg       0.97      0.97      0.97       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
106
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       0.85      0.92      0.88        12\n'
         '           2       0.94      0.89      0.91        18\n'
         '\n'
         '    accuracy                           0.93        43\n'
         '   macro avg       0.93      0.94      0.93        43\n'
         'weighted avg       0.93      0.93      0.93        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       1.00      1.00      1.00        38\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           1.00       106\n'
          '   macro avg       1.00      1.00      1.00       106\n'
          'weighted avg       1.00      1.00      1.00       106\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
80
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        18\n'
         '           1       0.92      0.92      0.92        24\n'
         '           2       0.93      0.93      0.93        27\n'
         '\n'
         '    accuracy                           0.94        69\n'
         '   macro avg       0.95      0.95      0.95        69\n'
         'weighted avg       0.94      0.94      0.94        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       0.96      0.85      0.90        26\n'
          '           2       0.85      0.96      0.90        23\n'
          '\n'
          '    accuracy                           0.94        80\n'
          '   macro avg       0.93      0.93      0.93        80\n'
          'weighted avg       0.94      0.94      0.94        80\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
88
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        19\n'
         '           1       0.89      0.94      0.92        18\n'
         '           2       0.96      0.92      0.94        24\n'
         '\n'
         '    accuracy                           0.95        61\n'
         '   macro avg       0.95      0.95      0.95        61\n'
         'weighted avg       0.95      0.95      0.95        61\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       0.94      0.91      0.92        32\n'
          '           2       0.89      0.92      0.91        26\n'
          '\n'
          '    accuracy                           0.94        88\n'
          '   macro avg       0.94      0.94      0.94        88\n'
          'weighted avg       0.94      0.94      0.94        88\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
79
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        23\n'
         '           1       0.88      0.92      0.90        25\n'
         '           2       0.90      0.86      0.88        22\n'
         '\n'
         '    accuracy                           0.93        70\n'
         '   macro avg       0.93      0.93      0.93        70\n'
         'weighted avg       0.93      0.93      0.93        70\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        26\n'
          '           1       0.83      1.00      0.91        25\n'
          '           2       1.00      0.82      0.90        28\n'
          '\n'
          '    accuracy                           0.94        79\n'
          '   macro avg       0.94      0.94      0.94        79\n'
          'weighted avg       0.95      0.94      0.94        79\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
95
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       0.90      1.00      0.95        19\n'
         '           2       1.00      0.89      0.94        18\n'
         '\n'
         '    accuracy                           0.96        54\n'
         '   macro avg       0.97      0.96      0.96        54\n'
         'weighted avg       0.97      0.96      0.96        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       0.93      0.90      0.92        31\n'
          '           2       0.91      0.94      0.92        32\n'
          '\n'
          '    accuracy                           0.95        95\n'
          '   macro avg       0.95      0.95      0.95        95\n'
          'weighted avg       0.95      0.95      0.95        95\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
115
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       0.83      1.00      0.91        10\n'
         '           2       1.00      0.80      0.89        10\n'
         '\n'
         '    accuracy                           0.94        34\n'
         '   macro avg       0.94      0.93      0.93        34\n'
         'weighted avg       0.95      0.94      0.94        34\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       1.00      1.00      1.00        40\n'
          '           2       1.00      1.00      1.00        40\n'
          '\n'
          '    accuracy                           1.00       115\n'
          '   macro avg       1.00      1.00      1.00       115\n'
          'weighted avg       1.00      1.00      1.00       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       0.94      0.89      0.92        19\n'
         '           2       0.89      0.94      0.91        17\n'
         '\n'
         '    accuracy                           0.94        53\n'
         '   macro avg       0.94      0.95      0.94        53\n'
         'weighted avg       0.94      0.94      0.94        53\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       0.97      1.00      0.98        31\n'
          '           2       1.00      0.97      0.98        33\n'
          '\n'
          '    accuracy                           0.99        96\n'
          '   macro avg       0.99      0.99      0.99        96\n'
          'weighted avg       0.99      0.99      0.99        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
107
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       0.85      1.00      0.92        11\n'
         '           2       1.00      0.86      0.92        14\n'
         '\n'
         '    accuracy                           0.95        42\n'
         '   macro avg       0.95      0.95      0.95        42\n'
         'weighted avg       0.96      0.95      0.95        42\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       1.00      0.95      0.97        39\n'
          '           2       0.95      1.00      0.97        36\n'
          '\n'
          '    accuracy                           0.98       107\n'
          '   macro avg       0.98      0.98      0.98       107\n'
          'weighted avg       0.98      0.98      0.98       107\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
74
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        18\n'
         '           1       0.96      0.86      0.91        29\n'
         '           2       0.87      0.96      0.92        28\n'
         '\n'
         '    accuracy                           0.93        75\n'
         '   macro avg       0.94      0.94      0.94        75\n'
         'weighted avg       0.94      0.93      0.93        75\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       0.94      0.76      0.84        21\n'
          '           2       0.81      0.95      0.88        22\n'
          '\n'
          '    accuracy                           0.92        74\n'
          '   macro avg       0.92      0.91      0.91        74\n'
          'weighted avg       0.93      0.92      0.92        74\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
97
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       1.00      0.94      0.97        17\n'
         '           2       0.95      1.00      0.97        18\n'
         '\n'
         '    accuracy                           0.98        52\n'
         '   macro avg       0.98      0.98      0.98        52\n'
         'weighted avg       0.98      0.98      0.98        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       0.97      0.94      0.95        33\n'
          '           2       0.94      0.97      0.95        32\n'
          '\n'
          '    accuracy                           0.97        97\n'
          '   macro avg       0.97      0.97      0.97        97\n'
          'weighted avg       0.97      0.97      0.97        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
110
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       0.86      0.92      0.89        13\n'
         '           2       0.92      0.85      0.88        13\n'
         '\n'
         '    accuracy                           0.92        39\n'
         '   macro avg       0.92      0.92      0.92        39\n'
         'weighted avg       0.92      0.92      0.92        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       0.95      0.95      0.95        37\n'
          '           2       0.95      0.95      0.95        37\n'
          '\n'
          '    accuracy                           0.96       110\n'
          '   macro avg       0.96      0.96      0.96       110\n'
          'weighted avg       0.96      0.96      0.96       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
104
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       0.93      0.87      0.90        15\n'
         '           2       0.89      0.94      0.91        17\n'
         '\n'
         '    accuracy                           0.93        45\n'
         '   macro avg       0.94      0.94      0.94        45\n'
         'weighted avg       0.93      0.93      0.93        45\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       0.97      1.00      0.99        35\n'
          '           2       1.00      0.97      0.98        33\n'
          '\n'
          '    accuracy                           0.99       104\n'
          '   macro avg       0.99      0.99      0.99       104\n'
          'weighted avg       0.99      0.99      0.99       104\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
117
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       0.75      1.00      0.86         6\n'
         '           2       1.00      0.83      0.91        12\n'
         '\n'
         '    accuracy                           0.94        32\n'
         '   macro avg       0.92      0.94      0.92        32\n'
         'weighted avg       0.95      0.94      0.94        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       0.96      1.00      0.98        44\n'
          '           2       1.00      0.95      0.97        38\n'
          '\n'
          '    accuracy                           0.98       117\n'
          '   macro avg       0.99      0.98      0.98       117\n'
          'weighted avg       0.98      0.98      0.98       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
94
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       0.85      0.89      0.87        19\n'
         '           2       0.89      0.84      0.86        19\n'
         '\n'
         '    accuracy                           0.91        55\n'
         '   macro avg       0.91      0.91      0.91        55\n'
         'weighted avg       0.91      0.91      0.91        55\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       1.00      0.94      0.97        31\n'
          '           2       0.94      1.00      0.97        31\n'
          '\n'
          '    accuracy                           0.98        94\n'
          '   macro avg       0.98      0.98      0.98        94\n'
          'weighted avg       0.98      0.98      0.98        94\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
83
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       0.95      0.79      0.86        24\n'
         '           2       0.80      0.95      0.87        21\n'
         '\n'
         '    accuracy                           0.91        66\n'
         '   macro avg       0.92      0.91      0.91        66\n'
         'weighted avg       0.92      0.91      0.91        66\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       0.96      0.85      0.90        26\n'
          '           2       0.88      0.97      0.92        29\n'
          '\n'
          '    accuracy                           0.94        83\n'
          '   macro avg       0.94      0.94      0.94        83\n'
          'weighted avg       0.94      0.94      0.94        83\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
100
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        16\n'
         '           1       1.00      0.89      0.94        18\n'
         '           2       0.88      1.00      0.94        15\n'
         '\n'
         '    accuracy                           0.96        49\n'
         '   macro avg       0.96      0.96      0.96        49\n'
         'weighted avg       0.96      0.96      0.96        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       1.00      0.94      0.97        32\n'
          '           2       0.95      1.00      0.97        35\n'
          '\n'
          '    accuracy                           0.98       100\n'
          '   macro avg       0.98      0.98      0.98       100\n'
          'weighted avg       0.98      0.98      0.98       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
78
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        29\n'
         '           1       0.92      0.96      0.94        23\n'
         '           2       0.94      0.89      0.92        19\n'
         '\n'
         '    accuracy                           0.96        71\n'
         '   macro avg       0.95      0.95      0.95        71\n'
         'weighted avg       0.96      0.96      0.96        71\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        20\n'
          '           1       0.93      0.96      0.95        27\n'
          '           2       0.97      0.94      0.95        31\n'
          '\n'
          '    accuracy                           0.96        78\n'
          '   macro avg       0.97      0.97      0.97        78\n'
          'weighted avg       0.96      0.96      0.96        78\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
83
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        19\n'
         '           1       0.87      0.95      0.91        21\n'
         '           2       0.96      0.88      0.92        26\n'
         '\n'
         '    accuracy                           0.94        66\n'
         '   macro avg       0.94      0.95      0.94        66\n'
         'weighted avg       0.94      0.94      0.94        66\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       0.97      0.97      0.97        29\n'
          '           2       0.96      0.96      0.96        24\n'
          '\n'
          '    accuracy                           0.98        83\n'
          '   macro avg       0.97      0.97      0.97        83\n'
          'weighted avg       0.98      0.98      0.98        83\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
102
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        11\n'
         '           1       0.94      0.94      0.94        18\n'
         '           2       0.94      0.94      0.94        18\n'
         '\n'
         '    accuracy                           0.96        47\n'
         '   macro avg       0.96      0.96      0.96        47\n'
         'weighted avg       0.96      0.96      0.96        47\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        38\n'
          '           1       1.00      1.00      1.00        32\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           1.00       102\n'
          '   macro avg       1.00      1.00      1.00       102\n'
          'weighted avg       1.00      1.00      1.00       102\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
118
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       0.85      0.92      0.88        12\n'
         '           2       0.88      0.78      0.82         9\n'
         '\n'
         '    accuracy                           0.90        31\n'
         '   macro avg       0.91      0.90      0.90        31\n'
         'weighted avg       0.90      0.90      0.90        31\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       0.93      0.97      0.95        38\n'
          '           2       0.97      0.93      0.95        41\n'
          '\n'
          '    accuracy                           0.97       118\n'
          '   macro avg       0.97      0.97      0.97       118\n'
          'weighted avg       0.97      0.97      0.97       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
100
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       0.83      0.88      0.86        17\n'
         '           2       0.89      0.85      0.87        20\n'
         '\n'
         '    accuracy                           0.90        49\n'
         '   macro avg       0.91      0.91      0.91        49\n'
         'weighted avg       0.90      0.90      0.90        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       0.97      0.91      0.94        33\n'
          '           2       0.91      0.97      0.94        30\n'
          '\n'
          '    accuracy                           0.96       100\n'
          '   macro avg       0.96      0.96      0.96       100\n'
          'weighted avg       0.96      0.96      0.96       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        20\n'
         '           1       1.00      1.00      1.00        16\n'
         '           2       1.00      1.00      1.00        17\n'
         '\n'
         '    accuracy                           1.00        53\n'
         '   macro avg       1.00      1.00      1.00        53\n'
         'weighted avg       1.00      1.00      1.00        53\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        29\n'
          '           1       1.00      0.94      0.97        34\n'
          '           2       0.94      1.00      0.97        33\n'
          '\n'
          '    accuracy                           0.98        96\n'
          '   macro avg       0.98      0.98      0.98        96\n'
          'weighted avg       0.98      0.98      0.98        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
100
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       1.00      0.94      0.97        18\n'
         '           2       0.95      1.00      0.97        19\n'
         '\n'
         '    accuracy                           0.98        49\n'
         '   macro avg       0.98      0.98      0.98        49\n'
         'weighted avg       0.98      0.98      0.98        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       0.94      0.91      0.92        32\n'
          '           2       0.91      0.94      0.92        31\n'
          '\n'
          '    accuracy                           0.95       100\n'
          '   macro avg       0.95      0.95      0.95       100\n'
          'weighted avg       0.95      0.95      0.95       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
80
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        23\n'
         '           1       0.89      0.84      0.86        19\n'
         '           2       0.89      0.93      0.91        27\n'
         '\n'
         '    accuracy                           0.93        69\n'
         '   macro avg       0.93      0.92      0.92        69\n'
         'weighted avg       0.93      0.93      0.93        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        26\n'
          '           1       0.97      1.00      0.98        31\n'
          '           2       1.00      0.96      0.98        23\n'
          '\n'
          '    accuracy                           0.99        80\n'
          '   macro avg       0.99      0.99      0.99        80\n'
          'weighted avg       0.99      0.99      0.99        80\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
80
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        25\n'
         '           1       0.94      0.89      0.91        18\n'
         '           2       0.93      0.96      0.94        26\n'
         '\n'
         '    accuracy                           0.96        69\n'
         '   macro avg       0.96      0.95      0.95        69\n'
         'weighted avg       0.96      0.96      0.96        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        24\n'
          '           1       0.97      1.00      0.98        32\n'
          '           2       1.00      0.96      0.98        24\n'
          '\n'
          '    accuracy                           0.99        80\n'
          '   macro avg       0.99      0.99      0.99        80\n'
          'weighted avg       0.99      0.99      0.99        80\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
87
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        19\n'
         '           1       0.91      1.00      0.95        21\n'
         '           2       1.00      0.91      0.95        22\n'
         '\n'
         '    accuracy                           0.97        62\n'
         '   macro avg       0.97      0.97      0.97        62\n'
         'weighted avg       0.97      0.97      0.97        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       0.93      0.93      0.93        29\n'
          '           2       0.93      0.93      0.93        28\n'
          '\n'
          '    accuracy                           0.95        87\n'
          '   macro avg       0.95      0.95      0.95        87\n'
          'weighted avg       0.95      0.95      0.95        87\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
106
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        16\n'
         '           1       1.00      0.93      0.97        15\n'
         '           2       0.92      1.00      0.96        12\n'
         '\n'
         '    accuracy                           0.98        43\n'
         '   macro avg       0.97      0.98      0.98        43\n'
         'weighted avg       0.98      0.98      0.98        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       0.94      0.89      0.91        35\n'
          '           2       0.90      0.95      0.92        38\n'
          '\n'
          '    accuracy                           0.94       106\n'
          '   macro avg       0.95      0.94      0.94       106\n'
          'weighted avg       0.94      0.94      0.94       106\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
117
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        15\n'
         '           1       1.00      1.00      1.00         7\n'
         '           2       1.00      1.00      1.00        10\n'
         '\n'
         '    accuracy                           1.00        32\n'
         '   macro avg       1.00      1.00      1.00        32\n'
         'weighted avg       1.00      1.00      1.00        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        34\n'
          '           1       0.95      0.95      0.95        43\n'
          '           2       0.95      0.95      0.95        40\n'
          '\n'
          '    accuracy                           0.97       117\n'
          '   macro avg       0.97      0.97      0.97       117\n'
          'weighted avg       0.97      0.97      0.97       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
78
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        22\n'
         '           1       0.95      0.84      0.89        25\n'
         '           2       0.85      0.96      0.90        24\n'
         '\n'
         '    accuracy                           0.93        71\n'
         '   macro avg       0.94      0.93      0.93        71\n'
         'weighted avg       0.93      0.93      0.93        71\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        27\n'
          '           1       0.93      1.00      0.96        25\n'
          '           2       1.00      0.92      0.96        26\n'
          '\n'
          '    accuracy                           0.97        78\n'
          '   macro avg       0.98      0.97      0.97        78\n'
          'weighted avg       0.98      0.97      0.97        78\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
75
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        29\n'
         '           1       1.00      0.90      0.95        20\n'
         '           2       0.93      1.00      0.96        25\n'
         '\n'
         '    accuracy                           0.97        74\n'
         '   macro avg       0.98      0.97      0.97        74\n'
         'weighted avg       0.97      0.97      0.97        74\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        20\n'
          '           1       0.97      0.97      0.97        30\n'
          '           2       0.96      0.96      0.96        25\n'
          '\n'
          '    accuracy                           0.97        75\n'
          '   macro avg       0.98      0.98      0.98        75\n'
          'weighted avg       0.97      0.97      0.97        75\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        18\n'
         '           1       0.94      1.00      0.97        16\n'
         '           2       1.00      0.95      0.97        19\n'
         '\n'
         '    accuracy                           0.98        53\n'
         '   macro avg       0.98      0.98      0.98        53\n'
         'weighted avg       0.98      0.98      0.98        53\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       0.97      1.00      0.99        34\n'
          '           2       1.00      0.97      0.98        31\n'
          '\n'
          '    accuracy                           0.99        96\n'
          '   macro avg       0.99      0.99      0.99        96\n'
          'weighted avg       0.99      0.99      0.99        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
91
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        16\n'
         '           1       0.95      0.90      0.93        21\n'
         '           2       0.91      0.95      0.93        21\n'
         '\n'
         '    accuracy                           0.95        58\n'
         '   macro avg       0.95      0.95      0.95        58\n'
         'weighted avg       0.95      0.95      0.95        58\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       1.00      0.90      0.95        29\n'
          '           2       0.91      1.00      0.95        29\n'
          '\n'
          '    accuracy                           0.97        91\n'
          '   macro avg       0.97      0.97      0.97        91\n'
          'weighted avg       0.97      0.97      0.97        91\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
108
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       1.00      0.87      0.93        15\n'
         '           2       0.89      1.00      0.94        16\n'
         '\n'
         '    accuracy                           0.95        41\n'
         '   macro avg       0.96      0.96      0.96        41\n'
         'weighted avg       0.96      0.95      0.95        41\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       0.94      0.91      0.93        35\n'
          '           2       0.91      0.94      0.93        34\n'
          '\n'
          '    accuracy                           0.95       108\n'
          '   macro avg       0.95      0.95      0.95       108\n'
          'weighted avg       0.95      0.95      0.95       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
117
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       1.00      1.00      1.00         8\n'
         '           2       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           1.00        32\n'
         '   macro avg       1.00      1.00      1.00        32\n'
         'weighted avg       1.00      1.00      1.00        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       1.00      0.93      0.96        42\n'
          '           2       0.93      1.00      0.96        38\n'
          '\n'
          '    accuracy                           0.97       117\n'
          '   macro avg       0.98      0.98      0.97       117\n'
          'weighted avg       0.98      0.97      0.97       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
106
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        19\n'
         '           1       0.83      1.00      0.91        10\n'
         '           2       1.00      0.86      0.92        14\n'
         '\n'
         '    accuracy                           0.95        43\n'
         '   macro avg       0.94      0.95      0.94        43\n'
         'weighted avg       0.96      0.95      0.95        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       0.95      0.95      0.95        40\n'
          '           2       0.94      0.94      0.94        36\n'
          '\n'
          '    accuracy                           0.96       106\n'
          '   macro avg       0.96      0.96      0.96       106\n'
          'weighted avg       0.96      0.96      0.96       106\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
90
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        20\n'
         '           1       1.00      0.95      0.97        19\n'
         '           2       0.95      1.00      0.98        20\n'
         '\n'
         '    accuracy                           0.98        59\n'
         '   macro avg       0.98      0.98      0.98        59\n'
         'weighted avg       0.98      0.98      0.98        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        29\n'
          '           1       1.00      1.00      1.00        31\n'
          '           2       1.00      1.00      1.00        30\n'
          '\n'
          '    accuracy                           1.00        90\n'
          '   macro avg       1.00      1.00      1.00        90\n'
          'weighted avg       1.00      1.00      1.00        90\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
82
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        20\n'
         '           1       1.00      0.86      0.93        29\n'
         '           2       0.82      1.00      0.90        18\n'
         '\n'
         '    accuracy                           0.94        67\n'
         '   macro avg       0.94      0.95      0.94        67\n'
         'weighted avg       0.95      0.94      0.94        67\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        29\n'
          '           1       1.00      1.00      1.00        21\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           1.00        82\n'
          '   macro avg       1.00      1.00      1.00        82\n'
          'weighted avg       1.00      1.00      1.00        82\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
111
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       1.00      0.93      0.96        14\n'
         '           2       0.92      1.00      0.96        11\n'
         '\n'
         '    accuracy                           0.97        38\n'
         '   macro avg       0.97      0.98      0.97        38\n'
         'weighted avg       0.98      0.97      0.97        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       0.88      0.97      0.92        36\n'
          '           2       0.97      0.87      0.92        39\n'
          '\n'
          '    accuracy                           0.95       111\n'
          '   macro avg       0.95      0.95      0.95       111\n'
          'weighted avg       0.95      0.95      0.95       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
117
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       1.00      0.90      0.95        10\n'
         '           2       0.92      1.00      0.96        12\n'
         '\n'
         '    accuracy                           0.97        32\n'
         '   macro avg       0.97      0.97      0.97        32\n'
         'weighted avg       0.97      0.97      0.97        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       0.95      0.88      0.91        40\n'
          '           2       0.88      0.95      0.91        38\n'
          '\n'
          '    accuracy                           0.94       117\n'
          '   macro avg       0.94      0.94      0.94       117\n'
          'weighted avg       0.94      0.94      0.94       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
110
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       0.88      0.93      0.90        15\n'
         '           2       0.90      0.82      0.86        11\n'
         '\n'
         '    accuracy                           0.92        39\n'
         '   macro avg       0.92      0.92      0.92        39\n'
         'weighted avg       0.92      0.92      0.92        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       1.00      0.91      0.96        35\n'
          '           2       0.93      1.00      0.96        39\n'
          '\n'
          '    accuracy                           0.97       110\n'
          '   macro avg       0.98      0.97      0.97       110\n'
          'weighted avg       0.97      0.97      0.97       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
89
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        18\n'
         '           1       1.00      0.73      0.84        22\n'
         '           2       0.77      1.00      0.87        20\n'
         '\n'
         '    accuracy                           0.90        60\n'
         '   macro avg       0.92      0.91      0.90        60\n'
         'weighted avg       0.92      0.90      0.90        60\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       0.93      0.93      0.93        28\n'
          '           2       0.93      0.93      0.93        30\n'
          '\n'
          '    accuracy                           0.96        89\n'
          '   macro avg       0.95      0.95      0.95        89\n'
          'weighted avg       0.96      0.96      0.96        89\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
107
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       0.94      1.00      0.97        15\n'
         '           2       1.00      0.93      0.97        15\n'
         '\n'
         '    accuracy                           0.98        42\n'
         '   macro avg       0.98      0.98      0.98        42\n'
         'weighted avg       0.98      0.98      0.98        42\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       1.00      0.94      0.97        35\n'
          '           2       0.95      1.00      0.97        35\n'
          '\n'
          '    accuracy                           0.98       107\n'
          '   macro avg       0.98      0.98      0.98       107\n'
          'weighted avg       0.98      0.98      0.98       107\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
101
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        15\n'
         '           1       0.80      0.94      0.86        17\n'
         '           2       0.92      0.75      0.83        16\n'
         '\n'
         '    accuracy                           0.90        48\n'
         '   macro avg       0.91      0.90      0.90        48\n'
         'weighted avg       0.90      0.90      0.89        48\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        34\n'
          '           1       1.00      1.00      1.00        33\n'
          '           2       1.00      1.00      1.00        34\n'
          '\n'
          '    accuracy                           1.00       101\n'
          '   macro avg       1.00      1.00      1.00       101\n'
          'weighted avg       1.00      1.00      1.00       101\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
118
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         7\n'
         '           1       0.93      0.72      0.81        18\n'
         '           2       0.50      0.83      0.62         6\n'
         '\n'
         '    accuracy                           0.81        31\n'
         '   macro avg       0.81      0.85      0.81        31\n'
         'weighted avg       0.86      0.81      0.82        31\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        42\n'
          '           1       1.00      0.97      0.98        32\n'
          '           2       0.98      1.00      0.99        44\n'
          '\n'
          '    accuracy                           0.99       118\n'
          '   macro avg       0.99      0.99      0.99       118\n'
          'weighted avg       0.99      0.99      0.99       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
106
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       1.00      1.00      1.00        12\n'
         '           2       1.00      1.00      1.00        14\n'
         '\n'
         '    accuracy                           1.00        43\n'
         '   macro avg       1.00      1.00      1.00        43\n'
         'weighted avg       1.00      1.00      1.00        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       0.94      0.87      0.90        38\n'
          '           2       0.87      0.94      0.91        36\n'
          '\n'
          '    accuracy                           0.93       106\n'
          '   macro avg       0.94      0.94      0.94       106\n'
          'weighted avg       0.94      0.93      0.93       106\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
108
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       0.93      1.00      0.96        13\n'
         '           2       1.00      0.93      0.96        14\n'
         '\n'
         '    accuracy                           0.98        41\n'
         '   macro avg       0.98      0.98      0.98        41\n'
         'weighted avg       0.98      0.98      0.98        41\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       0.92      0.95      0.93        37\n'
          '           2       0.94      0.92      0.93        36\n'
          '\n'
          '    accuracy                           0.95       108\n'
          '   macro avg       0.95      0.95      0.95       108\n'
          'weighted avg       0.95      0.95      0.95       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
83
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       0.95      1.00      0.98        20\n'
         '           2       1.00      0.96      0.98        25\n'
         '\n'
         '    accuracy                           0.98        66\n'
         '   macro avg       0.98      0.99      0.99        66\n'
         'weighted avg       0.99      0.98      0.98        66\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       0.90      0.90      0.90        30\n'
          '           2       0.88      0.88      0.88        25\n'
          '\n'
          '    accuracy                           0.93        83\n'
          '   macro avg       0.93      0.93      0.93        83\n'
          'weighted avg       0.93      0.93      0.93        83\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
110
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       1.00      0.92      0.96        13\n'
         '           2       0.90      1.00      0.95         9\n'
         '\n'
         '    accuracy                           0.97        39\n'
         '   macro avg       0.97      0.97      0.97        39\n'
         'weighted avg       0.98      0.97      0.97        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       1.00      1.00      1.00        37\n'
          '           2       1.00      1.00      1.00        41\n'
          '\n'
          '    accuracy                           1.00       110\n'
          '   macro avg       1.00      1.00      1.00       110\n'
          'weighted avg       1.00      1.00      1.00       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
92
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        19\n'
         '           1       0.90      0.95      0.93        20\n'
         '           2       0.94      0.89      0.91        18\n'
         '\n'
         '    accuracy                           0.95        57\n'
         '   macro avg       0.95      0.95      0.95        57\n'
         'weighted avg       0.95      0.95      0.95        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       0.97      1.00      0.98        30\n'
          '           2       1.00      0.97      0.98        32\n'
          '\n'
          '    accuracy                           0.99        92\n'
          '   macro avg       0.99      0.99      0.99        92\n'
          'weighted avg       0.99      0.99      0.99        92\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
93
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        18\n'
         '           1       1.00      0.81      0.90        16\n'
         '           2       0.88      1.00      0.94        22\n'
         '\n'
         '    accuracy                           0.95        56\n'
         '   macro avg       0.96      0.94      0.94        56\n'
         'weighted avg       0.95      0.95      0.95        56\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       0.94      0.94      0.94        34\n'
          '           2       0.93      0.93      0.93        28\n'
          '\n'
          '    accuracy                           0.96        93\n'
          '   macro avg       0.96      0.96      0.96        93\n'
          'weighted avg       0.96      0.96      0.96        93\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
82
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        19\n'
         '           1       0.83      0.95      0.89        21\n'
         '           2       0.96      0.85      0.90        27\n'
         '\n'
         '    accuracy                           0.93        67\n'
         '   macro avg       0.93      0.93      0.93        67\n'
         'weighted avg       0.93      0.93      0.93        67\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       0.93      0.93      0.93        29\n'
          '           2       0.91      0.91      0.91        23\n'
          '\n'
          '    accuracy                           0.95        82\n'
          '   macro avg       0.95      0.95      0.95        82\n'
          'weighted avg       0.95      0.95      0.95        82\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
88
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        23\n'
         '           1       0.93      0.93      0.93        15\n'
         '           2       0.96      0.96      0.96        23\n'
         '\n'
         '    accuracy                           0.97        61\n'
         '   macro avg       0.96      0.96      0.96        61\n'
         'weighted avg       0.97      0.97      0.97        61\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        26\n'
          '           1       1.00      0.97      0.99        35\n'
          '           2       0.96      1.00      0.98        27\n'
          '\n'
          '    accuracy                           0.99        88\n'
          '   macro avg       0.99      0.99      0.99        88\n'
          'weighted avg       0.99      0.99      0.99        88\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
76
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        25\n'
         '           1       0.86      0.86      0.86        21\n'
         '           2       0.89      0.89      0.89        27\n'
         '\n'
         '    accuracy                           0.92        73\n'
         '   macro avg       0.92      0.92      0.92        73\n'
         'weighted avg       0.92      0.92      0.92        73\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        24\n'
          '           1       0.97      0.97      0.97        29\n'
          '           2       0.96      0.96      0.96        23\n'
          '\n'
          '    accuracy                           0.97        76\n'
          '   macro avg       0.97      0.97      0.97        76\n'
          'weighted avg       0.97      0.97      0.97        76\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
108
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        15\n'
         '           1       1.00      1.00      1.00        15\n'
         '           2       1.00      1.00      1.00        11\n'
         '\n'
         '    accuracy                           1.00        41\n'
         '   macro avg       1.00      1.00      1.00        41\n'
         'weighted avg       1.00      1.00      1.00        41\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        34\n'
          '           1       0.97      0.94      0.96        35\n'
          '           2       0.95      0.97      0.96        39\n'
          '\n'
          '    accuracy                           0.97       108\n'
          '   macro avg       0.97      0.97      0.97       108\n'
          'weighted avg       0.97      0.97      0.97       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
109
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         9\n'
         '           1       0.94      0.94      0.94        18\n'
         '           2       0.92      0.92      0.92        13\n'
         '\n'
         '    accuracy                           0.95        40\n'
         '   macro avg       0.96      0.96      0.96        40\n'
         'weighted avg       0.95      0.95      0.95        40\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        40\n'
          '           1       0.97      1.00      0.98        32\n'
          '           2       1.00      0.97      0.99        37\n'
          '\n'
          '    accuracy                           0.99       109\n'
          '   macro avg       0.99      0.99      0.99       109\n'
          'weighted avg       0.99      0.99      0.99       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
83
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       0.90      0.90      0.90        21\n'
         '           2       0.92      0.92      0.92        24\n'
         '\n'
         '    accuracy                           0.94        66\n'
         '   macro avg       0.94      0.94      0.94        66\n'
         'weighted avg       0.94      0.94      0.94        66\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       0.96      0.93      0.95        29\n'
          '           2       0.93      0.96      0.94        26\n'
          '\n'
          '    accuracy                           0.96        83\n'
          '   macro avg       0.96      0.96      0.96        83\n'
          'weighted avg       0.96      0.96      0.96        83\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
102
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       1.00      0.76      0.86        21\n'
         '           2       0.74      1.00      0.85        14\n'
         '\n'
         '    accuracy                           0.89        47\n'
         '   macro avg       0.91      0.92      0.90        47\n'
         'weighted avg       0.92      0.89      0.89        47\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       0.93      0.93      0.93        29\n'
          '           2       0.94      0.94      0.94        36\n'
          '\n'
          '    accuracy                           0.96       102\n'
          '   macro avg       0.96      0.96      0.96       102\n'
          'weighted avg       0.96      0.96      0.96       102\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
104
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       1.00      0.94      0.97        17\n'
         '           2       0.88      1.00      0.93         7\n'
         '\n'
         '    accuracy                           0.98        45\n'
         '   macro avg       0.96      0.98      0.97        45\n'
         'weighted avg       0.98      0.98      0.98        45\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       1.00      0.94      0.97        33\n'
          '           2       0.96      1.00      0.98        43\n'
          '\n'
          '    accuracy                           0.98       104\n'
          '   macro avg       0.99      0.98      0.98       104\n'
          'weighted avg       0.98      0.98      0.98       104\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
101
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       0.89      1.00      0.94        16\n'
         '           2       1.00      0.89      0.94        19\n'
         '\n'
         '    accuracy                           0.96        48\n'
         '   macro avg       0.96      0.96      0.96        48\n'
         'weighted avg       0.96      0.96      0.96        48\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       0.94      0.94      0.94        34\n'
          '           2       0.94      0.94      0.94        31\n'
          '\n'
          '    accuracy                           0.96       101\n'
          '   macro avg       0.96      0.96      0.96       101\n'
          'weighted avg       0.96      0.96      0.96       101\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
114
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        11\n'
         '           1       0.89      1.00      0.94         8\n'
         '           2       1.00      0.94      0.97        16\n'
         '\n'
         '    accuracy                           0.97        35\n'
         '   macro avg       0.96      0.98      0.97        35\n'
         'weighted avg       0.97      0.97      0.97        35\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        38\n'
          '           1       0.97      0.93      0.95        42\n'
          '           2       0.92      0.97      0.94        34\n'
          '\n'
          '    accuracy                           0.96       114\n'
          '   macro avg       0.96      0.97      0.96       114\n'
          'weighted avg       0.97      0.96      0.96       114\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
106
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        11\n'
         '           1       0.93      1.00      0.97        14\n'
         '           2       1.00      0.94      0.97        18\n'
         '\n'
         '    accuracy                           0.98        43\n'
         '   macro avg       0.98      0.98      0.98        43\n'
         'weighted avg       0.98      0.98      0.98        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        38\n'
          '           1       1.00      1.00      1.00        36\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           1.00       106\n'
          '   macro avg       1.00      1.00      1.00       106\n'
          'weighted avg       1.00      1.00      1.00       106\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
115
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       1.00      0.92      0.96        12\n'
         '           2       0.92      1.00      0.96        12\n'
         '\n'
         '    accuracy                           0.97        34\n'
         '   macro avg       0.97      0.97      0.97        34\n'
         'weighted avg       0.97      0.97      0.97        34\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       0.97      0.89      0.93        38\n'
          '           2       0.90      0.97      0.94        38\n'
          '\n'
          '    accuracy                           0.96       115\n'
          '   macro avg       0.96      0.96      0.96       115\n'
          'weighted avg       0.96      0.96      0.96       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
93
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        16\n'
         '           1       0.82      1.00      0.90        18\n'
         '           2       1.00      0.82      0.90        22\n'
         '\n'
         '    accuracy                           0.93        56\n'
         '   macro avg       0.94      0.94      0.93        56\n'
         'weighted avg       0.94      0.93      0.93        56\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       0.91      0.94      0.92        32\n'
          '           2       0.93      0.89      0.91        28\n'
          '\n'
          '    accuracy                           0.95        93\n'
          '   macro avg       0.95      0.94      0.94        93\n'
          'weighted avg       0.95      0.95      0.95        93\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
106
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        11\n'
         '           1       1.00      0.94      0.97        17\n'
         '           2       0.94      1.00      0.97        15\n'
         '\n'
         '    accuracy                           0.98        43\n'
         '   macro avg       0.98      0.98      0.98        43\n'
         'weighted avg       0.98      0.98      0.98        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        38\n'
          '           1       1.00      0.97      0.98        33\n'
          '           2       0.97      1.00      0.99        35\n'
          '\n'
          '    accuracy                           0.99       106\n'
          '   macro avg       0.99      0.99      0.99       106\n'
          'weighted avg       0.99      0.99      0.99       106\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
115
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         4\n'
         '           1       0.88      0.88      0.88        16\n'
         '           2       0.86      0.86      0.86        14\n'
         '\n'
         '    accuracy                           0.88        34\n'
         '   macro avg       0.91      0.91      0.91        34\n'
         'weighted avg       0.88      0.88      0.88        34\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        45\n'
          '           1       0.94      0.97      0.96        34\n'
          '           2       0.97      0.94      0.96        36\n'
          '\n'
          '    accuracy                           0.97       115\n'
          '   macro avg       0.97      0.97      0.97       115\n'
          'weighted avg       0.97      0.97      0.97       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
77
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        19\n'
         '           1       0.96      0.89      0.93        28\n'
         '           2       0.89      0.96      0.92        25\n'
         '\n'
         '    accuracy                           0.94        72\n'
         '   macro avg       0.95      0.95      0.95        72\n'
         'weighted avg       0.95      0.94      0.94        72\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       0.95      0.91      0.93        22\n'
          '           2       0.92      0.96      0.94        25\n'
          '\n'
          '    accuracy                           0.96        77\n'
          '   macro avg       0.96      0.96      0.96        77\n'
          'weighted avg       0.96      0.96      0.96        77\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
98
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        18\n'
         '           1       0.86      0.86      0.86        14\n'
         '           2       0.89      0.89      0.89        19\n'
         '\n'
         '    accuracy                           0.92        51\n'
         '   macro avg       0.92      0.92      0.92        51\n'
         'weighted avg       0.92      0.92      0.92        51\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       1.00      0.97      0.99        36\n'
          '           2       0.97      1.00      0.98        31\n'
          '\n'
          '    accuracy                           0.99        98\n'
          '   macro avg       0.99      0.99      0.99        98\n'
          'weighted avg       0.99      0.99      0.99        98\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
99
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        16\n'
         '           1       0.89      1.00      0.94        17\n'
         '           2       1.00      0.88      0.94        17\n'
         '\n'
         '    accuracy                           0.96        50\n'
         '   macro avg       0.96      0.96      0.96        50\n'
         'weighted avg       0.96      0.96      0.96        50\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       0.94      0.97      0.96        33\n'
          '           2       0.97      0.94      0.95        33\n'
          '\n'
          '    accuracy                           0.97        99\n'
          '   macro avg       0.97      0.97      0.97        99\n'
          'weighted avg       0.97      0.97      0.97        99\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
116
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       0.92      0.92      0.92        12\n'
         '           2       0.89      0.89      0.89         9\n'
         '\n'
         '    accuracy                           0.94        33\n'
         '   macro avg       0.94      0.94      0.94        33\n'
         'weighted avg       0.94      0.94      0.94        33\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       0.97      0.87      0.92        38\n'
          '           2       0.89      0.98      0.93        41\n'
          '\n'
          '    accuracy                           0.95       116\n'
          '   macro avg       0.95      0.95      0.95       116\n'
          'weighted avg       0.95      0.95      0.95       116\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
116
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         8\n'
         '           1       1.00      0.82      0.90        11\n'
         '           2       0.88      1.00      0.93        14\n'
         '\n'
         '    accuracy                           0.94        33\n'
         '   macro avg       0.96      0.94      0.94        33\n'
         'weighted avg       0.95      0.94      0.94        33\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        41\n'
          '           1       1.00      0.95      0.97        39\n'
          '           2       0.95      1.00      0.97        36\n'
          '\n'
          '    accuracy                           0.98       116\n'
          '   macro avg       0.98      0.98      0.98       116\n'
          'weighted avg       0.98      0.98      0.98       116\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
113
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       0.86      1.00      0.92        12\n'
         '           2       1.00      0.83      0.91        12\n'
         '\n'
         '    accuracy                           0.94        36\n'
         '   macro avg       0.95      0.94      0.94        36\n'
         'weighted avg       0.95      0.94      0.94        36\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       0.95      0.95      0.95        38\n'
          '           2       0.95      0.95      0.95        38\n'
          '\n'
          '    accuracy                           0.96       113\n'
          '   macro avg       0.96      0.96      0.96       113\n'
          'weighted avg       0.96      0.96      0.96       113\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
82
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        26\n'
         '           1       0.95      0.86      0.90        22\n'
         '           2       0.86      0.95      0.90        19\n'
         '\n'
         '    accuracy                           0.94        67\n'
         '   macro avg       0.94      0.94      0.93        67\n'
         'weighted avg       0.94      0.94      0.94        67\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        23\n'
          '           1       1.00      0.96      0.98        28\n'
          '           2       0.97      1.00      0.98        31\n'
          '\n'
          '    accuracy                           0.99        82\n'
          '   macro avg       0.99      0.99      0.99        82\n'
          'weighted avg       0.99      0.99      0.99        82\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
117
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       0.88      0.88      0.88         8\n'
         '           2       0.93      0.93      0.93        14\n'
         '\n'
         '    accuracy                           0.94        32\n'
         '   macro avg       0.93      0.93      0.93        32\n'
         'weighted avg       0.94      0.94      0.94        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       0.98      0.98      0.98        42\n'
          '           2       0.97      0.97      0.97        36\n'
          '\n'
          '    accuracy                           0.98       117\n'
          '   macro avg       0.98      0.98      0.98       117\n'
          'weighted avg       0.98      0.98      0.98       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
109
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        16\n'
         '           1       0.87      0.93      0.90        14\n'
         '           2       0.89      0.80      0.84        10\n'
         '\n'
         '    accuracy                           0.93        40\n'
         '   macro avg       0.92      0.91      0.91        40\n'
         'weighted avg       0.93      0.93      0.92        40\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       0.95      0.97      0.96        36\n'
          '           2       0.97      0.95      0.96        40\n'
          '\n'
          '    accuracy                           0.97       109\n'
          '   macro avg       0.97      0.97      0.97       109\n'
          'weighted avg       0.97      0.97      0.97       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
80
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        24\n'
         '           1       0.78      0.78      0.78        23\n'
         '           2       0.77      0.77      0.77        22\n'
         '\n'
         '    accuracy                           0.86        69\n'
         '   macro avg       0.85      0.85      0.85        69\n'
         'weighted avg       0.86      0.86      0.86        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        25\n'
          '           1       1.00      0.93      0.96        27\n'
          '           2       0.93      1.00      0.97        28\n'
          '\n'
          '    accuracy                           0.97        80\n'
          '   macro avg       0.98      0.98      0.98        80\n'
          'weighted avg       0.98      0.97      0.97        80\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
102
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       1.00      0.95      0.97        20\n'
         '           2       0.91      1.00      0.95        10\n'
         '\n'
         '    accuracy                           0.98        47\n'
         '   macro avg       0.97      0.98      0.98        47\n'
         'weighted avg       0.98      0.98      0.98        47\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       1.00      0.97      0.98        30\n'
          '           2       0.98      1.00      0.99        40\n'
          '\n'
          '    accuracy                           0.99       102\n'
          '   macro avg       0.99      0.99      0.99       102\n'
          'weighted avg       0.99      0.99      0.99       102\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
83
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       0.87      0.95      0.91        21\n'
         '           2       0.95      0.88      0.91        24\n'
         '\n'
         '    accuracy                           0.94        66\n'
         '   macro avg       0.94      0.94      0.94        66\n'
         'weighted avg       0.94      0.94      0.94        66\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       1.00      0.93      0.96        29\n'
          '           2       0.93      1.00      0.96        26\n'
          '\n'
          '    accuracy                           0.98        83\n'
          '   macro avg       0.98      0.98      0.98        83\n'
          'weighted avg       0.98      0.98      0.98        83\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
79
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        23\n'
         '           1       1.00      1.00      1.00        23\n'
         '           2       1.00      1.00      1.00        24\n'
         '\n'
         '    accuracy                           1.00        70\n'
         '   macro avg       1.00      1.00      1.00        70\n'
         'weighted avg       1.00      1.00      1.00        70\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        26\n'
          '           1       1.00      1.00      1.00        27\n'
          '           2       1.00      1.00      1.00        26\n'
          '\n'
          '    accuracy                           1.00        79\n'
          '   macro avg       1.00      1.00      1.00        79\n'
          'weighted avg       1.00      1.00      1.00        79\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
84
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       1.00      0.83      0.91        24\n'
         '           2       0.83      1.00      0.91        20\n'
         '\n'
         '    accuracy                           0.94        65\n'
         '   macro avg       0.94      0.94      0.94        65\n'
         'weighted avg       0.95      0.94      0.94        65\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       1.00      0.96      0.98        26\n'
          '           2       0.97      1.00      0.98        30\n'
          '\n'
          '    accuracy                           0.99        84\n'
          '   macro avg       0.99      0.99      0.99        84\n'
          'weighted avg       0.99      0.99      0.99        84\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
83
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        20\n'
         '           1       0.96      0.88      0.92        25\n'
         '           2       0.87      0.95      0.91        21\n'
         '\n'
         '    accuracy                           0.94        66\n'
         '   macro avg       0.94      0.94      0.94        66\n'
         'weighted avg       0.94      0.94      0.94        66\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        29\n'
          '           1       1.00      0.92      0.96        25\n'
          '           2       0.94      1.00      0.97        29\n'
          '\n'
          '    accuracy                           0.98        83\n'
          '   macro avg       0.98      0.97      0.97        83\n'
          'weighted avg       0.98      0.98      0.98        83\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
118
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       1.00      0.80      0.89        10\n'
         '           2       0.82      1.00      0.90         9\n'
         '\n'
         '    accuracy                           0.94        31\n'
         '   macro avg       0.94      0.93      0.93        31\n'
         'weighted avg       0.95      0.94      0.94        31\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       0.95      0.90      0.92        40\n'
          '           2       0.91      0.95      0.93        41\n'
          '\n'
          '    accuracy                           0.95       118\n'
          '   macro avg       0.95      0.95      0.95       118\n'
          'weighted avg       0.95      0.95      0.95       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
114
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       1.00      1.00      1.00        13\n'
         '           2       1.00      1.00      1.00         9\n'
         '\n'
         '    accuracy                           1.00        35\n'
         '   macro avg       1.00      1.00      1.00        35\n'
         'weighted avg       1.00      1.00      1.00        35\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       1.00      0.92      0.96        37\n'
          '           2       0.93      1.00      0.96        41\n'
          '\n'
          '    accuracy                           0.97       114\n'
          '   macro avg       0.98      0.97      0.97       114\n'
          'weighted avg       0.98      0.97      0.97       114\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
104
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       0.94      0.94      0.94        16\n'
         '           2       0.95      0.95      0.95        19\n'
         '\n'
         '    accuracy                           0.96        45\n'
         '   macro avg       0.96      0.96      0.96        45\n'
         'weighted avg       0.96      0.96      0.96        45\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       0.91      0.94      0.93        34\n'
          '           2       0.93      0.90      0.92        31\n'
          '\n'
          '    accuracy                           0.95       104\n'
          '   macro avg       0.95      0.95      0.95       104\n'
          'weighted avg       0.95      0.95      0.95       104\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
107
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       1.00      0.81      0.90        16\n'
         '           2       0.82      1.00      0.90        14\n'
         '\n'
         '    accuracy                           0.93        42\n'
         '   macro avg       0.94      0.94      0.93        42\n'
         'weighted avg       0.94      0.93      0.93        42\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       1.00      1.00      1.00        34\n'
          '           2       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           1.00       107\n'
          '   macro avg       1.00      1.00      1.00       107\n'
          'weighted avg       1.00      1.00      1.00       107\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
110
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        12\n'
         '           1       1.00      0.93      0.97        15\n'
         '           2       0.92      1.00      0.96        12\n'
         '\n'
         '    accuracy                           0.97        39\n'
         '   macro avg       0.97      0.98      0.98        39\n'
         'weighted avg       0.98      0.97      0.97        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       1.00      1.00      1.00        35\n'
          '           2       1.00      1.00      1.00        38\n'
          '\n'
          '    accuracy                           1.00       110\n'
          '   macro avg       1.00      1.00      1.00       110\n'
          'weighted avg       1.00      1.00      1.00       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
115
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         9\n'
         '           1       0.82      0.90      0.86        10\n'
         '           2       0.93      0.87      0.90        15\n'
         '\n'
         '    accuracy                           0.91        34\n'
         '   macro avg       0.92      0.92      0.92        34\n'
         'weighted avg       0.92      0.91      0.91        34\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        40\n'
          '           1       0.93      0.97      0.95        40\n'
          '           2       0.97      0.91      0.94        35\n'
          '\n'
          '    accuracy                           0.97       115\n'
          '   macro avg       0.97      0.96      0.96       115\n'
          'weighted avg       0.97      0.97      0.97       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
85
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       0.88      0.95      0.91        22\n'
         '           2       0.95      0.86      0.90        21\n'
         '\n'
         '    accuracy                           0.94        64\n'
         '   macro avg       0.94      0.94      0.94        64\n'
         'weighted avg       0.94      0.94      0.94        64\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       0.96      0.89      0.93        28\n'
          '           2       0.90      0.97      0.93        29\n'
          '\n'
          '    accuracy                           0.95        85\n'
          '   macro avg       0.95      0.95      0.95        85\n'
          'weighted avg       0.95      0.95      0.95        85\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
91
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        18\n'
         '           1       0.94      0.88      0.91        17\n'
         '           2       0.92      0.96      0.94        23\n'
         '\n'
         '    accuracy                           0.95        58\n'
         '   macro avg       0.95      0.95      0.95        58\n'
         'weighted avg       0.95      0.95      0.95        58\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       1.00      0.94      0.97        33\n'
          '           2       0.93      1.00      0.96        27\n'
          '\n'
          '    accuracy                           0.98        91\n'
          '   macro avg       0.98      0.98      0.98        91\n'
          'weighted avg       0.98      0.98      0.98        91\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
104
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       0.94      0.84      0.89        19\n'
         '           2       0.79      0.92      0.85        12\n'
         '\n'
         '    accuracy                           0.91        45\n'
         '   macro avg       0.91      0.92      0.91        45\n'
         'weighted avg       0.92      0.91      0.91        45\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       0.94      0.97      0.95        31\n'
          '           2       0.97      0.95      0.96        38\n'
          '\n'
          '    accuracy                           0.97       104\n'
          '   macro avg       0.97      0.97      0.97       104\n'
          'weighted avg       0.97      0.97      0.97       104\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
97
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        16\n'
         '           1       0.95      1.00      0.98        20\n'
         '           2       1.00      0.94      0.97        16\n'
         '\n'
         '    accuracy                           0.98        52\n'
         '   macro avg       0.98      0.98      0.98        52\n'
         'weighted avg       0.98      0.98      0.98        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       1.00      1.00      1.00        30\n'
          '           2       1.00      1.00      1.00        34\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
113
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       0.80      1.00      0.89         8\n'
         '           2       1.00      0.89      0.94        18\n'
         '\n'
         '    accuracy                           0.94        36\n'
         '   macro avg       0.93      0.96      0.94        36\n'
         'weighted avg       0.96      0.94      0.95        36\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       1.00      1.00      1.00        42\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           1.00       113\n'
          '   macro avg       1.00      1.00      1.00       113\n'
          'weighted avg       1.00      1.00      1.00       113\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
82
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       0.92      0.92      0.92        25\n'
         '           2       0.90      0.90      0.90        21\n'
         '\n'
         '    accuracy                           0.94        67\n'
         '   macro avg       0.94      0.94      0.94        67\n'
         'weighted avg       0.94      0.94      0.94        67\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       0.96      0.96      0.96        25\n'
          '           2       0.97      0.97      0.97        29\n'
          '\n'
          '    accuracy                           0.98        82\n'
          '   macro avg       0.98      0.98      0.98        82\n'
          'weighted avg       0.98      0.98      0.98        82\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        16\n'
         '           1       0.92      0.80      0.86        15\n'
         '           2       0.88      0.95      0.91        22\n'
         '\n'
         '    accuracy                           0.92        53\n'
         '   macro avg       0.93      0.92      0.92        53\n'
         'weighted avg       0.93      0.92      0.92        53\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       0.94      0.91      0.93        35\n'
          '           2       0.90      0.93      0.91        28\n'
          '\n'
          '    accuracy                           0.95        96\n'
          '   macro avg       0.95      0.95      0.95        96\n'
          'weighted avg       0.95      0.95      0.95        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
92
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        20\n'
         '           1       1.00      0.94      0.97        16\n'
         '           2       0.95      1.00      0.98        21\n'
         '\n'
         '    accuracy                           0.98        57\n'
         '   macro avg       0.98      0.98      0.98        57\n'
         'weighted avg       0.98      0.98      0.98        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        29\n'
          '           1       1.00      0.94      0.97        34\n'
          '           2       0.94      1.00      0.97        29\n'
          '\n'
          '    accuracy                           0.98        92\n'
          '   macro avg       0.98      0.98      0.98        92\n'
          'weighted avg       0.98      0.98      0.98        92\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
111
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       1.00      0.75      0.86        12\n'
         '           2       0.80      1.00      0.89        12\n'
         '\n'
         '    accuracy                           0.92        38\n'
         '   macro avg       0.93      0.92      0.92        38\n'
         'weighted avg       0.94      0.92      0.92        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       0.93      0.97      0.95        38\n'
          '           2       0.97      0.92      0.95        38\n'
          '\n'
          '    accuracy                           0.96       111\n'
          '   macro avg       0.97      0.96      0.96       111\n'
          'weighted avg       0.96      0.96      0.96       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
78
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        23\n'
         '           1       1.00      0.96      0.98        25\n'
         '           2       0.96      1.00      0.98        23\n'
         '\n'
         '    accuracy                           0.99        71\n'
         '   macro avg       0.99      0.99      0.99        71\n'
         'weighted avg       0.99      0.99      0.99        71\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        26\n'
          '           1       0.96      1.00      0.98        25\n'
          '           2       1.00      0.96      0.98        27\n'
          '\n'
          '    accuracy                           0.99        78\n'
          '   macro avg       0.99      0.99      0.99        78\n'
          'weighted avg       0.99      0.99      0.99        78\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       0.78      0.93      0.85        15\n'
         '           2       0.94      0.81      0.87        21\n'
         '\n'
         '    accuracy                           0.91        53\n'
         '   macro avg       0.91      0.91      0.91        53\n'
         'weighted avg       0.92      0.91      0.91        53\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       1.00      1.00      1.00        35\n'
          '           2       1.00      1.00      1.00        29\n'
          '\n'
          '    accuracy                           1.00        96\n'
          '   macro avg       1.00      1.00      1.00        96\n'
          'weighted avg       1.00      1.00      1.00        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
99
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       0.89      1.00      0.94        17\n'
         '           2       1.00      0.88      0.93        16\n'
         '\n'
         '    accuracy                           0.96        50\n'
         '   macro avg       0.96      0.96      0.96        50\n'
         'weighted avg       0.96      0.96      0.96        50\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       0.89      0.97      0.93        33\n'
          '           2       0.97      0.88      0.92        34\n'
          '\n'
          '    accuracy                           0.95        99\n'
          '   macro avg       0.95      0.95      0.95        99\n'
          'weighted avg       0.95      0.95      0.95        99\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
76
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        27\n'
         '           1       1.00      0.92      0.96        25\n'
         '           2       0.91      1.00      0.95        21\n'
         '\n'
         '    accuracy                           0.97        73\n'
         '   macro avg       0.97      0.97      0.97        73\n'
         'weighted avg       0.97      0.97      0.97        73\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        22\n'
          '           1       0.91      0.84      0.87        25\n'
          '           2       0.87      0.93      0.90        29\n'
          '\n'
          '    accuracy                           0.92        76\n'
          '   macro avg       0.93      0.92      0.92        76\n'
          'weighted avg       0.92      0.92      0.92        76\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
80
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        19\n'
         '           1       0.96      1.00      0.98        26\n'
         '           2       1.00      0.96      0.98        24\n'
         '\n'
         '    accuracy                           0.99        69\n'
         '   macro avg       0.99      0.99      0.99        69\n'
         'weighted avg       0.99      0.99      0.99        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       0.96      0.96      0.96        24\n'
          '           2       0.96      0.96      0.96        26\n'
          '\n'
          '    accuracy                           0.97        80\n'
          '   macro avg       0.97      0.97      0.97        80\n'
          'weighted avg       0.97      0.97      0.97        80\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
114
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         8\n'
         '           1       1.00      0.86      0.92        14\n'
         '           2       0.87      1.00      0.93        13\n'
         '\n'
         '    accuracy                           0.94        35\n'
         '   macro avg       0.96      0.95      0.95        35\n'
         'weighted avg       0.95      0.94      0.94        35\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        41\n'
          '           1       0.92      0.94      0.93        36\n'
          '           2       0.94      0.92      0.93        37\n'
          '\n'
          '    accuracy                           0.96       114\n'
          '   macro avg       0.95      0.95      0.95       114\n'
          'weighted avg       0.96      0.96      0.96       114\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
108
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       0.94      1.00      0.97        16\n'
         '           2       1.00      0.92      0.96        12\n'
         '\n'
         '    accuracy                           0.98        41\n'
         '   macro avg       0.98      0.97      0.98        41\n'
         'weighted avg       0.98      0.98      0.98        41\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       0.97      0.94      0.96        34\n'
          '           2       0.95      0.97      0.96        38\n'
          '\n'
          '    accuracy                           0.97       108\n'
          '   macro avg       0.97      0.97      0.97       108\n'
          'weighted avg       0.97      0.97      0.97       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
89
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        23\n'
         '           1       0.95      1.00      0.97        19\n'
         '           2       1.00      0.94      0.97        18\n'
         '\n'
         '    accuracy                           0.98        60\n'
         '   macro avg       0.98      0.98      0.98        60\n'
         'weighted avg       0.98      0.98      0.98        60\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        26\n'
          '           1       1.00      1.00      1.00        31\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           1.00        89\n'
          '   macro avg       1.00      1.00      1.00        89\n'
          'weighted avg       1.00      1.00      1.00        89\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
80
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        25\n'
         '           1       0.95      0.86      0.90        22\n'
         '           2       0.88      0.95      0.91        22\n'
         '\n'
         '    accuracy                           0.94        69\n'
         '   macro avg       0.94      0.94      0.94        69\n'
         'weighted avg       0.94      0.94      0.94        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        24\n'
          '           1       0.96      0.93      0.95        28\n'
          '           2       0.93      0.96      0.95        28\n'
          '\n'
          '    accuracy                           0.96        80\n'
          '   macro avg       0.96      0.96      0.96        80\n'
          'weighted avg       0.96      0.96      0.96        80\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
118
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         8\n'
         '           1       1.00      0.92      0.96        13\n'
         '           2       0.91      1.00      0.95        10\n'
         '\n'
         '    accuracy                           0.97        31\n'
         '   macro avg       0.97      0.97      0.97        31\n'
         'weighted avg       0.97      0.97      0.97        31\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        41\n'
          '           1       0.94      0.86      0.90        37\n'
          '           2       0.88      0.95      0.92        40\n'
          '\n'
          '    accuracy                           0.94       118\n'
          '   macro avg       0.94      0.94      0.94       118\n'
          'weighted avg       0.94      0.94      0.94       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
75
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        24\n'
         '           1       0.96      0.93      0.95        29\n'
         '           2       0.91      0.95      0.93        21\n'
         '\n'
         '    accuracy                           0.96        74\n'
         '   macro avg       0.96      0.96      0.96        74\n'
         'weighted avg       0.96      0.96      0.96        74\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        25\n'
          '           1       1.00      0.95      0.98        21\n'
          '           2       0.97      1.00      0.98        29\n'
          '\n'
          '    accuracy                           0.99        75\n'
          '   macro avg       0.99      0.98      0.99        75\n'
          'weighted avg       0.99      0.99      0.99        75\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
77
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        24\n'
         '           1       1.00      0.89      0.94        27\n'
         '           2       0.88      1.00      0.93        21\n'
         '\n'
         '    accuracy                           0.96        72\n'
         '   macro avg       0.96      0.96      0.96        72\n'
         'weighted avg       0.96      0.96      0.96        72\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        25\n'
          '           1       0.85      0.96      0.90        23\n'
          '           2       0.96      0.86      0.91        29\n'
          '\n'
          '    accuracy                           0.94        77\n'
          '   macro avg       0.94      0.94      0.94        77\n'
          'weighted avg       0.94      0.94      0.94        77\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
100
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       1.00      0.87      0.93        15\n'
         '           2       0.89      1.00      0.94        17\n'
         '\n'
         '    accuracy                           0.96        49\n'
         '   macro avg       0.96      0.96      0.96        49\n'
         'weighted avg       0.96      0.96      0.96        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       1.00      1.00      1.00        35\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           1.00       100\n'
          '   macro avg       1.00      1.00      1.00       100\n'
          'weighted avg       1.00      1.00      1.00       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        17\n'
         '           1       1.00      0.75      0.86        16\n'
         '           2       0.83      1.00      0.90        19\n'
         '\n'
         '    accuracy                           0.92        52\n'
         '   macro avg       0.94      0.92      0.92        52\n'
         'weighted avg       0.94      0.92      0.92        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       0.97      1.00      0.99        34\n'
          '           2       1.00      0.97      0.98        31\n'
          '\n'
          '    accuracy                           0.99        97\n'
          '   macro avg       0.99      0.99      0.99        97\n'
          'weighted avg       0.99      0.99      0.99        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
117
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       0.79      1.00      0.88        11\n'
         '           2       1.00      0.73      0.84        11\n'
         '\n'
         '    accuracy                           0.91        32\n'
         '   macro avg       0.93      0.91      0.91        32\n'
         'weighted avg       0.93      0.91      0.90        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       0.95      0.95      0.95        39\n'
          '           2       0.95      0.95      0.95        39\n'
          '\n'
          '    accuracy                           0.97       117\n'
          '   macro avg       0.97      0.97      0.97       117\n'
          'weighted avg       0.97      0.97      0.97       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
117
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         6\n'
         '           1       1.00      0.80      0.89        15\n'
         '           2       0.79      1.00      0.88        11\n'
         '\n'
         '    accuracy                           0.91        32\n'
         '   macro avg       0.93      0.93      0.92        32\n'
         'weighted avg       0.93      0.91      0.91        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        43\n'
          '           1       0.94      0.89      0.91        35\n'
          '           2       0.90      0.95      0.92        39\n'
          '\n'
          '    accuracy                           0.95       117\n'
          '   macro avg       0.95      0.94      0.95       117\n'
          'weighted avg       0.95      0.95      0.95       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
79
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        26\n'
         '           1       0.91      0.95      0.93        21\n'
         '           2       0.95      0.91      0.93        23\n'
         '\n'
         '    accuracy                           0.96        70\n'
         '   macro avg       0.95      0.96      0.95        70\n'
         'weighted avg       0.96      0.96      0.96        70\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        23\n'
          '           1       0.97      1.00      0.98        29\n'
          '           2       1.00      0.96      0.98        27\n'
          '\n'
          '    accuracy                           0.99        79\n'
          '   macro avg       0.99      0.99      0.99        79\n'
          'weighted avg       0.99      0.99      0.99        79\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
90
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        24\n'
         '           1       0.94      0.89      0.91        18\n'
         '           2       0.89      0.94      0.91        17\n'
         '\n'
         '    accuracy                           0.95        59\n'
         '   macro avg       0.94      0.94      0.94        59\n'
         'weighted avg       0.95      0.95      0.95        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        25\n'
          '           1       0.94      0.97      0.95        32\n'
          '           2       0.97      0.94      0.95        33\n'
          '\n'
          '    accuracy                           0.97        90\n'
          '   macro avg       0.97      0.97      0.97        90\n'
          'weighted avg       0.97      0.97      0.97        90\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
115
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        11\n'
         '           1       0.89      0.80      0.84        10\n'
         '           2       0.86      0.92      0.89        13\n'
         '\n'
         '    accuracy                           0.91        34\n'
         '   macro avg       0.92      0.91      0.91        34\n'
         'weighted avg       0.91      0.91      0.91        34\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        38\n'
          '           1       0.97      0.97      0.97        40\n'
          '           2       0.97      0.97      0.97        37\n'
          '\n'
          '    accuracy                           0.98       115\n'
          '   macro avg       0.98      0.98      0.98       115\n'
          'weighted avg       0.98      0.98      0.98       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
116
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00         6\n'
         '           1       1.00      1.00      1.00        14\n'
         '           2       1.00      1.00      1.00        13\n'
         '\n'
         '    accuracy                           1.00        33\n'
         '   macro avg       1.00      1.00      1.00        33\n'
         'weighted avg       1.00      1.00      1.00        33\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        43\n'
          '           1       1.00      1.00      1.00        36\n'
          '           2       1.00      1.00      1.00        37\n'
          '\n'
          '    accuracy                           1.00       116\n'
          '   macro avg       1.00      1.00      1.00       116\n'
          'weighted avg       1.00      1.00      1.00       116\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='iris', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
86
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        21\n'
         '           1       0.96      1.00      0.98        23\n'
         '           2       1.00      0.95      0.97        19\n'
         '\n'
         '    accuracy                           0.98        63\n'
         '   macro avg       0.99      0.98      0.98        63\n'
         'weighted avg       0.98      0.98      0.98        63\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       0.92      0.85      0.88        27\n'
          '           2       0.88      0.94      0.91        31\n'
          '\n'
          '    accuracy                           0.93        86\n'
          '   macro avg       0.93      0.93      0.93        86\n'
          'weighted avg       0.93      0.93      0.93        86\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
171
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00         6\n'
         '\n'
         '    accuracy                           1.00         6\n'
         '   macro avg       1.00      1.00      1.00         6\n'
         'weighted avg       1.00      1.00      1.00         6\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.94      0.97        52\n'
          '         1.0       0.95      0.97      0.96        71\n'
          '         2.0       0.96      0.98      0.97        48\n'
          '\n'
          '    accuracy                           0.96       171\n'
          '   macro avg       0.97      0.96      0.97       171\n'
          'weighted avg       0.97      0.96      0.96       171\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        45\n'
         '         1.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.02        46\n'
         '   macro avg       0.01      0.50      0.02        46\n'
         'weighted avg       0.00      0.02      0.00        46\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.92      0.96        13\n'
          '         1.0       0.99      0.99      0.99        70\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.98       131\n'
          '   macro avg       0.99      0.97      0.98       131\n'
          'weighted avg       0.98      0.98      0.98       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.08      1.00      0.15         9\n'
         '         1.0       0.88      0.10      0.19        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.13       123\n'
         '   macro avg       0.32      0.37      0.11       123\n'
         'weighted avg       0.48      0.13      0.11       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.50      0.25      0.33         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.93        54\n'
          '   macro avg       0.48      0.42      0.43        54\n'
          'weighted avg       0.89      0.93      0.91        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
154
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.91      0.95        22\n'
         '         2.0       1.00      1.00      1.00         1\n'
         '\n'
         '    accuracy                           0.91        23\n'
         '   macro avg       0.67      0.64      0.65        23\n'
         'weighted avg       1.00      0.91      0.95        23\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.98      1.00      0.99        58\n'
          '         1.0       1.00      1.00      1.00        49\n'
          '         2.0       1.00      0.98      0.99        47\n'
          '\n'
          '    accuracy                           0.99       154\n'
          '   macro avg       0.99      0.99      0.99       154\n'
          'weighted avg       0.99      0.99      0.99       154\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.91      1.00      0.95        49\n'
          '         1.0       0.00      0.00      0.00         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.91        54\n'
          '   macro avg       0.30      0.33      0.32        54\n'
          'weighted avg       0.82      0.91      0.86        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        45\n'
         '         1.0       1.00      1.00      1.00         1\n'
         '\n'
         '    accuracy                           1.00        46\n'
         '   macro avg       1.00      1.00      1.00        46\n'
         'weighted avg       1.00      1.00      1.00        46\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.77      0.87        13\n'
          '         1.0       0.94      0.97      0.96        70\n'
          '         2.0       0.96      0.98      0.97        48\n'
          '\n'
          '    accuracy                           0.95       131\n'
          '   macro avg       0.97      0.91      0.93       131\n'
          'weighted avg       0.96      0.95      0.95       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.91      1.00      0.95        49\n'
          '         1.0       0.00      0.00      0.00         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.91        54\n'
          '   macro avg       0.30      0.33      0.32        54\n'
          'weighted avg       0.82      0.91      0.86        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.08      1.00      0.15         9\n'
         '         1.0       0.88      0.10      0.19        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.13       123\n'
         '   macro avg       0.32      0.37      0.11       123\n'
         'weighted avg       0.48      0.13      0.11       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
108
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00        50\n'
         '         2.0       0.28      1.00      0.43        19\n'
         '\n'
         '    accuracy                           0.28        69\n'
         '   macro avg       0.14      0.50      0.22        69\n'
         'weighted avg       0.08      0.28      0.12        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.85      0.95      0.89        58\n'
          '         1.0       0.80      0.38      0.52        21\n'
          '         2.0       0.73      0.83      0.77        29\n'
          '\n'
          '    accuracy                           0.81       108\n'
          '   macro avg       0.79      0.72      0.73       108\n'
          'weighted avg       0.81      0.81      0.79       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
115
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.50      0.62      0.55        13\n'
         '         1.0       0.59      0.85      0.69        20\n'
         '         2.0       1.00      0.59      0.74        29\n'
         '\n'
         '    accuracy                           0.68        62\n'
         '   macro avg       0.70      0.68      0.66        62\n'
         'weighted avg       0.76      0.68      0.69        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        45\n'
          '         1.0       0.98      1.00      0.99        51\n'
          '         2.0       1.00      0.95      0.97        19\n'
          '\n'
          '    accuracy                           0.99       115\n'
          '   macro avg       0.99      0.98      0.99       115\n'
          'weighted avg       0.99      0.99      0.99       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
154
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        23\n'
         '\n'
         '    accuracy                           1.00        23\n'
         '   macro avg       1.00      1.00      1.00        23\n'
         'weighted avg       1.00      1.00      1.00        23\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.97      1.00      0.99        35\n'
          '         1.0       1.00      0.97      0.99        71\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.99       154\n'
          '   macro avg       0.98      0.99      0.99       154\n'
          'weighted avg       0.99      0.99      0.99       154\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
160
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        17\n'
         '\n'
         '    accuracy                           1.00        17\n'
         '   macro avg       1.00      1.00      1.00        17\n'
         'weighted avg       1.00      1.00      1.00        17\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.95      0.97        41\n'
          '         1.0       0.96      0.99      0.97        71\n'
          '         2.0       0.98      0.98      0.98        48\n'
          '\n'
          '    accuracy                           0.97       160\n'
          '   macro avg       0.98      0.97      0.98       160\n'
          'weighted avg       0.98      0.97      0.98       160\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.04      0.50      0.08         4\n'
         '         2.0       0.20      1.00      0.33         1\n'
         '\n'
         '    accuracy                           0.06        54\n'
         '   macro avg       0.08      0.50      0.14        54\n'
         'weighted avg       0.01      0.06      0.01        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.89      0.94         9\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        47\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.99      0.96      0.97       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.08      1.00      0.15         9\n'
         '         1.0       0.88      0.10      0.19        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.13       123\n'
         '   macro avg       0.32      0.37      0.11       123\n'
         'weighted avg       0.48      0.13      0.11       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
120
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         6\n'
         '         1.0       0.00      0.00      0.00        22\n'
         '         2.0       0.51      1.00      0.67        29\n'
         '\n'
         '    accuracy                           0.51        57\n'
         '   macro avg       0.17      0.33      0.22        57\n'
         'weighted avg       0.26      0.51      0.34        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.89      0.94      0.92        52\n'
          '         1.0       0.90      0.88      0.89        49\n'
          '         2.0       0.71      0.63      0.67        19\n'
          '\n'
          '    accuracy                           0.87       120\n'
          '   macro avg       0.83      0.82      0.82       120\n'
          'weighted avg       0.86      0.87      0.86       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
147
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.80      0.89         5\n'
         '         1.0       0.85      1.00      0.92        11\n'
         '         2.0       1.00      0.93      0.96        14\n'
         '\n'
         '    accuracy                           0.93        30\n'
         '   macro avg       0.95      0.91      0.92        30\n'
         'weighted avg       0.94      0.93      0.93        30\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        53\n'
          '         1.0       1.00      1.00      1.00        60\n'
          '         2.0       1.00      1.00      1.00        34\n'
          '\n'
          '    accuracy                           1.00       147\n'
          '   macro avg       1.00      1.00      1.00       147\n'
          'weighted avg       1.00      1.00      1.00       147\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
146
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.96      1.00      0.98        26\n'
         '         1.0       1.00      0.75      0.86         4\n'
         '         2.0       1.00      1.00      1.00         1\n'
         '\n'
         '    accuracy                           0.97        31\n'
         '   macro avg       0.99      0.92      0.95        31\n'
         'weighted avg       0.97      0.97      0.97        31\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        32\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           1.00       146\n'
          '   macro avg       1.00      1.00      1.00       146\n'
          'weighted avg       1.00      1.00      1.00       146\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
118
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.93      0.97        45\n'
         '         2.0       0.82      1.00      0.90        14\n'
         '\n'
         '    accuracy                           0.95        59\n'
         '   macro avg       0.91      0.97      0.93        59\n'
         'weighted avg       0.96      0.95      0.95        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        58\n'
          '         1.0       0.93      1.00      0.96        26\n'
          '         2.0       1.00      1.00      1.00        34\n'
          '\n'
          '    accuracy                           0.98       118\n'
          '   macro avg       0.98      0.99      0.98       118\n'
          'weighted avg       0.98      0.98      0.98       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.04      0.50      0.08         4\n'
         '         2.0       0.20      1.00      0.33         1\n'
         '\n'
         '    accuracy                           0.06        54\n'
         '   macro avg       0.08      0.50      0.14        54\n'
         'weighted avg       0.01      0.06      0.01        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.89      0.94         9\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        47\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.99      0.96      0.97       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.94      0.35      0.51        49\n'
         '         1.0       0.06      0.50      0.11         4\n'
         '         2.0       0.50      1.00      0.67         1\n'
         '\n'
         '    accuracy                           0.37        54\n'
         '   macro avg       0.50      0.62      0.43        54\n'
         'weighted avg       0.87      0.37      0.48        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        47\n'
          '\n'
          '    accuracy                           0.99       123\n'
          '   macro avg       0.99      1.00      0.99       123\n'
          'weighted avg       0.99      0.99      0.99       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.60      0.06      0.11        49\n'
         '         1.0       0.00      0.00      0.00         4\n'
         '         2.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.07        54\n'
         '   macro avg       0.21      0.35      0.05        54\n'
         'weighted avg       0.54      0.07      0.10        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           1.00       123\n'
          '   macro avg       1.00      1.00      1.00       123\n'
          'weighted avg       1.00      1.00      1.00       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
118
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.71      0.83      0.77         6\n'
         '         1.0       0.91      0.91      0.91        22\n'
         '         2.0       1.00      0.97      0.98        31\n'
         '\n'
         '    accuracy                           0.93        59\n'
         '   macro avg       0.87      0.90      0.89        59\n'
         'weighted avg       0.94      0.93      0.93        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        52\n'
          '         1.0       1.00      1.00      1.00        49\n'
          '         2.0       1.00      1.00      1.00        17\n'
          '\n'
          '    accuracy                           1.00       118\n'
          '   macro avg       1.00      1.00      1.00       118\n'
          'weighted avg       1.00      1.00      1.00       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
152
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        25\n'
         '\n'
         '    accuracy                           1.00        25\n'
         '   macro avg       1.00      1.00      1.00        25\n'
         'weighted avg       1.00      1.00      1.00        25\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.97      0.97      0.97        33\n'
          '         1.0       0.99      0.99      0.99        71\n'
          '         2.0       1.00      1.00      1.00        48\n'
          '\n'
          '    accuracy                           0.99       152\n'
          '   macro avg       0.99      0.99      0.99       152\n'
          'weighted avg       0.99      0.99      0.99       152\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.50      0.33      0.40         9\n'
         '         1.0       0.64      0.24      0.35        67\n'
         '         2.0       0.45      0.87      0.59        47\n'
         '\n'
         '    accuracy                           0.49       123\n'
         '   macro avg       0.53      0.48      0.45       123\n'
         'weighted avg       0.56      0.49      0.44       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
151
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.56      0.83      0.67        12\n'
         '         1.0       0.50      0.40      0.44         5\n'
         '         2.0       0.75      0.33      0.46         9\n'
         '\n'
         '    accuracy                           0.58        26\n'
         '   macro avg       0.60      0.52      0.52        26\n'
         'weighted avg       0.61      0.58      0.55        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        46\n'
          '         1.0       0.98      0.98      0.98        66\n'
          '         2.0       0.97      1.00      0.99        39\n'
          '\n'
          '    accuracy                           0.99       151\n'
          '   macro avg       0.99      0.99      0.99       151\n'
          'weighted avg       0.99      0.99      0.99       151\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
139
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.97      0.98        29\n'
         '         1.0       0.80      1.00      0.89         4\n'
         '         2.0       1.00      1.00      1.00         5\n'
         '\n'
         '    accuracy                           0.97        38\n'
         '   macro avg       0.93      0.99      0.96        38\n'
         'weighted avg       0.98      0.97      0.97        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        29\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        43\n'
          '\n'
          '    accuracy                           0.99       139\n'
          '   macro avg       0.99      0.98      0.99       139\n'
          'weighted avg       0.99      0.99      0.99       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.60      0.06      0.11        49\n'
         '         1.0       0.00      0.00      0.00         4\n'
         '         2.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.07        54\n'
         '   macro avg       0.21      0.35      0.05        54\n'
         'weighted avg       0.54      0.07      0.10        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           1.00       123\n'
          '   macro avg       1.00      1.00      1.00       123\n'
          'weighted avg       1.00      1.00      1.00       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
115
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.50      0.62      0.55        13\n'
         '         1.0       0.59      0.85      0.69        20\n'
         '         2.0       1.00      0.59      0.74        29\n'
         '\n'
         '    accuracy                           0.68        62\n'
         '   macro avg       0.70      0.68      0.66        62\n'
         'weighted avg       0.76      0.68      0.69        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        45\n'
          '         1.0       0.98      1.00      0.99        51\n'
          '         2.0       1.00      0.95      0.97        19\n'
          '\n'
          '    accuracy                           0.99       115\n'
          '   macro avg       0.99      0.98      0.99       115\n'
          'weighted avg       0.99      0.99      0.99       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.89      0.94        45\n'
         '         1.0       0.17      1.00      0.29         1\n'
         '\n'
         '    accuracy                           0.89        46\n'
         '   macro avg       0.58      0.94      0.61        46\n'
         'weighted avg       0.98      0.89      0.93        46\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.85      0.92        13\n'
          '         1.0       0.97      0.99      0.98        70\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.98       131\n'
          '   macro avg       0.98      0.94      0.96       131\n'
          'weighted avg       0.98      0.98      0.98       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
115
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.62      0.38      0.48        13\n'
         '         1.0       0.67      0.90      0.77        20\n'
         '         2.0       1.00      0.93      0.96        29\n'
         '\n'
         '    accuracy                           0.81        62\n'
         '   macro avg       0.76      0.74      0.74        62\n'
         'weighted avg       0.81      0.81      0.80        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        45\n'
          '         1.0       1.00      1.00      1.00        51\n'
          '         2.0       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00       115\n'
          '   macro avg       1.00      1.00      1.00       115\n'
          'weighted avg       1.00      1.00      1.00       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
167
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        10\n'
         '\n'
         '    accuracy                           1.00        10\n'
         '   macro avg       1.00      1.00      1.00        10\n'
         'weighted avg       1.00      1.00      1.00        10\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        48\n'
          '         1.0       0.99      0.99      0.99        71\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.99       167\n'
          '   macro avg       0.99      0.99      0.99       167\n'
          'weighted avg       0.99      0.99      0.99       167\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
161
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.94      1.00      0.97        15\n'
         '         1.0       0.00      0.00      0.00         1\n'
         '\n'
         '    accuracy                           0.94        16\n'
         '   macro avg       0.47      0.50      0.48        16\n'
         'weighted avg       0.88      0.94      0.91        16\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.95      0.98        43\n'
          '         1.0       0.97      0.97      0.97        70\n'
          '         2.0       0.96      1.00      0.98        48\n'
          '\n'
          '    accuracy                           0.98       161\n'
          '   macro avg       0.98      0.97      0.98       161\n'
          'weighted avg       0.98      0.98      0.98       161\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.60      0.06      0.11        49\n'
         '         1.0       0.00      0.00      0.00         4\n'
         '         2.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.07        54\n'
         '   macro avg       0.21      0.35      0.05        54\n'
         'weighted avg       0.54      0.07      0.10        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           1.00       123\n'
          '   macro avg       1.00      1.00      1.00       123\n'
          'weighted avg       1.00      1.00      1.00       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.11      0.78      0.19         9\n'
         '         1.0       0.98      0.76      0.86        67\n'
         '         2.0       0.67      0.09      0.15        47\n'
         '\n'
         '    accuracy                           0.50       123\n'
         '   macro avg       0.59      0.54      0.40       123\n'
         'weighted avg       0.80      0.50      0.54       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.91      1.00      0.95        49\n'
          '         1.0       0.00      0.00      0.00         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.91        54\n'
          '   macro avg       0.30      0.33      0.32        54\n'
          'weighted avg       0.82      0.91      0.86        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.50      0.33      0.40         9\n'
         '         1.0       0.64      0.24      0.35        67\n'
         '         2.0       0.45      0.87      0.59        47\n'
         '\n'
         '    accuracy                           0.49       123\n'
         '   macro avg       0.53      0.48      0.45       123\n'
         'weighted avg       0.56      0.49      0.44       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        45\n'
         '         1.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.02        46\n'
         '   macro avg       0.01      0.50      0.02        46\n'
         'weighted avg       0.00      0.02      0.00        46\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.92      0.96        13\n'
          '         1.0       0.99      0.99      0.99        70\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.98       131\n'
          '   macro avg       0.99      0.97      0.98       131\n'
          'weighted avg       0.98      0.98      0.98       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
163
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        14\n'
         '\n'
         '    accuracy                           1.00        14\n'
         '   macro avg       1.00      1.00      1.00        14\n'
         'weighted avg       1.00      1.00      1.00        14\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        44\n'
          '         1.0       0.99      0.99      0.99        71\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.99       163\n'
          '   macro avg       0.99      0.99      0.99       163\n'
          'weighted avg       0.99      0.99      0.99       163\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.50      0.25      0.33         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.93        54\n'
          '   macro avg       0.48      0.42      0.43        54\n'
          'weighted avg       0.89      0.93      0.91        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
149
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.65      1.00      0.79        11\n'
         '         2.0       1.00      0.65      0.79        17\n'
         '\n'
         '    accuracy                           0.79        28\n'
         '   macro avg       0.82      0.82      0.79        28\n'
         'weighted avg       0.86      0.79      0.79        28\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        58\n'
          '         1.0       1.00      1.00      1.00        60\n'
          '         2.0       1.00      1.00      1.00        31\n'
          '\n'
          '    accuracy                           1.00       149\n'
          '   macro avg       1.00      1.00      1.00       149\n'
          'weighted avg       1.00      1.00      1.00       149\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
171
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00         6\n'
         '\n'
         '    accuracy                           1.00         6\n'
         '   macro avg       1.00      1.00      1.00         6\n'
         'weighted avg       1.00      1.00      1.00         6\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.98      1.00      0.99        52\n'
          '         1.0       1.00      0.97      0.99        71\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.99       171\n'
          '   macro avg       0.99      0.99      0.99       171\n'
          'weighted avg       0.99      0.99      0.99       171\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
157
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        20\n'
         '\n'
         '    accuracy                           1.00        20\n'
         '   macro avg       1.00      1.00      1.00        20\n'
         'weighted avg       1.00      1.00      1.00        20\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.95      0.97        38\n'
          '         1.0       0.96      0.99      0.97        71\n'
          '         2.0       0.98      0.98      0.98        48\n'
          '\n'
          '    accuracy                           0.97       157\n'
          '   macro avg       0.98      0.97      0.97       157\n'
          'weighted avg       0.98      0.97      0.97       157\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
139
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.75      0.10      0.18        29\n'
         '         1.0       0.12      1.00      0.21         4\n'
         '         2.0       0.00      0.00      0.00         5\n'
         '\n'
         '    accuracy                           0.18        38\n'
         '   macro avg       0.29      0.37      0.13        38\n'
         'weighted avg       0.58      0.18      0.16        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        29\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        43\n'
          '\n'
          '    accuracy                           0.99       139\n'
          '   macro avg       0.99      0.98      0.99       139\n'
          'weighted avg       0.99      0.99      0.99       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
129
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         1\n'
         '         1.0       0.95      1.00      0.98        20\n'
         '         2.0       1.00      1.00      1.00        27\n'
         '\n'
         '    accuracy                           0.98        48\n'
         '   macro avg       0.65      0.67      0.66        48\n'
         'weighted avg       0.96      0.98      0.97        48\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        57\n'
          '         1.0       0.98      0.98      0.98        51\n'
          '         2.0       0.95      1.00      0.98        21\n'
          '\n'
          '    accuracy                           0.98       129\n'
          '   macro avg       0.98      0.99      0.98       129\n'
          'weighted avg       0.98      0.98      0.98       129\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.60      0.06      0.11        49\n'
         '         1.0       0.00      0.00      0.00         4\n'
         '         2.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.07        54\n'
         '   macro avg       0.21      0.35      0.05        54\n'
         'weighted avg       0.54      0.07      0.10        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           1.00       123\n'
          '   macro avg       1.00      1.00      1.00       123\n'
          'weighted avg       1.00      1.00      1.00       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.11      0.78      0.19         9\n'
         '         1.0       0.98      0.76      0.86        67\n'
         '         2.0       0.67      0.09      0.15        47\n'
         '\n'
         '    accuracy                           0.50       123\n'
         '   macro avg       0.59      0.54      0.40       123\n'
         'weighted avg       0.80      0.50      0.54       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
171
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00         6\n'
         '\n'
         '    accuracy                           1.00         6\n'
         '   macro avg       1.00      1.00      1.00         6\n'
         'weighted avg       1.00      1.00      1.00         6\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.98      1.00      0.99        52\n'
          '         1.0       1.00      0.97      0.99        71\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.99       171\n'
          '   macro avg       0.99      0.99      0.99       171\n'
          'weighted avg       0.99      0.99      0.99       171\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
136
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.92      0.96        24\n'
         '         2.0       0.89      1.00      0.94        17\n'
         '\n'
         '    accuracy                           0.95        41\n'
         '   macro avg       0.95      0.96      0.95        41\n'
         'weighted avg       0.96      0.95      0.95        41\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        58\n'
          '         1.0       0.94      1.00      0.97        47\n'
          '         2.0       1.00      0.97      0.98        31\n'
          '\n'
          '    accuracy                           0.98       136\n'
          '   macro avg       0.98      0.98      0.98       136\n'
          'weighted avg       0.98      0.98      0.98       136\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.04      0.50      0.08         4\n'
         '         2.0       0.20      1.00      0.33         1\n'
         '\n'
         '    accuracy                           0.06        54\n'
         '   macro avg       0.08      0.50      0.14        54\n'
         'weighted avg       0.01      0.06      0.01        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.89      0.94         9\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        47\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.99      0.96      0.97       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
108
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.86      0.92        50\n'
         '         2.0       0.90      1.00      0.95        19\n'
         '\n'
         '    accuracy                           0.90        69\n'
         '   macro avg       0.63      0.62      0.62        69\n'
         'weighted avg       0.97      0.90      0.93        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        58\n'
          '         1.0       0.95      1.00      0.98        21\n'
          '         2.0       1.00      1.00      1.00        29\n'
          '\n'
          '    accuracy                           0.99       108\n'
          '   macro avg       0.98      0.99      0.99       108\n'
          'weighted avg       0.99      0.99      0.99       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.60      0.06      0.11        49\n'
         '         1.0       0.00      0.00      0.00         4\n'
         '         2.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.07        54\n'
         '   macro avg       0.21      0.35      0.05        54\n'
         'weighted avg       0.54      0.07      0.10        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           1.00       123\n'
          '   macro avg       1.00      1.00      1.00       123\n'
          'weighted avg       1.00      1.00      1.00       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
160
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        17\n'
         '\n'
         '    accuracy                           1.00        17\n'
         '   macro avg       1.00      1.00      1.00        17\n'
         'weighted avg       1.00      1.00      1.00        17\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        41\n'
          '         1.0       1.00      1.00      1.00        71\n'
          '         2.0       1.00      1.00      1.00        48\n'
          '\n'
          '    accuracy                           1.00       160\n'
          '   macro avg       1.00      1.00      1.00       160\n'
          'weighted avg       1.00      1.00      1.00       160\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
151
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.75      0.86        12\n'
         '         1.0       0.57      0.80      0.67         5\n'
         '         2.0       0.90      1.00      0.95         9\n'
         '\n'
         '    accuracy                           0.85        26\n'
         '   macro avg       0.82      0.85      0.82        26\n'
         'weighted avg       0.88      0.85      0.85        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.98      0.98      0.98        46\n'
          '         1.0       0.98      0.97      0.98        66\n'
          '         2.0       0.97      1.00      0.99        39\n'
          '\n'
          '    accuracy                           0.98       151\n'
          '   macro avg       0.98      0.98      0.98       151\n'
          'weighted avg       0.98      0.98      0.98       151\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
120
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.93      0.97        45\n'
         '         2.0       0.80      1.00      0.89        12\n'
         '\n'
         '    accuracy                           0.95        57\n'
         '   macro avg       0.90      0.97      0.93        57\n'
         'weighted avg       0.96      0.95      0.95        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        58\n'
          '         1.0       0.93      1.00      0.96        26\n'
          '         2.0       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           0.98       120\n'
          '   macro avg       0.98      0.99      0.98       120\n'
          'weighted avg       0.98      0.98      0.98       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.91      1.00      0.95        49\n'
          '         1.0       0.00      0.00      0.00         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.91        54\n'
          '   macro avg       0.30      0.33      0.32        54\n'
          'weighted avg       0.82      0.91      0.86        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
171
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00         6\n'
         '\n'
         '    accuracy                           1.00         6\n'
         '   macro avg       1.00      1.00      1.00         6\n'
         'weighted avg       1.00      1.00      1.00         6\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        52\n'
          '         1.0       0.99      0.99      0.99        71\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.99       171\n'
          '   macro avg       0.99      0.99      0.99       171\n'
          'weighted avg       0.99      0.99      0.99       171\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
161
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.33      0.50         6\n'
         '         2.0       0.71      1.00      0.83        10\n'
         '\n'
         '    accuracy                           0.75        16\n'
         '   macro avg       0.86      0.67      0.67        16\n'
         'weighted avg       0.82      0.75      0.71        16\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        58\n'
          '         1.0       1.00      1.00      1.00        65\n'
          '         2.0       1.00      1.00      1.00        38\n'
          '\n'
          '    accuracy                           1.00       161\n'
          '   macro avg       1.00      1.00      1.00       161\n'
          'weighted avg       1.00      1.00      1.00       161\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
160
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        17\n'
         '\n'
         '    accuracy                           1.00        17\n'
         '   macro avg       1.00      1.00      1.00        17\n'
         'weighted avg       1.00      1.00      1.00        17\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        41\n'
          '         1.0       1.00      1.00      1.00        71\n'
          '         2.0       1.00      1.00      1.00        48\n'
          '\n'
          '    accuracy                           1.00       160\n'
          '   macro avg       1.00      1.00      1.00       160\n'
          'weighted avg       1.00      1.00      1.00       160\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
141
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.96      0.96      0.96        27\n'
         '         1.0       0.75      0.75      0.75         4\n'
         '         2.0       1.00      1.00      1.00         5\n'
         '\n'
         '    accuracy                           0.94        36\n'
         '   macro avg       0.90      0.90      0.90        36\n'
         'weighted avg       0.94      0.94      0.94        36\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        31\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        43\n'
          '\n'
          '    accuracy                           1.00       141\n'
          '   macro avg       1.00      1.00      1.00       141\n'
          'weighted avg       1.00      1.00      1.00       141\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
160
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        17\n'
         '\n'
         '    accuracy                           1.00        17\n'
         '   macro avg       1.00      1.00      1.00        17\n'
         'weighted avg       1.00      1.00      1.00        17\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.95      0.97        41\n'
          '         1.0       0.96      0.99      0.97        71\n'
          '         2.0       0.98      0.98      0.98        48\n'
          '\n'
          '    accuracy                           0.97       160\n'
          '   macro avg       0.98      0.97      0.98       160\n'
          'weighted avg       0.98      0.97      0.98       160\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
147
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.56      0.72        16\n'
         '         2.0       0.71      0.36      0.48        14\n'
         '\n'
         '    accuracy                           0.47        30\n'
         '   macro avg       0.57      0.31      0.40        30\n'
         'weighted avg       0.87      0.47      0.61        30\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        58\n'
          '         1.0       0.98      0.98      0.98        55\n'
          '         2.0       0.97      1.00      0.99        34\n'
          '\n'
          '    accuracy                           0.99       147\n'
          '   macro avg       0.98      0.99      0.99       147\n'
          'weighted avg       0.99      0.99      0.99       147\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.08      1.00      0.15         9\n'
         '         1.0       0.88      0.10      0.19        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.13       123\n'
         '   macro avg       0.32      0.37      0.11       123\n'
         'weighted avg       0.48      0.13      0.11       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
120
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.00      0.00      0.00        45\n'
         '         2.0       0.21      1.00      0.35        12\n'
         '\n'
         '    accuracy                           0.21        57\n'
         '   macro avg       0.11      0.50      0.17        57\n'
         'weighted avg       0.04      0.21      0.07        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        58\n'
          '         1.0       1.00      1.00      1.00        26\n'
          '         2.0       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           1.00       120\n'
          '   macro avg       1.00      1.00      1.00       120\n'
          'weighted avg       1.00      1.00      1.00       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
120
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.87      0.93        45\n'
         '         2.0       0.75      1.00      0.86        12\n'
         '\n'
         '    accuracy                           0.89        57\n'
         '   macro avg       0.58      0.62      0.60        57\n'
         'weighted avg       0.95      0.89      0.91        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        58\n'
          '         1.0       1.00      1.00      1.00        26\n'
          '         2.0       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           1.00       120\n'
          '   macro avg       1.00      1.00      1.00       120\n'
          'weighted avg       1.00      1.00      1.00       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
118
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.67      0.80         6\n'
         '         1.0       0.92      1.00      0.96        22\n'
         '         2.0       1.00      1.00      1.00        31\n'
         '\n'
         '    accuracy                           0.97        59\n'
         '   macro avg       0.97      0.89      0.92        59\n'
         'weighted avg       0.97      0.97      0.96        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        52\n'
          '         1.0       0.98      0.98      0.98        49\n'
          '         2.0       0.94      1.00      0.97        17\n'
          '\n'
          '    accuracy                           0.98       118\n'
          '   macro avg       0.97      0.99      0.98       118\n'
          'weighted avg       0.98      0.98      0.98       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
108
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.94      0.97        50\n'
         '         2.0       0.86      1.00      0.93        19\n'
         '\n'
         '    accuracy                           0.96        69\n'
         '   macro avg       0.93      0.97      0.95        69\n'
         'weighted avg       0.96      0.96      0.96        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        58\n'
          '         1.0       0.88      1.00      0.93        21\n'
          '         2.0       1.00      0.97      0.98        29\n'
          '\n'
          '    accuracy                           0.97       108\n'
          '   macro avg       0.96      0.98      0.97       108\n'
          'weighted avg       0.98      0.97      0.97       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
118
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.11      1.00      0.19         6\n'
         '         1.0       0.00      0.00      0.00        22\n'
         '         2.0       1.00      0.06      0.12        31\n'
         '\n'
         '    accuracy                           0.14        59\n'
         '   macro avg       0.37      0.35      0.10        59\n'
         'weighted avg       0.54      0.14      0.08        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        52\n'
          '         1.0       1.00      0.98      0.99        49\n'
          '         2.0       0.94      1.00      0.97        17\n'
          '\n'
          '    accuracy                           0.99       118\n'
          '   macro avg       0.98      0.99      0.99       118\n'
          'weighted avg       0.99      0.99      0.99       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.97      0.62      0.76        45\n'
         '         1.0       0.00      0.00      0.00         1\n'
         '\n'
         '    accuracy                           0.61        46\n'
         '   macro avg       0.48      0.31      0.38        46\n'
         'weighted avg       0.94      0.61      0.74        46\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        13\n'
          '         1.0       1.00      0.97      0.99        70\n'
          '         2.0       0.96      1.00      0.98        48\n'
          '\n'
          '    accuracy                           0.98       131\n'
          '   macro avg       0.99      0.99      0.99       131\n'
          'weighted avg       0.99      0.98      0.98       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
149
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       0.93      1.00      0.96        26\n'
         '         2.0       0.00      0.00      0.00         2\n'
         '\n'
         '    accuracy                           0.93        28\n'
         '   macro avg       0.46      0.50      0.48        28\n'
         'weighted avg       0.86      0.93      0.89        28\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        58\n'
          '         1.0       1.00      1.00      1.00        45\n'
          '         2.0       1.00      1.00      1.00        46\n'
          '\n'
          '    accuracy                           1.00       149\n'
          '   macro avg       1.00      1.00      1.00       149\n'
          'weighted avg       1.00      1.00      1.00       149\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
150
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.80      0.89         5\n'
         '         1.0       0.83      1.00      0.91        10\n'
         '         2.0       1.00      0.92      0.96        12\n'
         '\n'
         '    accuracy                           0.93        27\n'
         '   macro avg       0.94      0.91      0.92        27\n'
         'weighted avg       0.94      0.93      0.93        27\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        53\n'
          '         1.0       1.00      1.00      1.00        61\n'
          '         2.0       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           1.00       150\n'
          '   macro avg       1.00      1.00      1.00       150\n'
          'weighted avg       1.00      1.00      1.00       150\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
154
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        23\n'
         '\n'
         '    accuracy                           1.00        23\n'
         '   macro avg       1.00      1.00      1.00        23\n'
         'weighted avg       1.00      1.00      1.00        23\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.97      1.00      0.99        35\n'
          '         1.0       1.00      0.97      0.99        71\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.99       154\n'
          '   macro avg       0.98      0.99      0.99       154\n'
          'weighted avg       0.99      0.99      0.99       154\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.96      1.00      0.98        49\n'
         '         1.0       1.00      0.25      0.40         4\n'
         '         2.0       0.50      1.00      0.67         1\n'
         '\n'
         '    accuracy                           0.94        54\n'
         '   macro avg       0.82      0.75      0.68        54\n'
         'weighted avg       0.96      0.94      0.93        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.78      0.88         9\n'
          '         1.0       0.97      1.00      0.99        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.99      0.93      0.95       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
129
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.02      1.00      0.05         1\n'
         '         1.0       1.00      0.05      0.10        20\n'
         '         2.0       1.00      0.15      0.26        27\n'
         '\n'
         '    accuracy                           0.12        48\n'
         '   macro avg       0.67      0.40      0.13        48\n'
         'weighted avg       0.98      0.12      0.19        48\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        57\n'
          '         1.0       1.00      0.98      0.99        51\n'
          '         2.0       0.95      1.00      0.98        21\n'
          '\n'
          '    accuracy                           0.99       129\n'
          '   macro avg       0.98      0.99      0.99       129\n'
          'weighted avg       0.99      0.99      0.99       129\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.94      0.35      0.51        49\n'
         '         1.0       0.06      0.50      0.11         4\n'
         '         2.0       0.50      1.00      0.67         1\n'
         '\n'
         '    accuracy                           0.37        54\n'
         '   macro avg       0.50      0.62      0.43        54\n'
         'weighted avg       0.87      0.37      0.48        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        47\n'
          '\n'
          '    accuracy                           0.99       123\n'
          '   macro avg       0.99      1.00      0.99       123\n'
          'weighted avg       0.99      0.99      0.99       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.50      0.25      0.33         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.93        54\n'
          '   macro avg       0.48      0.42      0.43        54\n'
          'weighted avg       0.89      0.93      0.91        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
154
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.86      0.93        22\n'
         '         1.0       0.25      1.00      0.40         1\n'
         '\n'
         '    accuracy                           0.87        23\n'
         '   macro avg       0.62      0.93      0.66        23\n'
         'weighted avg       0.97      0.87      0.90        23\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        36\n'
          '         1.0       1.00      1.00      1.00        70\n'
          '         2.0       1.00      1.00      1.00        48\n'
          '\n'
          '    accuracy                           1.00       154\n'
          '   macro avg       1.00      1.00      1.00       154\n'
          'weighted avg       1.00      1.00      1.00       154\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
149
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      0.96      0.98        26\n'
         '         2.0       0.67      1.00      0.80         2\n'
         '\n'
         '    accuracy                           0.96        28\n'
         '   macro avg       0.83      0.98      0.89        28\n'
         'weighted avg       0.98      0.96      0.97        28\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.97      1.00      0.98        58\n'
          '         1.0       1.00      0.93      0.97        45\n'
          '         2.0       0.98      1.00      0.99        46\n'
          '\n'
          '    accuracy                           0.98       149\n'
          '   macro avg       0.98      0.98      0.98       149\n'
          'weighted avg       0.98      0.98      0.98       149\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.96      1.00      0.98        49\n'
         '         1.0       1.00      0.25      0.40         4\n'
         '         2.0       0.50      1.00      0.67         1\n'
         '\n'
         '    accuracy                           0.94        54\n'
         '   macro avg       0.82      0.75      0.68        54\n'
         'weighted avg       0.96      0.94      0.93        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.78      0.88         9\n'
          '         1.0       0.97      1.00      0.99        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.99      0.93      0.95       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
139
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.75      0.10      0.18        29\n'
         '         1.0       0.12      1.00      0.21         4\n'
         '         2.0       0.00      0.00      0.00         5\n'
         '\n'
         '    accuracy                           0.18        38\n'
         '   macro avg       0.29      0.37      0.13        38\n'
         'weighted avg       0.58      0.18      0.16        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        29\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        43\n'
          '\n'
          '    accuracy                           0.99       139\n'
          '   macro avg       0.99      0.98      0.99       139\n'
          'weighted avg       0.99      0.99      0.99       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
151
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.83      0.91        12\n'
         '         1.0       0.71      1.00      0.83         5\n'
         '         2.0       1.00      1.00      1.00         9\n'
         '\n'
         '    accuracy                           0.92        26\n'
         '   macro avg       0.90      0.94      0.91        26\n'
         'weighted avg       0.95      0.92      0.93        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        46\n'
          '         1.0       0.98      0.98      0.98        66\n'
          '         2.0       0.97      1.00      0.99        39\n'
          '\n'
          '    accuracy                           0.99       151\n'
          '   macro avg       0.99      0.99      0.99       151\n'
          'weighted avg       0.99      0.99      0.99       151\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.50      0.25      0.33         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.93        54\n'
          '   macro avg       0.48      0.42      0.43        54\n'
          'weighted avg       0.89      0.93      0.91        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
146
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.90      0.95        29\n'
         '         2.0       0.67      1.00      0.80         2\n'
         '\n'
         '    accuracy                           0.90        31\n'
         '   macro avg       0.56      0.63      0.58        31\n'
         'weighted avg       0.98      0.90      0.94        31\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        58\n'
          '         1.0       1.00      1.00      1.00        42\n'
          '         2.0       1.00      1.00      1.00        46\n'
          '\n'
          '    accuracy                           1.00       146\n'
          '   macro avg       1.00      1.00      1.00       146\n'
          'weighted avg       1.00      1.00      1.00       146\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.90      0.95        49\n'
         '         1.0       0.44      1.00      0.62         4\n'
         '         2.0       1.00      1.00      1.00         1\n'
         '\n'
         '    accuracy                           0.91        54\n'
         '   macro avg       0.81      0.97      0.85        54\n'
         'weighted avg       0.96      0.91      0.92        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.78      0.88         9\n'
          '         1.0       0.97      1.00      0.99        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.99      0.93      0.95       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
151
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.67      0.80        12\n'
         '         1.0       0.50      0.80      0.62         5\n'
         '         2.0       0.90      1.00      0.95         9\n'
         '\n'
         '    accuracy                           0.81        26\n'
         '   macro avg       0.80      0.82      0.79        26\n'
         'weighted avg       0.87      0.81      0.82        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        46\n'
          '         1.0       1.00      1.00      1.00        66\n'
          '         2.0       1.00      1.00      1.00        39\n'
          '\n'
          '    accuracy                           1.00       151\n'
          '   macro avg       1.00      1.00      1.00       151\n'
          'weighted avg       1.00      1.00      1.00       151\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.91      1.00      0.95        49\n'
          '         1.0       0.00      0.00      0.00         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.91        54\n'
          '   macro avg       0.30      0.33      0.32        54\n'
          'weighted avg       0.82      0.91      0.86        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
120
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.67      0.80         6\n'
         '         1.0       0.92      1.00      0.96        22\n'
         '         2.0       1.00      1.00      1.00        29\n'
         '\n'
         '    accuracy                           0.96        57\n'
         '   macro avg       0.97      0.89      0.92        57\n'
         'weighted avg       0.97      0.96      0.96        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        52\n'
          '         1.0       0.98      0.98      0.98        49\n'
          '         2.0       0.95      1.00      0.97        19\n'
          '\n'
          '    accuracy                           0.98       120\n'
          '   macro avg       0.98      0.99      0.98       120\n'
          'weighted avg       0.98      0.98      0.98       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.60      0.06      0.11        49\n'
         '         1.0       0.00      0.00      0.00         4\n'
         '         2.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.07        54\n'
         '   macro avg       0.21      0.35      0.05        54\n'
         'weighted avg       0.54      0.07      0.10        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           1.00       123\n'
          '   macro avg       1.00      1.00      1.00       123\n'
          'weighted avg       1.00      1.00      1.00       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.98      1.00      0.99        45\n'
         '         1.0       0.00      0.00      0.00         1\n'
         '\n'
         '    accuracy                           0.98        46\n'
         '   macro avg       0.49      0.50      0.49        46\n'
         'weighted avg       0.96      0.98      0.97        46\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        13\n'
          '         1.0       1.00      1.00      1.00        70\n'
          '         2.0       1.00      1.00      1.00        48\n'
          '\n'
          '    accuracy                           1.00       131\n'
          '   macro avg       1.00      1.00      1.00       131\n'
          'weighted avg       1.00      1.00      1.00       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.91      1.00      0.95        49\n'
          '         1.0       0.00      0.00      0.00         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.91        54\n'
          '   macro avg       0.30      0.33      0.32        54\n'
          'weighted avg       0.82      0.91      0.86        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
120
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.83      0.91         6\n'
         '         1.0       0.92      1.00      0.96        22\n'
         '         2.0       1.00      0.97      0.98        29\n'
         '\n'
         '    accuracy                           0.96        57\n'
         '   macro avg       0.97      0.93      0.95        57\n'
         'weighted avg       0.97      0.96      0.96        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.98      0.98      0.98        52\n'
          '         1.0       0.98      0.96      0.97        49\n'
          '         2.0       0.95      1.00      0.97        19\n'
          '\n'
          '    accuracy                           0.97       120\n'
          '   macro avg       0.97      0.98      0.97       120\n'
          'weighted avg       0.98      0.97      0.97       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        45\n'
         '         1.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.02        46\n'
         '   macro avg       0.01      0.50      0.02        46\n'
         'weighted avg       0.00      0.02      0.00        46\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.92      0.96        13\n'
          '         1.0       0.99      0.99      0.99        70\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.98       131\n'
          '   macro avg       0.99      0.97      0.98       131\n'
          'weighted avg       0.98      0.98      0.98       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.08      1.00      0.15         9\n'
         '         1.0       0.88      0.10      0.19        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.13       123\n'
         '   macro avg       0.32      0.37      0.11       123\n'
         'weighted avg       0.48      0.13      0.11       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.94      1.00      0.97        49\n'
          '         1.0       0.50      0.25      0.33         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.93        54\n'
          '   macro avg       0.48      0.42      0.43        54\n'
          'weighted avg       0.89      0.93      0.91        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
118
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.87      0.93        45\n'
         '         2.0       0.78      1.00      0.88        14\n'
         '\n'
         '    accuracy                           0.90        59\n'
         '   macro avg       0.59      0.62      0.60        59\n'
         'weighted avg       0.95      0.90      0.92        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        58\n'
          '         1.0       1.00      1.00      1.00        26\n'
          '         2.0       1.00      1.00      1.00        34\n'
          '\n'
          '    accuracy                           1.00       118\n'
          '   macro avg       1.00      1.00      1.00       118\n'
          'weighted avg       1.00      1.00      1.00       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
157
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        20\n'
         '\n'
         '    accuracy                           1.00        20\n'
         '   macro avg       1.00      1.00      1.00        20\n'
         'weighted avg       1.00      1.00      1.00        20\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.97      1.00      0.99        38\n'
          '         1.0       1.00      0.97      0.99        71\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.99       157\n'
          '   macro avg       0.98      0.99      0.99       157\n'
          'weighted avg       0.99      0.99      0.99       157\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.50      0.33      0.40         9\n'
         '         1.0       0.64      0.24      0.35        67\n'
         '         2.0       0.45      0.87      0.59        47\n'
         '\n'
         '    accuracy                           0.49       123\n'
         '   macro avg       0.53      0.48      0.45       123\n'
         'weighted avg       0.56      0.49      0.44       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        49\n'
         '         1.0       0.04      0.50      0.08         4\n'
         '         2.0       0.20      1.00      0.33         1\n'
         '\n'
         '    accuracy                           0.06        54\n'
         '   macro avg       0.08      0.50      0.14        54\n'
         'weighted avg       0.01      0.06      0.01        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.89      0.94         9\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        47\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.99      0.96      0.97       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
126
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.91      0.95        43\n'
         '         2.0       0.80      1.00      0.89         8\n'
         '\n'
         '    accuracy                           0.92        51\n'
         '   macro avg       0.60      0.64      0.61        51\n'
         'weighted avg       0.97      0.92      0.94        51\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        58\n'
          '         1.0       0.97      1.00      0.98        28\n'
          '         2.0       1.00      1.00      1.00        40\n'
          '\n'
          '    accuracy                           0.99       126\n'
          '   macro avg       0.99      0.99      0.99       126\n'
          'weighted avg       0.99      0.99      0.99       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
146
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         1\n'
         '         1.0       0.80      0.33      0.47        12\n'
         '         2.0       0.65      0.94      0.77        18\n'
         '\n'
         '    accuracy                           0.68        31\n'
         '   macro avg       0.48      0.43      0.41        31\n'
         'weighted avg       0.69      0.68      0.63        31\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        57\n'
          '         1.0       1.00      1.00      1.00        59\n'
          '         2.0       1.00      1.00      1.00        30\n'
          '\n'
          '    accuracy                           1.00       146\n'
          '   macro avg       1.00      1.00      1.00       146\n'
          'weighted avg       1.00      1.00      1.00       146\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
171
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00         6\n'
         '\n'
         '    accuracy                           1.00         6\n'
         '   macro avg       1.00      1.00      1.00         6\n'
         'weighted avg       1.00      1.00      1.00         6\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        52\n'
          '         1.0       1.00      1.00      1.00        71\n'
          '         2.0       1.00      1.00      1.00        48\n'
          '\n'
          '    accuracy                           1.00       171\n'
          '   macro avg       1.00      1.00      1.00       171\n'
          'weighted avg       1.00      1.00      1.00       171\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
120
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.82      0.90        45\n'
         '         2.0       0.80      1.00      0.89        12\n'
         '\n'
         '    accuracy                           0.86        57\n'
         '   macro avg       0.60      0.61      0.60        57\n'
         'weighted avg       0.96      0.86      0.90        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.95      1.00      0.97        58\n'
          '         1.0       1.00      0.88      0.94        26\n'
          '         2.0       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           0.97       120\n'
          '   macro avg       0.98      0.96      0.97       120\n'
          'weighted avg       0.98      0.97      0.97       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
154
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        23\n'
         '\n'
         '    accuracy                           1.00        23\n'
         '   macro avg       1.00      1.00      1.00        23\n'
         'weighted avg       1.00      1.00      1.00        23\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.94      0.97        35\n'
          '         1.0       0.96      0.97      0.97        71\n'
          '         2.0       0.96      0.98      0.97        48\n'
          '\n'
          '    accuracy                           0.97       154\n'
          '   macro avg       0.97      0.96      0.97       154\n'
          'weighted avg       0.97      0.97      0.97       154\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.07      1.00      0.14         9\n'
         '         1.0       0.00      0.00      0.00        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.07       123\n'
         '   macro avg       0.02      0.33      0.05       123\n'
         'weighted avg       0.01      0.07      0.01       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.91      1.00      0.95        49\n'
          '         1.0       0.00      0.00      0.00         4\n'
          '         2.0       0.00      0.00      0.00         1\n'
          '\n'
          '    accuracy                           0.91        54\n'
          '   macro avg       0.30      0.33      0.32        54\n'
          'weighted avg       0.82      0.91      0.86        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
54
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.08      1.00      0.15         9\n'
         '         1.0       0.88      0.10      0.19        67\n'
         '         2.0       0.00      0.00      0.00        47\n'
         '\n'
         '    accuracy                           0.13       123\n'
         '   macro avg       0.32      0.37      0.11       123\n'
         'weighted avg       0.48      0.13      0.11       123\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        49\n'
          '         1.0       1.00      1.00      1.00         4\n'
          '         2.0       1.00      1.00      1.00         1\n'
          '\n'
          '    accuracy                           1.00        54\n'
          '   macro avg       1.00      1.00      1.00        54\n'
          'weighted avg       1.00      1.00      1.00        54\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
160
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        17\n'
         '\n'
         '    accuracy                           1.00        17\n'
         '   macro avg       1.00      1.00      1.00        17\n'
         'weighted avg       1.00      1.00      1.00        17\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        41\n'
          '         1.0       1.00      1.00      1.00        71\n'
          '         2.0       1.00      1.00      1.00        48\n'
          '\n'
          '    accuracy                           1.00       160\n'
          '   macro avg       1.00      1.00      1.00       160\n'
          'weighted avg       1.00      1.00      1.00       160\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
118
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.71      0.83      0.77         6\n'
         '         1.0       0.91      0.91      0.91        22\n'
         '         2.0       1.00      0.97      0.98        31\n'
         '\n'
         '    accuracy                           0.93        59\n'
         '   macro avg       0.87      0.90      0.89        59\n'
         'weighted avg       0.94      0.93      0.93        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        52\n'
          '         1.0       1.00      1.00      1.00        49\n'
          '         2.0       1.00      1.00      1.00        17\n'
          '\n'
          '    accuracy                           1.00       118\n'
          '   macro avg       1.00      1.00      1.00       118\n'
          'weighted avg       1.00      1.00      1.00       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
145
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.96      1.00      0.98        26\n'
         '         1.0       1.00      0.75      0.86         4\n'
         '         2.0       1.00      1.00      1.00         2\n'
         '\n'
         '    accuracy                           0.97        32\n'
         '   macro avg       0.99      0.92      0.95        32\n'
         'weighted avg       0.97      0.97      0.97        32\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        32\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        46\n'
          '\n'
          '    accuracy                           1.00       145\n'
          '   macro avg       1.00      1.00      1.00       145\n'
          'weighted avg       1.00      1.00      1.00       145\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
139
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.93      0.96        29\n'
         '         1.0       0.67      1.00      0.80         4\n'
         '         2.0       1.00      1.00      1.00         5\n'
         '\n'
         '    accuracy                           0.95        38\n'
         '   macro avg       0.89      0.98      0.92        38\n'
         'weighted avg       0.96      0.95      0.95        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        29\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        43\n'
          '\n'
          '    accuracy                           0.99       139\n'
          '   macro avg       0.99      0.98      0.99       139\n'
          'weighted avg       0.99      0.99      0.99       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
131
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00        45\n'
         '         1.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.02        46\n'
         '   macro avg       0.01      0.50      0.02        46\n'
         'weighted avg       0.00      0.02      0.00        46\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.92      0.96        13\n'
          '         1.0       0.99      0.99      0.99        70\n'
          '         2.0       0.98      1.00      0.99        48\n'
          '\n'
          '    accuracy                           0.98       131\n'
          '   macro avg       0.99      0.97      0.98       131\n'
          'weighted avg       0.98      0.98      0.98       131\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
162
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00         6\n'
         '         2.0       1.00      1.00      1.00         9\n'
         '\n'
         '    accuracy                           1.00        15\n'
         '   macro avg       1.00      1.00      1.00        15\n'
         'weighted avg       1.00      1.00      1.00        15\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        58\n'
          '         1.0       0.98      0.98      0.98        65\n'
          '         2.0       0.97      1.00      0.99        39\n'
          '\n'
          '    accuracy                           0.99       162\n'
          '   macro avg       0.99      0.99      0.99       162\n'
          'weighted avg       0.99      0.99      0.99       162\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.60      0.06      0.11        49\n'
         '         1.0       0.00      0.00      0.00         4\n'
         '         2.0       0.02      1.00      0.04         1\n'
         '\n'
         '    accuracy                           0.07        54\n'
         '   macro avg       0.21      0.35      0.05        54\n'
         'weighted avg       0.54      0.07      0.10        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00         9\n'
          '         1.0       1.00      1.00      1.00        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           1.00       123\n'
          '   macro avg       1.00      1.00      1.00       123\n'
          'weighted avg       1.00      1.00      1.00       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
171
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00         6\n'
         '\n'
         '    accuracy                           1.00         6\n'
         '   macro avg       1.00      1.00      1.00         6\n'
         'weighted avg       1.00      1.00      1.00         6\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        52\n'
          '         1.0       1.00      1.00      1.00        71\n'
          '         2.0       1.00      1.00      1.00        48\n'
          '\n'
          '    accuracy                           1.00       171\n'
          '   macro avg       1.00      1.00      1.00       171\n'
          'weighted avg       1.00      1.00      1.00       171\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
123
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.90      0.95        49\n'
         '         1.0       0.44      1.00      0.62         4\n'
         '         2.0       1.00      1.00      1.00         1\n'
         '\n'
         '    accuracy                           0.91        54\n'
         '   macro avg       0.81      0.97      0.85        54\n'
         'weighted avg       0.96      0.91      0.92        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.78      0.88         9\n'
          '         1.0       0.97      1.00      0.99        67\n'
          '         2.0       1.00      1.00      1.00        47\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.99      0.93      0.95       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
139
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.93      0.96        29\n'
         '         1.0       0.67      1.00      0.80         4\n'
         '         2.0       1.00      1.00      1.00         5\n'
         '\n'
         '    accuracy                           0.95        38\n'
         '   macro avg       0.89      0.98      0.92        38\n'
         'weighted avg       0.96      0.95      0.95        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.98        29\n'
          '         1.0       0.99      0.99      0.99        67\n'
          '         2.0       0.98      1.00      0.99        43\n'
          '\n'
          '    accuracy                           0.99       139\n'
          '   macro avg       0.99      0.98      0.99       139\n'
          'weighted avg       0.99      0.99      0.99       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
108
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       0.00      0.00      0.00        50\n'
         '         2.0       0.67      0.11      0.18        19\n'
         '\n'
         '    accuracy                           0.03        69\n'
         '   macro avg       0.22      0.04      0.06        69\n'
         'weighted avg       0.18      0.03      0.05        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        58\n'
          '         1.0       0.95      0.95      0.95        21\n'
          '         2.0       0.97      1.00      0.98        29\n'
          '\n'
          '    accuracy                           0.98       108\n'
          '   macro avg       0.97      0.98      0.98       108\n'
          'weighted avg       0.98      0.98      0.98       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
120
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.91      0.95        45\n'
         '         2.0       0.86      1.00      0.92        12\n'
         '\n'
         '    accuracy                           0.93        57\n'
         '   macro avg       0.62      0.64      0.63        57\n'
         'weighted avg       0.97      0.93      0.95        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        58\n'
          '         1.0       0.96      1.00      0.98        26\n'
          '         2.0       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           0.99       120\n'
          '   macro avg       0.99      0.99      0.99       120\n'
          'weighted avg       0.99      0.99      0.99       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
115
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.53      0.69      0.60        13\n'
         '         1.0       0.00      0.00      0.00        20\n'
         '         2.0       0.53      0.83      0.65        29\n'
         '\n'
         '    accuracy                           0.53        62\n'
         '   macro avg       0.35      0.51      0.42        62\n'
         'weighted avg       0.36      0.53      0.43        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.98      1.00      0.99        45\n'
          '         1.0       0.94      0.92      0.93        51\n'
          '         2.0       0.84      0.84      0.84        19\n'
          '\n'
          '    accuracy                           0.94       115\n'
          '   macro avg       0.92      0.92      0.92       115\n'
          'weighted avg       0.94      0.94      0.94       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
151
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.50      0.33      0.40        12\n'
         '         1.0       0.20      0.40      0.27         5\n'
         '         2.0       0.88      0.78      0.82         9\n'
         '\n'
         '    accuracy                           0.50        26\n'
         '   macro avg       0.53      0.50      0.50        26\n'
         'weighted avg       0.57      0.50      0.52        26\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.98      0.99        46\n'
          '         1.0       0.99      1.00      0.99        66\n'
          '         2.0       1.00      1.00      1.00        39\n'
          '\n'
          '    accuracy                           0.99       151\n'
          '   macro avg       1.00      0.99      0.99       151\n'
          'weighted avg       0.99      0.99      0.99       151\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
115
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.91      0.77      0.83        13\n'
         '         1.0       0.87      1.00      0.93        20\n'
         '         2.0       1.00      0.97      0.98        29\n'
         '\n'
         '    accuracy                           0.94        62\n'
         '   macro avg       0.93      0.91      0.92        62\n'
         'weighted avg       0.94      0.94      0.93        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        45\n'
          '         1.0       1.00      0.96      0.98        51\n'
          '         2.0       0.90      1.00      0.95        19\n'
          '\n'
          '    accuracy                           0.98       115\n'
          '   macro avg       0.97      0.99      0.98       115\n'
          'weighted avg       0.98      0.98      0.98       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
102
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      0.96      0.96        27\n'
         '           1       0.90      0.96      0.93        27\n'
         '           2       1.00      0.90      0.95        21\n'
         '\n'
         '    accuracy                           0.95        75\n'
         '   macro avg       0.95      0.94      0.95        75\n'
         'weighted avg       0.95      0.95      0.95        75\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.98        31\n'
          '           1       0.98      0.98      0.98        44\n'
          '           2       0.96      1.00      0.98        27\n'
          '\n'
          '    accuracy                           0.98       102\n'
          '   macro avg       0.98      0.98      0.98       102\n'
          'weighted avg       0.98      0.98      0.98       102\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
97
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.89      0.83      0.86        29\n'
         '           1       0.59      0.89      0.71        27\n'
         '           2       0.83      0.42      0.56        24\n'
         '\n'
         '    accuracy                           0.73        80\n'
         '   macro avg       0.77      0.71      0.71        80\n'
         'weighted avg       0.77      0.72      0.72        80\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        29\n'
          '           1       0.98      0.98      0.98        44\n'
          '           2       0.96      0.96      0.96        24\n'
          '\n'
          '    accuracy                           0.98        97\n'
          '   macro avg       0.98      0.98      0.98        97\n'
          'weighted avg       0.98      0.98      0.98        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      1.00      0.98        27\n'
         '           1       1.00      0.97      0.98        32\n'
         '           2       1.00      1.00      1.00        22\n'
         '\n'
         '    accuracy                           0.99        81\n'
         '   macro avg       0.99      0.99      0.99        81\n'
         'weighted avg       0.99      0.99      0.99        81\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.98        31\n'
          '           1       0.97      0.97      0.97        39\n'
          '           2       0.96      1.00      0.98        26\n'
          '\n'
          '    accuracy                           0.98        96\n'
          '   macro avg       0.98      0.98      0.98        96\n'
          'weighted avg       0.98      0.98      0.98        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
133
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.91      0.83      0.87        12\n'
         '           1       0.79      0.88      0.83        17\n'
         '           2       0.79      0.73      0.76        15\n'
         '\n'
         '    accuracy                           0.82        44\n'
         '   macro avg       0.83      0.82      0.82        44\n'
         'weighted avg       0.82      0.82      0.82        44\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        46\n'
          '           1       1.00      1.00      1.00        54\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           1.00       133\n'
          '   macro avg       1.00      1.00      1.00       133\n'
          'weighted avg       1.00      1.00      1.00       133\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
120
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      0.95      0.95        21\n'
         '           1       0.89      0.84      0.86        19\n'
         '           2       0.89      0.94      0.91        17\n'
         '\n'
         '    accuracy                           0.91        57\n'
         '   macro avg       0.91      0.91      0.91        57\n'
         'weighted avg       0.91      0.91      0.91        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       1.00      1.00      1.00        52\n'
          '           2       1.00      1.00      1.00        31\n'
          '\n'
          '    accuracy                           1.00       120\n'
          '   macro avg       1.00      1.00      1.00       120\n'
          'weighted avg       1.00      1.00      1.00       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
111
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      1.00      0.98        24\n'
         '           1       1.00      0.96      0.98        27\n'
         '           2       1.00      1.00      1.00        15\n'
         '\n'
         '    accuracy                           0.98        66\n'
         '   macro avg       0.99      0.99      0.99        66\n'
         'weighted avg       0.99      0.98      0.98        66\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      1.00      0.99        34\n'
          '           1       1.00      0.95      0.98        44\n'
          '           2       0.97      1.00      0.99        33\n'
          '\n'
          '    accuracy                           0.98       111\n'
          '   macro avg       0.98      0.98      0.98       111\n'
          'weighted avg       0.98      0.98      0.98       111\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
105
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.96      0.98        25\n'
         '           1       0.97      0.97      0.97        30\n'
         '           2       0.94      1.00      0.97        17\n'
         '\n'
         '    accuracy                           0.97        72\n'
         '   macro avg       0.97      0.98      0.97        72\n'
         'weighted avg       0.97      0.97      0.97        72\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.94      0.97        33\n'
          '           1       0.93      0.98      0.95        41\n'
          '           2       0.97      0.97      0.97        31\n'
          '\n'
          '    accuracy                           0.96       105\n'
          '   macro avg       0.97      0.96      0.96       105\n'
          'weighted avg       0.96      0.96      0.96       105\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
140
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.83      0.77      0.80        13\n'
         '           1       0.73      0.69      0.71        16\n'
         '           2       0.60      0.75      0.67         8\n'
         '\n'
         '    accuracy                           0.73        37\n'
         '   macro avg       0.72      0.74      0.73        37\n'
         'weighted avg       0.74      0.73      0.73        37\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        45\n'
          '           1       0.98      0.96      0.97        55\n'
          '           2       0.95      1.00      0.98        40\n'
          '\n'
          '    accuracy                           0.98       140\n'
          '   macro avg       0.98      0.98      0.98       140\n'
          'weighted avg       0.98      0.98      0.98       140\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
128
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.93      0.97        15\n'
         '           1       0.95      1.00      0.97        19\n'
         '           2       1.00      1.00      1.00        15\n'
         '\n'
         '    accuracy                           0.98        49\n'
         '   macro avg       0.98      0.98      0.98        49\n'
         'weighted avg       0.98      0.98      0.98        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        43\n'
          '           1       0.98      0.98      0.98        52\n'
          '           2       0.97      1.00      0.99        33\n'
          '\n'
          '    accuracy                           0.98       128\n'
          '   macro avg       0.98      0.99      0.98       128\n'
          'weighted avg       0.98      0.98      0.98       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
117
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.80      0.94      0.86        17\n'
         '           1       0.87      0.80      0.83        25\n'
         '           2       0.76      0.72      0.74        18\n'
         '\n'
         '    accuracy                           0.82        60\n'
         '   macro avg       0.81      0.82      0.81        60\n'
         'weighted avg       0.82      0.82      0.82        60\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        41\n'
          '           1       1.00      1.00      1.00        46\n'
          '           2       1.00      1.00      1.00        30\n'
          '\n'
          '    accuracy                           1.00       117\n'
          '   macro avg       1.00      1.00      1.00       117\n'
          'weighted avg       1.00      1.00      1.00       117\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
97
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.87      1.00      0.93        27\n'
         '           1       1.00      0.84      0.92        32\n'
         '           2       0.95      1.00      0.98        21\n'
         '\n'
         '    accuracy                           0.94        80\n'
         '   macro avg       0.94      0.95      0.94        80\n'
         'weighted avg       0.94      0.94      0.94        80\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       1.00      1.00      1.00        39\n'
          '           2       1.00      1.00      1.00        27\n'
          '\n'
          '    accuracy                           1.00        97\n'
          '   macro avg       1.00      1.00      1.00        97\n'
          'weighted avg       1.00      1.00      1.00        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
126
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      0.95      0.95        19\n'
         '           1       0.94      0.84      0.89        19\n'
         '           2       0.87      1.00      0.93        13\n'
         '\n'
         '    accuracy                           0.92        51\n'
         '   macro avg       0.92      0.93      0.92        51\n'
         'weighted avg       0.92      0.92      0.92        51\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       1.00      1.00      1.00        52\n'
          '           2       1.00      1.00      1.00        35\n'
          '\n'
          '    accuracy                           1.00       126\n'
          '   macro avg       1.00      1.00      1.00       126\n'
          'weighted avg       1.00      1.00      1.00       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
128
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.94      1.00      0.97        15\n'
         '           1       1.00      0.86      0.92        21\n'
         '           2       0.87      1.00      0.93        13\n'
         '\n'
         '    accuracy                           0.94        49\n'
         '   macro avg       0.93      0.95      0.94        49\n'
         'weighted avg       0.95      0.94      0.94        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      0.95      0.96        43\n'
          '           1       0.96      0.98      0.97        50\n'
          '           2       1.00      1.00      1.00        35\n'
          '\n'
          '    accuracy                           0.98       128\n'
          '   macro avg       0.98      0.98      0.98       128\n'
          'weighted avg       0.98      0.98      0.98       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
101
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.81      0.92      0.86        24\n'
         '           1       0.81      0.67      0.73        33\n'
         '           2       0.64      0.74      0.68        19\n'
         '\n'
         '    accuracy                           0.76        76\n'
         '   macro avg       0.76      0.77      0.76        76\n'
         'weighted avg       0.77      0.76      0.76        76\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        34\n'
          '           1       0.95      1.00      0.97        38\n'
          '           2       1.00      0.97      0.98        29\n'
          '\n'
          '    accuracy                           0.98       101\n'
          '   macro avg       0.98      0.98      0.98       101\n'
          'weighted avg       0.98      0.98      0.98       101\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
132
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.90      0.95        10\n'
         '           1       0.94      1.00      0.97        16\n'
         '           2       1.00      1.00      1.00        19\n'
         '\n'
         '    accuracy                           0.98        45\n'
         '   macro avg       0.98      0.97      0.97        45\n'
         'weighted avg       0.98      0.98      0.98        45\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        48\n'
          '           1       0.98      0.98      0.98        55\n'
          '           2       0.97      1.00      0.98        29\n'
          '\n'
          '    accuracy                           0.98       132\n'
          '   macro avg       0.98      0.99      0.98       132\n'
          'weighted avg       0.99      0.98      0.98       132\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
90
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.79      0.85      0.81        26\n'
         '           1       0.62      0.76      0.68        34\n'
         '           2       0.65      0.41      0.50        27\n'
         '\n'
         '    accuracy                           0.68        87\n'
         '   macro avg       0.68      0.67      0.67        87\n'
         'weighted avg       0.68      0.68      0.67        87\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        32\n'
          '           1       1.00      1.00      1.00        37\n'
          '           2       1.00      1.00      1.00        21\n'
          '\n'
          '    accuracy                           1.00        90\n'
          '   macro avg       1.00      1.00      1.00        90\n'
          'weighted avg       1.00      1.00      1.00        90\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
122
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      0.91      0.93        22\n'
         '           1       0.86      0.95      0.90        20\n'
         '           2       1.00      0.92      0.96        13\n'
         '\n'
         '    accuracy                           0.93        55\n'
         '   macro avg       0.94      0.93      0.93        55\n'
         'weighted avg       0.93      0.93      0.93        55\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       1.00      1.00      1.00        51\n'
          '           2       1.00      1.00      1.00        35\n'
          '\n'
          '    accuracy                           1.00       122\n'
          '   macro avg       1.00      1.00      1.00       122\n'
          'weighted avg       1.00      1.00      1.00       122\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
109
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.90      1.00      0.95        18\n'
         '           1       1.00      1.00      1.00        28\n'
         '           2       1.00      0.91      0.95        22\n'
         '\n'
         '    accuracy                           0.97        68\n'
         '   macro avg       0.97      0.97      0.97        68\n'
         'weighted avg       0.97      0.97      0.97        68\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      1.00      0.99        40\n'
          '           1       1.00      0.95      0.98        43\n'
          '           2       0.96      1.00      0.98        26\n'
          '\n'
          '    accuracy                           0.98       109\n'
          '   macro avg       0.98      0.98      0.98       109\n'
          'weighted avg       0.98      0.98      0.98       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
128
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.93      0.97        15\n'
         '           1       0.89      0.94      0.92        18\n'
         '           2       0.94      0.94      0.94        16\n'
         '\n'
         '    accuracy                           0.94        49\n'
         '   macro avg       0.94      0.94      0.94        49\n'
         'weighted avg       0.94      0.94      0.94        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        43\n'
          '           1       0.98      1.00      0.99        53\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           0.99       128\n'
          '   macro avg       0.99      0.99      0.99       128\n'
          'weighted avg       0.99      0.99      0.99       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
134
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.80      0.80      0.80        15\n'
         '           1       0.53      0.67      0.59        12\n'
         '           2       0.62      0.50      0.55        16\n'
         '\n'
         '    accuracy                           0.65        43\n'
         '   macro avg       0.65      0.66      0.65        43\n'
         'weighted avg       0.66      0.65      0.65        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      0.98      0.98        43\n'
          '           1       0.86      0.85      0.85        59\n'
          '           2       0.76      0.78      0.77        32\n'
          '\n'
          '    accuracy                           0.87       134\n'
          '   macro avg       0.87      0.87      0.87       134\n'
          'weighted avg       0.87      0.87      0.87       134\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
108
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      1.00      0.98        20\n'
         '           1       1.00      0.94      0.97        33\n'
         '           2       0.94      1.00      0.97        16\n'
         '\n'
         '    accuracy                           0.97        69\n'
         '   macro avg       0.96      0.98      0.97        69\n'
         'weighted avg       0.97      0.97      0.97        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        38\n'
          '           1       0.97      1.00      0.99        38\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           0.99       108\n'
          '   macro avg       0.99      0.99      0.99       108\n'
          'weighted avg       0.99      0.99      0.99       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
130
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.86      0.86      0.86        14\n'
         '           1       0.94      0.73      0.82        22\n'
         '           2       0.50      0.73      0.59        11\n'
         '\n'
         '    accuracy                           0.77        47\n'
         '   macro avg       0.77      0.77      0.76        47\n'
         'weighted avg       0.81      0.77      0.78        47\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.85      0.93      0.89        44\n'
          '           1       0.86      0.61      0.71        49\n'
          '           2       0.62      0.78      0.69        37\n'
          '\n'
          '    accuracy                           0.77       130\n'
          '   macro avg       0.78      0.78      0.77       130\n'
          'weighted avg       0.79      0.77      0.77       130\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
93
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.96      0.98        27\n'
         '           1       0.97      0.97      0.97        33\n'
         '           2       0.96      1.00      0.98        24\n'
         '\n'
         '    accuracy                           0.98        84\n'
         '   macro avg       0.98      0.98      0.98        84\n'
         'weighted avg       0.98      0.98      0.98        84\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       1.00      1.00      1.00        38\n'
          '           2       1.00      1.00      1.00        24\n'
          '\n'
          '    accuracy                           1.00        93\n'
          '   macro avg       1.00      1.00      1.00        93\n'
          'weighted avg       1.00      1.00      1.00        93\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
135
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.90      1.00      0.95         9\n'
         '           1       1.00      0.89      0.94        18\n'
         '           2       0.94      1.00      0.97        15\n'
         '\n'
         '    accuracy                           0.95        42\n'
         '   macro avg       0.95      0.96      0.95        42\n'
         'weighted avg       0.96      0.95      0.95        42\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      1.00      0.99        49\n'
          '           1       1.00      0.98      0.99        53\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           0.99       135\n'
          '   macro avg       0.99      0.99      0.99       135\n'
          'weighted avg       0.99      0.99      0.99       135\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
94
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.77      1.00      0.87        24\n'
         '           1       1.00      0.74      0.85        34\n'
         '           2       0.93      1.00      0.96        25\n'
         '\n'
         '    accuracy                           0.89        83\n'
         '   macro avg       0.90      0.91      0.89        83\n'
         'weighted avg       0.91      0.89      0.89        83\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      0.97      0.97        34\n'
          '           1       0.97      0.97      0.97        37\n'
          '           2       1.00      1.00      1.00        23\n'
          '\n'
          '    accuracy                           0.98        94\n'
          '   macro avg       0.98      0.98      0.98        94\n'
          'weighted avg       0.98      0.98      0.98        94\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
106
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.83      0.90        23\n'
         '           1       0.65      0.71      0.68        28\n'
         '           2       0.62      0.65      0.63        20\n'
         '\n'
         '    accuracy                           0.73        71\n'
         '   macro avg       0.75      0.73      0.74        71\n'
         'weighted avg       0.75      0.73      0.74        71\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        35\n'
          '           1       0.98      0.98      0.98        43\n'
          '           2       0.93      0.96      0.95        28\n'
          '\n'
          '    accuracy                           0.97       106\n'
          '   macro avg       0.97      0.97      0.97       106\n'
          'weighted avg       0.97      0.97      0.97       106\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.96      0.98        28\n'
         '           1       0.97      0.93      0.95        30\n'
         '           2       0.92      1.00      0.96        23\n'
         '\n'
         '    accuracy                           0.96        81\n'
         '   macro avg       0.96      0.97      0.96        81\n'
         'weighted avg       0.96      0.96      0.96        81\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       1.00      0.98      0.99        41\n'
          '           2       0.96      1.00      0.98        25\n'
          '\n'
          '    accuracy                           0.99        96\n'
          '   macro avg       0.99      0.99      0.99        96\n'
          'weighted avg       0.99      0.99      0.99        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
92
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.69      0.95      0.80        21\n'
         '           1       0.81      0.68      0.74        38\n'
         '           2       0.67      0.62      0.64        26\n'
         '\n'
         '    accuracy                           0.73        85\n'
         '   macro avg       0.72      0.75      0.73        85\n'
         'weighted avg       0.74      0.73      0.73        85\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       1.00      1.00      1.00        33\n'
          '           2       1.00      1.00      1.00        22\n'
          '\n'
          '    accuracy                           1.00        92\n'
          '   macro avg       1.00      1.00      1.00        92\n'
          'weighted avg       1.00      1.00      1.00        92\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
90
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.93      0.96      0.95        27\n'
         '           1       0.87      0.79      0.83        33\n'
         '           2       0.79      0.85      0.82        27\n'
         '\n'
         '    accuracy                           0.86        87\n'
         '   macro avg       0.86      0.87      0.86        87\n'
         'weighted avg       0.86      0.86      0.86        87\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       1.00      1.00      1.00        38\n'
          '           2       1.00      1.00      1.00        21\n'
          '\n'
          '    accuracy                           1.00        90\n'
          '   macro avg       1.00      1.00      1.00        90\n'
          'weighted avg       1.00      1.00      1.00        90\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
115
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.94      1.00      0.97        17\n'
         '           1       1.00      0.92      0.96        26\n'
         '           2       0.90      0.95      0.92        19\n'
         '\n'
         '    accuracy                           0.95        62\n'
         '   macro avg       0.95      0.96      0.95        62\n'
         'weighted avg       0.95      0.95      0.95        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.95      1.00      0.98        41\n'
          '           1       1.00      0.96      0.98        45\n'
          '           2       1.00      1.00      1.00        29\n'
          '\n'
          '    accuracy                           0.98       115\n'
          '   macro avg       0.98      0.99      0.98       115\n'
          'weighted avg       0.98      0.98      0.98       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
89
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.90      0.93      0.92        29\n'
         '           1       0.94      0.88      0.91        34\n'
         '           2       0.96      1.00      0.98        25\n'
         '\n'
         '    accuracy                           0.93        88\n'
         '   macro avg       0.93      0.94      0.93        88\n'
         'weighted avg       0.93      0.93      0.93        88\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.98        29\n'
          '           1       0.97      1.00      0.99        37\n'
          '           2       1.00      1.00      1.00        23\n'
          '\n'
          '    accuracy                           0.99        89\n'
          '   macro avg       0.99      0.99      0.99        89\n'
          'weighted avg       0.99      0.99      0.99        89\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
88
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.76      0.93      0.84        28\n'
         '           1       0.69      0.67      0.68        36\n'
         '           2       0.45      0.36      0.40        25\n'
         '\n'
         '    accuracy                           0.66        89\n'
         '   macro avg       0.63      0.65      0.64        89\n'
         'weighted avg       0.64      0.66      0.65        89\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.98        30\n'
          '           1       0.97      1.00      0.99        35\n'
          '           2       1.00      1.00      1.00        23\n'
          '\n'
          '    accuracy                           0.99        88\n'
          '   macro avg       0.99      0.99      0.99        88\n'
          'weighted avg       0.99      0.99      0.99        88\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
119
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       1.00      0.97      0.98        29\n'
         '           2       0.94      1.00      0.97        16\n'
         '\n'
         '    accuracy                           0.98        58\n'
         '   macro avg       0.98      0.99      0.98        58\n'
         'weighted avg       0.98      0.98      0.98        58\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        45\n'
          '           1       0.98      0.98      0.98        42\n'
          '           2       0.97      1.00      0.98        32\n'
          '\n'
          '    accuracy                           0.98       119\n'
          '   macro avg       0.98      0.98      0.98       119\n'
          'weighted avg       0.98      0.98      0.98       119\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
125
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.82      0.74      0.78        19\n'
         '           1       0.71      0.75      0.73        20\n'
         '           2       0.50      0.54      0.52        13\n'
         '\n'
         '    accuracy                           0.69        52\n'
         '   macro avg       0.68      0.68      0.68        52\n'
         'weighted avg       0.70      0.69      0.70        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       1.00      1.00      1.00        51\n'
          '           2       1.00      1.00      1.00        35\n'
          '\n'
          '    accuracy                           1.00       125\n'
          '   macro avg       1.00      1.00      1.00       125\n'
          'weighted avg       1.00      1.00      1.00       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
110
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.90      0.90      0.90        21\n'
         '           1       0.90      0.93      0.92        30\n'
         '           2       1.00      0.94      0.97        16\n'
         '\n'
         '    accuracy                           0.93        67\n'
         '   macro avg       0.94      0.93      0.93        67\n'
         'weighted avg       0.93      0.93      0.93        67\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       1.00      1.00      1.00        41\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           1.00       110\n'
          '   macro avg       1.00      1.00      1.00       110\n'
          'weighted avg       1.00      1.00      1.00       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
126
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.87      0.93        23\n'
         '           1       0.77      0.91      0.83        11\n'
         '           2       0.94      1.00      0.97        17\n'
         '\n'
         '    accuracy                           0.92        51\n'
         '   macro avg       0.90      0.93      0.91        51\n'
         'weighted avg       0.93      0.92      0.92        51\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      0.97      0.97        35\n'
          '           1       0.98      0.97      0.97        60\n'
          '           2       0.97      1.00      0.98        31\n'
          '\n'
          '    accuracy                           0.98       126\n'
          '   macro avg       0.97      0.98      0.98       126\n'
          'weighted avg       0.98      0.98      0.98       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
140
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       1.00      0.94      0.97        17\n'
         '           2       0.91      1.00      0.95        10\n'
         '\n'
         '    accuracy                           0.97        37\n'
         '   macro avg       0.97      0.98      0.97        37\n'
         'weighted avg       0.98      0.97      0.97        37\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.96      0.98        48\n'
          '           1       0.95      0.98      0.96        54\n'
          '           2       0.97      0.97      0.97        38\n'
          '\n'
          '    accuracy                           0.97       140\n'
          '   macro avg       0.97      0.97      0.97       140\n'
          'weighted avg       0.97      0.97      0.97       140\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
109
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.86      0.86      0.86        22\n'
         '           1       0.81      0.81      0.81        26\n'
         '           2       0.75      0.75      0.75        20\n'
         '\n'
         '    accuracy                           0.81        68\n'
         '   macro avg       0.81      0.81      0.81        68\n'
         'weighted avg       0.81      0.81      0.81        68\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       1.00      1.00      1.00        45\n'
          '           2       1.00      1.00      1.00        28\n'
          '\n'
          '    accuracy                           1.00       109\n'
          '   macro avg       1.00      1.00      1.00       109\n'
          'weighted avg       1.00      1.00      1.00       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
108
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.89      0.94        19\n'
         '           1       0.94      1.00      0.97        31\n'
         '           2       1.00      1.00      1.00        19\n'
         '\n'
         '    accuracy                           0.97        69\n'
         '   macro avg       0.98      0.96      0.97        69\n'
         'weighted avg       0.97      0.97      0.97        69\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       1.00      0.97      0.99        40\n'
          '           2       0.97      1.00      0.98        29\n'
          '\n'
          '    accuracy                           0.99       108\n'
          '   macro avg       0.99      0.99      0.99       108\n'
          'weighted avg       0.99      0.99      0.99       108\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
95
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.93      0.81      0.86        31\n'
         '           1       0.74      0.79      0.76        33\n'
         '           2       0.60      0.67      0.63        18\n'
         '\n'
         '    accuracy                           0.77        82\n'
         '   macro avg       0.76      0.75      0.75        82\n'
         'weighted avg       0.78      0.77      0.77        82\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        27\n'
          '           1       1.00      1.00      1.00        38\n'
          '           2       1.00      1.00      1.00        30\n'
          '\n'
          '    accuracy                           1.00        95\n'
          '   macro avg       1.00      1.00      1.00        95\n'
          'weighted avg       1.00      1.00      1.00        95\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
140
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.92      0.92      0.92        13\n'
         '           1       0.93      1.00      0.97        14\n'
         '           2       1.00      0.90      0.95        10\n'
         '\n'
         '    accuracy                           0.95        37\n'
         '   macro avg       0.95      0.94      0.95        37\n'
         'weighted avg       0.95      0.95      0.95        37\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        45\n'
          '           1       1.00      1.00      1.00        57\n'
          '           2       1.00      1.00      1.00        38\n'
          '\n'
          '    accuracy                           1.00       140\n'
          '   macro avg       1.00      1.00      1.00       140\n'
          'weighted avg       1.00      1.00      1.00       140\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
138
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.93      1.00      0.96        13\n'
         '           1       1.00      0.91      0.95        11\n'
         '           2       1.00      1.00      1.00        15\n'
         '\n'
         '    accuracy                           0.97        39\n'
         '   macro avg       0.98      0.97      0.97        39\n'
         'weighted avg       0.98      0.97      0.97        39\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      1.00      0.99        45\n'
          '           1       1.00      0.98      0.99        60\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           0.99       138\n'
          '   macro avg       0.99      0.99      0.99       138\n'
          'weighted avg       0.99      0.99      0.99       138\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
140
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.76      0.87        17\n'
         '           1       0.76      1.00      0.87        13\n'
         '           2       1.00      1.00      1.00         7\n'
         '\n'
         '    accuracy                           0.89        37\n'
         '   macro avg       0.92      0.92      0.91        37\n'
         'weighted avg       0.92      0.89      0.89        37\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        41\n'
          '           1       0.98      0.97      0.97        58\n'
          '           2       0.95      0.98      0.96        41\n'
          '\n'
          '    accuracy                           0.98       140\n'
          '   macro avg       0.98      0.98      0.98       140\n'
          'weighted avg       0.98      0.98      0.98       140\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
134
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.83      0.91        12\n'
         '           1       0.81      0.81      0.81        16\n'
         '           2       0.71      0.80      0.75        15\n'
         '\n'
         '    accuracy                           0.81        43\n'
         '   macro avg       0.84      0.82      0.82        43\n'
         'weighted avg       0.83      0.81      0.82        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        46\n'
          '           1       1.00      0.95      0.97        55\n'
          '           2       0.89      1.00      0.94        33\n'
          '\n'
          '    accuracy                           0.97       134\n'
          '   macro avg       0.96      0.97      0.97       134\n'
          'weighted avg       0.97      0.97      0.97       134\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
128
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.92      0.96        13\n'
         '           1       0.96      1.00      0.98        24\n'
         '           2       1.00      1.00      1.00        12\n'
         '\n'
         '    accuracy                           0.98        49\n'
         '   macro avg       0.99      0.97      0.98        49\n'
         'weighted avg       0.98      0.98      0.98        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      0.98      0.98        45\n'
          '           1       0.98      0.94      0.96        47\n'
          '           2       0.95      1.00      0.97        36\n'
          '\n'
          '    accuracy                           0.97       128\n'
          '   macro avg       0.97      0.97      0.97       128\n'
          'weighted avg       0.97      0.97      0.97       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
115
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.81      0.91      0.86        23\n'
         '           1       0.87      0.77      0.82        26\n'
         '           2       0.46      0.46      0.46        13\n'
         '\n'
         '    accuracy                           0.76        62\n'
         '   macro avg       0.71      0.71      0.71        62\n'
         'weighted avg       0.76      0.76      0.76        62\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       1.00      1.00      1.00        45\n'
          '           2       1.00      1.00      1.00        35\n'
          '\n'
          '    accuracy                           1.00       115\n'
          '   macro avg       1.00      1.00      1.00       115\n'
          'weighted avg       1.00      1.00      1.00       115\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
139
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.93      1.00      0.96        13\n'
         '           1       0.92      0.86      0.89        14\n'
         '           2       0.82      0.82      0.82        11\n'
         '\n'
         '    accuracy                           0.89        38\n'
         '   macro avg       0.89      0.89      0.89        38\n'
         'weighted avg       0.89      0.89      0.89        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        45\n'
          '           1       1.00      1.00      1.00        57\n'
          '           2       1.00      1.00      1.00        37\n'
          '\n'
          '    accuracy                           1.00       139\n'
          '   macro avg       1.00      1.00      1.00       139\n'
          'weighted avg       1.00      1.00      1.00       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
99
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      1.00      0.98        20\n'
         '           1       1.00      0.97      0.98        32\n'
         '           2       0.96      0.96      0.96        26\n'
         '\n'
         '    accuracy                           0.97        78\n'
         '   macro avg       0.97      0.98      0.97        78\n'
         'weighted avg       0.97      0.97      0.97        78\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.95      1.00      0.97        38\n'
          '           1       1.00      0.90      0.95        39\n'
          '           2       0.92      1.00      0.96        22\n'
          '\n'
          '    accuracy                           0.96        99\n'
          '   macro avg       0.96      0.97      0.96        99\n'
          'weighted avg       0.96      0.96      0.96        99\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
126
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.92      0.96        12\n'
         '           1       0.96      0.96      0.96        24\n'
         '           2       0.94      1.00      0.97        15\n'
         '\n'
         '    accuracy                           0.96        51\n'
         '   macro avg       0.97      0.96      0.96        51\n'
         'weighted avg       0.96      0.96      0.96        51\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.96      0.98        46\n'
          '           1       0.96      1.00      0.98        47\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           0.98       126\n'
          '   macro avg       0.99      0.99      0.99       126\n'
          'weighted avg       0.98      0.98      0.98       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
128
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.83      0.91      0.87        22\n'
         '           1       0.79      0.85      0.81        13\n'
         '           2       0.91      0.71      0.80        14\n'
         '\n'
         '    accuracy                           0.84        49\n'
         '   macro avg       0.84      0.82      0.83        49\n'
         'weighted avg       0.84      0.84      0.84        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        36\n'
          '           1       0.97      1.00      0.98        58\n'
          '           2       1.00      0.97      0.99        34\n'
          '\n'
          '    accuracy                           0.98       128\n'
          '   macro avg       0.99      0.98      0.98       128\n'
          'weighted avg       0.98      0.98      0.98       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
126
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.95      0.97        20\n'
         '           1       0.95      1.00      0.98        21\n'
         '           2       1.00      1.00      1.00        10\n'
         '\n'
         '    accuracy                           0.98        51\n'
         '   macro avg       0.98      0.98      0.98        51\n'
         'weighted avg       0.98      0.98      0.98        51\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        38\n'
          '           1       1.00      0.98      0.99        50\n'
          '           2       0.97      1.00      0.99        38\n'
          '\n'
          '    accuracy                           0.99       126\n'
          '   macro avg       0.99      0.99      0.99       126\n'
          'weighted avg       0.99      0.99      0.99       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
103
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.81      0.88      0.85        25\n'
         '           1       0.85      0.79      0.82        29\n'
         '           2       0.65      0.65      0.65        20\n'
         '\n'
         '    accuracy                           0.78        74\n'
         '   macro avg       0.77      0.77      0.77        74\n'
         'weighted avg       0.78      0.78      0.78        74\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.89      0.97      0.93        33\n'
          '           1       0.95      0.88      0.91        42\n'
          '           2       0.86      0.86      0.86        28\n'
          '\n'
          '    accuracy                           0.90       103\n'
          '   macro avg       0.90      0.90      0.90       103\n'
          'weighted avg       0.90      0.90      0.90       103\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
104
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.87      1.00      0.93        27\n'
         '           1       1.00      0.79      0.88        28\n'
         '           2       0.90      1.00      0.95        18\n'
         '\n'
         '    accuracy                           0.92        73\n'
         '   macro avg       0.92      0.93      0.92        73\n'
         'weighted avg       0.93      0.92      0.92        73\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      1.00      0.98        31\n'
          '           1       1.00      0.98      0.99        43\n'
          '           2       1.00      1.00      1.00        30\n'
          '\n'
          '    accuracy                           0.99       104\n'
          '   macro avg       0.99      0.99      0.99       104\n'
          'weighted avg       0.99      0.99      0.99       104\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
139
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.85      1.00      0.92        11\n'
         '           1       1.00      0.86      0.92        14\n'
         '           2       0.92      0.92      0.92        13\n'
         '\n'
         '    accuracy                           0.92        38\n'
         '   macro avg       0.92      0.93      0.92        38\n'
         'weighted avg       0.93      0.92      0.92        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      1.00      0.99        47\n'
          '           1       1.00      0.96      0.98        57\n'
          '           2       0.97      1.00      0.99        35\n'
          '\n'
          '    accuracy                           0.99       139\n'
          '   macro avg       0.98      0.99      0.99       139\n'
          'weighted avg       0.99      0.99      0.99       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
114
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.96      0.98        23\n'
         '           1       0.91      1.00      0.95        21\n'
         '           2       1.00      0.95      0.97        19\n'
         '\n'
         '    accuracy                           0.97        63\n'
         '   macro avg       0.97      0.97      0.97        63\n'
         'weighted avg       0.97      0.97      0.97        63\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        35\n'
          '           1       0.98      0.98      0.98        50\n'
          '           2       0.97      1.00      0.98        29\n'
          '\n'
          '    accuracy                           0.98       114\n'
          '   macro avg       0.98      0.98      0.98       114\n'
          'weighted avg       0.98      0.98      0.98       114\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
94
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.91      0.94      0.92        31\n'
         '           1       0.77      0.67      0.72        36\n'
         '           2       0.50      0.62      0.56        16\n'
         '\n'
         '    accuracy                           0.76        83\n'
         '   macro avg       0.73      0.74      0.73        83\n'
         'weighted avg       0.77      0.76      0.76        83\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        27\n'
          '           1       1.00      1.00      1.00        35\n'
          '           2       1.00      1.00      1.00        32\n'
          '\n'
          '    accuracy                           1.00        94\n'
          '   macro avg       1.00      1.00      1.00        94\n'
          'weighted avg       1.00      1.00      1.00        94\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
120
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        15\n'
         '           1       1.00      1.00      1.00        27\n'
         '           2       1.00      1.00      1.00        15\n'
         '\n'
         '    accuracy                           1.00        57\n'
         '   macro avg       1.00      1.00      1.00        57\n'
         'weighted avg       1.00      1.00      1.00        57\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        43\n'
          '           1       0.98      0.98      0.98        44\n'
          '           2       0.97      1.00      0.99        33\n'
          '\n'
          '    accuracy                           0.98       120\n'
          '   macro avg       0.98      0.98      0.98       120\n'
          'weighted avg       0.98      0.98      0.98       120\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
128
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.93      0.82      0.87        17\n'
         '           1       0.76      0.95      0.84        20\n'
         '           2       0.67      0.50      0.57        12\n'
         '\n'
         '    accuracy                           0.80        49\n'
         '   macro avg       0.79      0.76      0.76        49\n'
         'weighted avg       0.80      0.80      0.79        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        41\n'
          '           1       1.00      1.00      1.00        51\n'
          '           2       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           1.00       128\n'
          '   macro avg       1.00      1.00      1.00       128\n'
          'weighted avg       1.00      1.00      1.00       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
109
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.87      0.95      0.91        21\n'
         '           1       0.93      0.93      0.93        29\n'
         '           2       1.00      0.89      0.94        18\n'
         '\n'
         '    accuracy                           0.93        68\n'
         '   macro avg       0.93      0.92      0.93        68\n'
         'weighted avg       0.93      0.93      0.93        68\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        37\n'
          '           1       1.00      1.00      1.00        42\n'
          '           2       1.00      1.00      1.00        30\n'
          '\n'
          '    accuracy                           1.00       109\n'
          '   macro avg       1.00      1.00      1.00       109\n'
          'weighted avg       1.00      1.00      1.00       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
116
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      1.00      0.98        25\n'
         '           1       1.00      0.95      0.98        21\n'
         '           2       1.00      1.00      1.00        15\n'
         '\n'
         '    accuracy                           0.98        61\n'
         '   macro avg       0.99      0.98      0.99        61\n'
         'weighted avg       0.98      0.98      0.98        61\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      1.00      0.99        33\n'
          '           1       1.00      0.98      0.99        50\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           0.99       116\n'
          '   macro avg       0.99      0.99      0.99       116\n'
          'weighted avg       0.99      0.99      0.99       116\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
92
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.92      0.96        24\n'
         '           1       0.91      0.97      0.94        33\n'
         '           2       0.96      0.96      0.96        28\n'
         '\n'
         '    accuracy                           0.95        85\n'
         '   macro avg       0.96      0.95      0.95        85\n'
         'weighted avg       0.95      0.95      0.95        85\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        34\n'
          '           1       0.97      1.00      0.99        38\n'
          '           2       1.00      1.00      1.00        20\n'
          '\n'
          '    accuracy                           0.99        92\n'
          '   macro avg       0.99      0.99      0.99        92\n'
          'weighted avg       0.99      0.99      0.99        92\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
134
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.76      1.00      0.87        13\n'
         '           1       0.62      0.71      0.67        14\n'
         '           2       0.70      0.44      0.54        16\n'
         '\n'
         '    accuracy                           0.70        43\n'
         '   macro avg       0.70      0.72      0.69        43\n'
         'weighted avg       0.70      0.70      0.68        43\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        45\n'
          '           1       0.98      0.96      0.97        57\n'
          '           2       0.91      0.97      0.94        32\n'
          '\n'
          '    accuracy                           0.97       134\n'
          '   macro avg       0.96      0.97      0.97       134\n'
          'weighted avg       0.97      0.97      0.97       134\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
112
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.92      0.96        25\n'
         '           1       0.91      1.00      0.95        21\n'
         '           2       1.00      1.00      1.00        19\n'
         '\n'
         '    accuracy                           0.97        65\n'
         '   macro avg       0.97      0.97      0.97        65\n'
         'weighted avg       0.97      0.97      0.97        65\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       1.00      0.98      0.99        50\n'
          '           2       0.97      1.00      0.98        29\n'
          '\n'
          '    accuracy                           0.99       112\n'
          '   macro avg       0.99      0.99      0.99       112\n'
          'weighted avg       0.99      0.99      0.99       112\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
100
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      0.88      0.92        25\n'
         '           1       0.76      0.87      0.81        30\n'
         '           2       0.70      0.64      0.67        22\n'
         '\n'
         '    accuracy                           0.81        77\n'
         '   macro avg       0.81      0.79      0.80        77\n'
         'weighted avg       0.81      0.81      0.80        77\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       1.00      1.00      1.00        41\n'
          '           2       1.00      1.00      1.00        26\n'
          '\n'
          '    accuracy                           1.00       100\n'
          '   macro avg       1.00      1.00      1.00       100\n'
          'weighted avg       1.00      1.00      1.00       100\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
127
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        13\n'
         '           1       1.00      0.83      0.90        23\n'
         '           2       0.78      1.00      0.88        14\n'
         '\n'
         '    accuracy                           0.92        50\n'
         '   macro avg       0.93      0.94      0.93        50\n'
         'weighted avg       0.94      0.92      0.92        50\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        45\n'
          '           1       1.00      1.00      1.00        48\n'
          '           2       1.00      1.00      1.00        34\n'
          '\n'
          '    accuracy                           1.00       127\n'
          '   macro avg       1.00      1.00      1.00       127\n'
          'weighted avg       1.00      1.00      1.00       127\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
105
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      0.92      0.94        24\n'
         '           1       0.91      0.88      0.89        24\n'
         '           2       0.88      0.96      0.92        24\n'
         '\n'
         '    accuracy                           0.92        72\n'
         '   macro avg       0.92      0.92      0.92        72\n'
         'weighted avg       0.92      0.92      0.92        72\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        34\n'
          '           1       1.00      1.00      1.00        47\n'
          '           2       1.00      1.00      1.00        24\n'
          '\n'
          '    accuracy                           1.00       105\n'
          '   macro avg       1.00      1.00      1.00       105\n'
          'weighted avg       1.00      1.00      1.00       105\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
97
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.92      0.96        25\n'
         '           1       0.93      0.93      0.93        29\n'
         '           2       0.93      1.00      0.96        26\n'
         '\n'
         '    accuracy                           0.95        80\n'
         '   macro avg       0.95      0.95      0.95        80\n'
         'weighted avg       0.95      0.95      0.95        80\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.98        33\n'
          '           1       0.98      1.00      0.99        42\n'
          '           2       1.00      1.00      1.00        22\n'
          '\n'
          '    accuracy                           0.99        97\n'
          '   macro avg       0.99      0.99      0.99        97\n'
          'weighted avg       0.99      0.99      0.99        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
93
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.93      0.88      0.90        32\n'
         '           1       0.73      0.73      0.73        37\n'
         '           2       0.47      0.53      0.50        15\n'
         '\n'
         '    accuracy                           0.75        84\n'
         '   macro avg       0.71      0.71      0.71        84\n'
         'weighted avg       0.76      0.75      0.75        84\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        26\n'
          '           1       1.00      1.00      1.00        34\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           1.00        93\n'
          '   macro avg       1.00      1.00      1.00        93\n'
          'weighted avg       1.00      1.00      1.00        93\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
137
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        15\n'
         '           1       1.00      1.00      1.00        16\n'
         '           2       1.00      1.00      1.00         9\n'
         '\n'
         '    accuracy                           1.00        40\n'
         '   macro avg       1.00      1.00      1.00        40\n'
         'weighted avg       1.00      1.00      1.00        40\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      0.98      0.98        43\n'
          '           1       0.98      0.96      0.97        55\n'
          '           2       0.97      1.00      0.99        39\n'
          '\n'
          '    accuracy                           0.98       137\n'
          '   macro avg       0.98      0.98      0.98       137\n'
          'weighted avg       0.98      0.98      0.98       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
89
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.83      0.94      0.88        31\n'
         '           1       0.76      0.59      0.67        32\n'
         '           2       0.61      0.68      0.64        25\n'
         '\n'
         '    accuracy                           0.74        88\n'
         '   macro avg       0.73      0.74      0.73        88\n'
         'weighted avg       0.74      0.74      0.73        88\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        27\n'
          '           1       1.00      1.00      1.00        39\n'
          '           2       1.00      1.00      1.00        23\n'
          '\n'
          '    accuracy                           1.00        89\n'
          '   macro avg       1.00      1.00      1.00        89\n'
          'weighted avg       1.00      1.00      1.00        89\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
94
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.97      1.00      0.98        28\n'
         '           1       0.92      0.88      0.90        26\n'
         '           2       0.93      0.93      0.93        29\n'
         '\n'
         '    accuracy                           0.94        83\n'
         '   macro avg       0.94      0.94      0.94        83\n'
         'weighted avg       0.94      0.94      0.94        83\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       1.00      1.00      1.00        45\n'
          '           2       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00        94\n'
          '   macro avg       1.00      1.00      1.00        94\n'
          'weighted avg       1.00      1.00      1.00        94\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
128
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       1.00      0.95      0.98        21\n'
         '           2       0.93      1.00      0.97        14\n'
         '\n'
         '    accuracy                           0.98        49\n'
         '   macro avg       0.98      0.98      0.98        49\n'
         'weighted avg       0.98      0.98      0.98        49\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      1.00      0.99        44\n'
          '           1       1.00      0.94      0.97        50\n'
          '           2       0.94      1.00      0.97        34\n'
          '\n'
          '    accuracy                           0.98       128\n'
          '   macro avg       0.97      0.98      0.98       128\n'
          'weighted avg       0.98      0.98      0.98       128\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
103
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.93      0.96        28\n'
         '           1       0.81      1.00      0.90        26\n'
         '           2       1.00      0.80      0.89        20\n'
         '\n'
         '    accuracy                           0.92        74\n'
         '   macro avg       0.94      0.91      0.92        74\n'
         'weighted avg       0.93      0.92      0.92        74\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        30\n'
          '           1       1.00      1.00      1.00        45\n'
          '           2       1.00      1.00      1.00        28\n'
          '\n'
          '    accuracy                           1.00       103\n'
          '   macro avg       1.00      1.00      1.00       103\n'
          'weighted avg       1.00      1.00      1.00       103\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
126
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.86      0.90      0.88        21\n'
         '           1       0.65      0.69      0.67        16\n'
         '           2       0.67      0.57      0.62        14\n'
         '\n'
         '    accuracy                           0.75        51\n'
         '   macro avg       0.73      0.72      0.72        51\n'
         'weighted avg       0.74      0.75      0.74        51\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        37\n'
          '           1       0.98      0.98      0.98        55\n'
          '           2       0.97      1.00      0.99        34\n'
          '\n'
          '    accuracy                           0.98       126\n'
          '   macro avg       0.98      0.98      0.98       126\n'
          'weighted avg       0.98      0.98      0.98       126\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
137
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.91      0.95        11\n'
         '           1       0.93      0.93      0.93        14\n'
         '           2       0.94      1.00      0.97        15\n'
         '\n'
         '    accuracy                           0.95        40\n'
         '   macro avg       0.96      0.95      0.95        40\n'
         'weighted avg       0.95      0.95      0.95        40\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        47\n'
          '           1       1.00      1.00      1.00        57\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           1.00       137\n'
          '   macro avg       1.00      1.00      1.00       137\n'
          'weighted avg       1.00      1.00      1.00       137\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
106
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.93      1.00      0.96        25\n'
         '           1       0.62      0.69      0.65        26\n'
         '           2       0.60      0.45      0.51        20\n'
         '\n'
         '    accuracy                           0.73        71\n'
         '   macro avg       0.72      0.71      0.71        71\n'
         'weighted avg       0.72      0.73      0.72        71\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       1.00      1.00      1.00        45\n'
          '           2       1.00      1.00      1.00        28\n'
          '\n'
          '    accuracy                           1.00       106\n'
          '   macro avg       1.00      1.00      1.00       106\n'
          'weighted avg       1.00      1.00      1.00       106\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
130
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.94      0.94      0.94        16\n'
         '           1       0.94      1.00      0.97        16\n'
         '           2       1.00      0.93      0.97        15\n'
         '\n'
         '    accuracy                           0.96        47\n'
         '   macro avg       0.96      0.96      0.96        47\n'
         'weighted avg       0.96      0.96      0.96        47\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        42\n'
          '           1       1.00      1.00      1.00        55\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           1.00       130\n'
          '   macro avg       1.00      1.00      1.00       130\n'
          'weighted avg       1.00      1.00      1.00       130\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
130
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        15\n'
         '           1       1.00      1.00      1.00        19\n'
         '           2       1.00      1.00      1.00        13\n'
         '\n'
         '    accuracy                           1.00        47\n'
         '   macro avg       1.00      1.00      1.00        47\n'
         'weighted avg       1.00      1.00      1.00        47\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        43\n'
          '           1       1.00      1.00      1.00        52\n'
          '           2       1.00      1.00      1.00        35\n'
          '\n'
          '    accuracy                           1.00       130\n'
          '   macro avg       1.00      1.00      1.00       130\n'
          'weighted avg       1.00      1.00      1.00       130\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
123
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.95      0.98        22\n'
         '           1       0.94      0.94      0.94        17\n'
         '           2       0.94      1.00      0.97        15\n'
         '\n'
         '    accuracy                           0.96        54\n'
         '   macro avg       0.96      0.97      0.96        54\n'
         'weighted avg       0.96      0.96      0.96        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        36\n'
          '           1       0.96      0.98      0.97        54\n'
          '           2       0.97      0.97      0.97        33\n'
          '\n'
          '    accuracy                           0.98       123\n'
          '   macro avg       0.98      0.97      0.98       123\n'
          'weighted avg       0.98      0.98      0.98       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
107
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.91      0.84      0.87        25\n'
         '           1       0.96      0.68      0.79        34\n'
         '           2       0.43      0.91      0.59        11\n'
         '\n'
         '    accuracy                           0.77        70\n'
         '   macro avg       0.77      0.81      0.75        70\n'
         'weighted avg       0.86      0.77      0.79        70\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.98        33\n'
          '           1       1.00      1.00      1.00        37\n'
          '           2       0.97      1.00      0.99        37\n'
          '\n'
          '    accuracy                           0.99       107\n'
          '   macro avg       0.99      0.99      0.99       107\n'
          'weighted avg       0.99      0.99      0.99       107\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
116
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.96      0.98        27\n'
         '           1       0.94      1.00      0.97        17\n'
         '           2       1.00      1.00      1.00        17\n'
         '\n'
         '    accuracy                           0.98        61\n'
         '   macro avg       0.98      0.99      0.98        61\n'
         'weighted avg       0.98      0.98      0.98        61\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.94      0.97        31\n'
          '           1       0.96      0.98      0.97        54\n'
          '           2       0.97      1.00      0.98        31\n'
          '\n'
          '    accuracy                           0.97       116\n'
          '   macro avg       0.98      0.97      0.97       116\n'
          'weighted avg       0.97      0.97      0.97       116\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
109
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      0.91      0.93        23\n'
         '           1       0.91      0.75      0.82        28\n'
         '           2       0.61      0.82      0.70        17\n'
         '\n'
         '    accuracy                           0.82        68\n'
         '   macro avg       0.83      0.83      0.82        68\n'
         'weighted avg       0.85      0.82      0.83        68\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       1.00      1.00      1.00        43\n'
          '           2       1.00      1.00      1.00        31\n'
          '\n'
          '    accuracy                           1.00       109\n'
          '   macro avg       1.00      1.00      1.00       109\n'
          'weighted avg       1.00      1.00      1.00       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
116
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      1.00      0.98        23\n'
         '           1       1.00      0.85      0.92        26\n'
         '           2       0.80      1.00      0.89        12\n'
         '\n'
         '    accuracy                           0.93        61\n'
         '   macro avg       0.92      0.95      0.93        61\n'
         'weighted avg       0.94      0.93      0.93        61\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        35\n'
          '           1       1.00      1.00      1.00        45\n'
          '           2       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           1.00       116\n'
          '   macro avg       1.00      1.00      1.00       116\n'
          'weighted avg       1.00      1.00      1.00       116\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
91
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.89      1.00      0.94        25\n'
         '           1       1.00      0.92      0.96        36\n'
         '           2       0.96      0.96      0.96        25\n'
         '\n'
         '    accuracy                           0.95        86\n'
         '   macro avg       0.95      0.96      0.95        86\n'
         'weighted avg       0.96      0.95      0.95        86\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       1.00      0.97      0.99        35\n'
          '           2       0.96      1.00      0.98        23\n'
          '\n'
          '    accuracy                           0.99        91\n'
          '   macro avg       0.99      0.99      0.99        91\n'
          'weighted avg       0.99      0.99      0.99        91\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
132
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        11\n'
         '           1       0.94      1.00      0.97        16\n'
         '           2       1.00      0.94      0.97        18\n'
         '\n'
         '    accuracy                           0.98        45\n'
         '   macro avg       0.98      0.98      0.98        45\n'
         'weighted avg       0.98      0.98      0.98        45\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      0.96      0.97        47\n'
          '           1       0.96      0.96      0.96        55\n'
          '           2       0.97      1.00      0.98        30\n'
          '\n'
          '    accuracy                           0.97       132\n'
          '   macro avg       0.97      0.97      0.97       132\n'
          'weighted avg       0.97      0.97      0.97       132\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
114
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.89      0.73      0.80        22\n'
         '           1       0.64      0.58      0.61        24\n'
         '           2       0.57      0.76      0.65        17\n'
         '\n'
         '    accuracy                           0.68        63\n'
         '   macro avg       0.70      0.69      0.69        63\n'
         'weighted avg       0.71      0.68      0.69        63\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       1.00      1.00      1.00        47\n'
          '           2       1.00      1.00      1.00        31\n'
          '\n'
          '    accuracy                           1.00       114\n'
          '   macro avg       1.00      1.00      1.00       114\n'
          'weighted avg       1.00      1.00      1.00       114\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
123
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.95      0.97        20\n'
         '           1       0.96      1.00      0.98        24\n'
         '           2       1.00      1.00      1.00        10\n'
         '\n'
         '    accuracy                           0.98        54\n'
         '   macro avg       0.99      0.98      0.98        54\n'
         'weighted avg       0.98      0.98      0.98        54\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        38\n'
          '           1       1.00      0.98      0.99        47\n'
          '           2       0.97      1.00      0.99        38\n'
          '\n'
          '    accuracy                           0.99       123\n'
          '   macro avg       0.99      0.99      0.99       123\n'
          'weighted avg       0.99      0.99      0.99       123\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
102
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      0.83      0.89        29\n'
         '           1       0.79      0.76      0.77        29\n'
         '           2       0.55      0.71      0.62        17\n'
         '\n'
         '    accuracy                           0.77        75\n'
         '   macro avg       0.76      0.76      0.76        75\n'
         'weighted avg       0.80      0.77      0.78        75\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        29\n'
          '           1       1.00      1.00      1.00        42\n'
          '           2       1.00      1.00      1.00        31\n'
          '\n'
          '    accuracy                           1.00       102\n'
          '   macro avg       1.00      1.00      1.00       102\n'
          'weighted avg       1.00      1.00      1.00       102\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
89
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.94      1.00      0.97        30\n'
         '           1       0.97      0.91      0.94        35\n'
         '           2       0.91      0.91      0.91        23\n'
         '\n'
         '    accuracy                           0.94        88\n'
         '   macro avg       0.94      0.94      0.94        88\n'
         'weighted avg       0.94      0.94      0.94        88\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        28\n'
          '           1       1.00      1.00      1.00        36\n'
          '           2       1.00      1.00      1.00        25\n'
          '\n'
          '    accuracy                           1.00        89\n'
          '   macro avg       1.00      1.00      1.00        89\n'
          'weighted avg       1.00      1.00      1.00        89\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
114
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      1.00      0.98        20\n'
         '           1       1.00      0.93      0.96        27\n'
         '           2       0.94      1.00      0.97        16\n'
         '\n'
         '    accuracy                           0.97        63\n'
         '   macro avg       0.96      0.98      0.97        63\n'
         'weighted avg       0.97      0.97      0.97        63\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.95      1.00      0.97        38\n'
          '           1       1.00      0.98      0.99        44\n'
          '           2       1.00      0.97      0.98        32\n'
          '\n'
          '    accuracy                           0.98       114\n'
          '   macro avg       0.98      0.98      0.98       114\n'
          'weighted avg       0.98      0.98      0.98       114\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
136
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        10\n'
         '           1       1.00      1.00      1.00        16\n'
         '           2       1.00      1.00      1.00        15\n'
         '\n'
         '    accuracy                           1.00        41\n'
         '   macro avg       1.00      1.00      1.00        41\n'
         'weighted avg       1.00      1.00      1.00        41\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.96      0.98        48\n'
          '           1       0.95      0.98      0.96        55\n'
          '           2       0.97      0.97      0.97        33\n'
          '\n'
          '    accuracy                           0.97       136\n'
          '   macro avg       0.97      0.97      0.97       136\n'
          'weighted avg       0.97      0.97      0.97       136\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
118
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.84      0.84      0.84        19\n'
         '           1       0.67      0.67      0.67        21\n'
         '           2       0.74      0.74      0.74        19\n'
         '\n'
         '    accuracy                           0.75        59\n'
         '   macro avg       0.75      0.75      0.75        59\n'
         'weighted avg       0.75      0.75      0.75        59\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        39\n'
          '           1       1.00      1.00      1.00        50\n'
          '           2       1.00      1.00      1.00        29\n'
          '\n'
          '    accuracy                           1.00       118\n'
          '   macro avg       1.00      1.00      1.00       118\n'
          'weighted avg       1.00      1.00      1.00       118\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      1.00      0.97        18\n'
         '           1       1.00      0.92      0.96        37\n'
         '           2       0.93      1.00      0.96        26\n'
         '\n'
         '    accuracy                           0.96        81\n'
         '   macro avg       0.96      0.97      0.96        81\n'
         'weighted avg       0.97      0.96      0.96        81\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        40\n'
          '           1       0.97      1.00      0.99        34\n'
          '           2       1.00      1.00      1.00        22\n'
          '\n'
          '    accuracy                           0.99        96\n'
          '   macro avg       0.99      0.99      0.99        96\n'
          'weighted avg       0.99      0.99      0.99        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
114
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.91      1.00      0.95        20\n'
         '           1       0.83      0.90      0.86        21\n'
         '           2       0.89      0.73      0.80        22\n'
         '\n'
         '    accuracy                           0.87        63\n'
         '   macro avg       0.87      0.88      0.87        63\n'
         'weighted avg       0.87      0.87      0.87        63\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        38\n'
          '           1       1.00      1.00      1.00        50\n'
          '           2       1.00      1.00      1.00        26\n'
          '\n'
          '    accuracy                           1.00       114\n'
          '   macro avg       1.00      1.00      1.00       114\n'
          'weighted avg       1.00      1.00      1.00       114\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
130
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.93      0.97        15\n'
         '           1       0.95      0.95      0.95        20\n'
         '           2       0.92      1.00      0.96        12\n'
         '\n'
         '    accuracy                           0.96        47\n'
         '   macro avg       0.96      0.96      0.96        47\n'
         'weighted avg       0.96      0.96      0.96        47\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        43\n'
          '           1       0.98      1.00      0.99        51\n'
          '           2       1.00      1.00      1.00        36\n'
          '\n'
          '    accuracy                           0.99       130\n'
          '   macro avg       0.99      0.99      0.99       130\n'
          'weighted avg       0.99      0.99      0.99       130\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
95
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.93      1.00      0.96        27\n'
         '           1       1.00      0.88      0.94        34\n'
         '           2       0.91      1.00      0.95        21\n'
         '\n'
         '    accuracy                           0.95        82\n'
         '   macro avg       0.95      0.96      0.95        82\n'
         'weighted avg       0.96      0.95      0.95        82\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        31\n'
          '           1       1.00      0.95      0.97        37\n'
          '           2       0.93      1.00      0.96        27\n'
          '\n'
          '    accuracy                           0.98        95\n'
          '   macro avg       0.98      0.98      0.98        95\n'
          'weighted avg       0.98      0.98      0.98        95\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
89
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.94      0.97        32\n'
         '           1       0.94      0.97      0.96        33\n'
         '           2       0.96      1.00      0.98        23\n'
         '\n'
         '    accuracy                           0.97        88\n'
         '   macro avg       0.97      0.97      0.97        88\n'
         'weighted avg       0.97      0.97      0.97        88\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.96      0.98        26\n'
          '           1       0.97      1.00      0.99        38\n'
          '           2       1.00      1.00      1.00        25\n'
          '\n'
          '    accuracy                           0.99        89\n'
          '   macro avg       0.99      0.99      0.99        89\n'
          'weighted avg       0.99      0.99      0.99        89\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
109
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.80      1.00      0.89        20\n'
         '           1       0.79      0.71      0.75        31\n'
         '           2       0.60      0.53      0.56        17\n'
         '\n'
         '    accuracy                           0.75        68\n'
         '   macro avg       0.73      0.75      0.73        68\n'
         'weighted avg       0.74      0.75      0.74        68\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        38\n'
          '           1       1.00      1.00      1.00        40\n'
          '           2       0.97      1.00      0.98        31\n'
          '\n'
          '    accuracy                           0.99       109\n'
          '   macro avg       0.99      0.99      0.99       109\n'
          'weighted avg       0.99      0.99      0.99       109\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
97
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.97      1.00      0.98        30\n'
         '           1       1.00      0.97      0.98        29\n'
         '           2       1.00      1.00      1.00        21\n'
         '\n'
         '    accuracy                           0.99        80\n'
         '   macro avg       0.99      0.99      0.99        80\n'
         'weighted avg       0.99      0.99      0.99        80\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.96      0.96      0.96        28\n'
          '           1       0.98      0.95      0.96        42\n'
          '           2       0.96      1.00      0.98        27\n'
          '\n'
          '    accuracy                           0.97        97\n'
          '   macro avg       0.97      0.97      0.97        97\n'
          'weighted avg       0.97      0.97      0.97        97\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
135
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.89      0.73      0.80        11\n'
         '           1       0.71      0.67      0.69        18\n'
         '           2       0.56      0.69      0.62        13\n'
         '\n'
         '    accuracy                           0.69        42\n'
         '   macro avg       0.72      0.70      0.70        42\n'
         'weighted avg       0.71      0.69      0.70        42\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        47\n'
          '           1       1.00      1.00      1.00        53\n'
          '           2       1.00      1.00      1.00        35\n'
          '\n'
          '    accuracy                           1.00       135\n'
          '   macro avg       1.00      1.00      1.00       135\n'
          'weighted avg       1.00      1.00      1.00       135\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
140
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.67      0.80        12\n'
         '           1       0.75      0.88      0.81        17\n'
         '           2       0.78      0.88      0.82         8\n'
         '\n'
         '    accuracy                           0.81        37\n'
         '   macro avg       0.84      0.81      0.81        37\n'
         'weighted avg       0.84      0.81      0.81        37\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        46\n'
          '           1       0.98      1.00      0.99        54\n'
          '           2       1.00      1.00      1.00        40\n'
          '\n'
          '    accuracy                           0.99       140\n'
          '   macro avg       0.99      0.99      0.99       140\n'
          'weighted avg       0.99      0.99      0.99       140\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
110
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        28\n'
         '           1       1.00      1.00      1.00        25\n'
         '           2       1.00      1.00      1.00        14\n'
         '\n'
         '    accuracy                           1.00        67\n'
         '   macro avg       1.00      1.00      1.00        67\n'
         'weighted avg       1.00      1.00      1.00        67\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      1.00      0.98        30\n'
          '           1       1.00      0.98      0.99        46\n'
          '           2       1.00      1.00      1.00        34\n'
          '\n'
          '    accuracy                           0.99       110\n'
          '   macro avg       0.99      0.99      0.99       110\n'
          'weighted avg       0.99      0.99      0.99       110\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
92
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.92      0.77      0.84        31\n'
         '           1       0.80      0.88      0.84        32\n'
         '           2       0.92      1.00      0.96        22\n'
         '\n'
         '    accuracy                           0.87        85\n'
         '   macro avg       0.88      0.88      0.88        85\n'
         'weighted avg       0.88      0.87      0.87        85\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        27\n'
          '           1       1.00      1.00      1.00        39\n'
          '           2       1.00      1.00      1.00        26\n'
          '\n'
          '    accuracy                           1.00        92\n'
          '   macro avg       1.00      1.00      1.00        92\n'
          'weighted avg       1.00      1.00      1.00        92\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
89
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.80      0.92      0.86        26\n'
         '           1       0.81      0.50      0.62        42\n'
         '           2       0.44      0.70      0.54        20\n'
         '\n'
         '    accuracy                           0.67        88\n'
         '   macro avg       0.68      0.71      0.67        88\n'
         'weighted avg       0.72      0.67      0.67        88\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.88      0.94      0.91        32\n'
          '           1       1.00      0.76      0.86        29\n'
          '           2       0.79      0.93      0.85        28\n'
          '\n'
          '    accuracy                           0.88        89\n'
          '   macro avg       0.89      0.87      0.87        89\n'
          'weighted avg       0.89      0.88      0.88        89\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
93
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.96      1.00      0.98        24\n'
         '           1       1.00      0.91      0.96        35\n'
         '           2       0.93      1.00      0.96        25\n'
         '\n'
         '    accuracy                           0.96        84\n'
         '   macro avg       0.96      0.97      0.97        84\n'
         'weighted avg       0.97      0.96      0.96        84\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      1.00      0.99        34\n'
          '           1       1.00      0.97      0.99        36\n'
          '           2       1.00      1.00      1.00        23\n'
          '\n'
          '    accuracy                           0.99        93\n'
          '   macro avg       0.99      0.99      0.99        93\n'
          'weighted avg       0.99      0.99      0.99        93\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
125
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.94      0.88      0.91        17\n'
         '           1       0.73      0.86      0.79        22\n'
         '           2       0.70      0.54      0.61        13\n'
         '\n'
         '    accuracy                           0.79        52\n'
         '   macro avg       0.79      0.76      0.77        52\n'
         'weighted avg       0.79      0.79      0.78        52\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        41\n'
          '           1       1.00      1.00      1.00        49\n'
          '           2       1.00      1.00      1.00        35\n'
          '\n'
          '    accuracy                           1.00       125\n'
          '   macro avg       1.00      1.00      1.00       125\n'
          'weighted avg       1.00      1.00      1.00       125\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
119
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      0.95      0.95        21\n'
         '           1       0.91      0.91      0.91        22\n'
         '           2       0.87      0.87      0.87        15\n'
         '\n'
         '    accuracy                           0.91        58\n'
         '   macro avg       0.91      0.91      0.91        58\n'
         'weighted avg       0.91      0.91      0.91        58\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.97      0.99        37\n'
          '           1       0.98      1.00      0.99        49\n'
          '           2       1.00      1.00      1.00        33\n'
          '\n'
          '    accuracy                           0.99       119\n'
          '   macro avg       0.99      0.99      0.99       119\n'
          'weighted avg       0.99      0.99      0.99       119\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
101
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      1.00      0.98        21\n'
         '           1       1.00      0.87      0.93        31\n'
         '           2       0.89      1.00      0.94        24\n'
         '\n'
         '    accuracy                           0.95        76\n'
         '   macro avg       0.95      0.96      0.95        76\n'
         'weighted avg       0.95      0.95      0.95        76\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      1.00      0.99        37\n'
          '           1       0.97      0.93      0.95        40\n'
          '           2       0.92      0.96      0.94        24\n'
          '\n'
          '    accuracy                           0.96       101\n'
          '   macro avg       0.96      0.96      0.96       101\n'
          'weighted avg       0.96      0.96      0.96       101\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
89
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.97      0.99        35\n'
         '           1       0.96      0.96      0.96        28\n'
         '           2       0.96      1.00      0.98        25\n'
         '\n'
         '    accuracy                           0.98        88\n'
         '   macro avg       0.98      0.98      0.98        88\n'
         'weighted avg       0.98      0.98      0.98        88\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.87      0.93        23\n'
          '           1       0.93      1.00      0.97        43\n'
          '           2       1.00      1.00      1.00        23\n'
          '\n'
          '    accuracy                           0.97        89\n'
          '   macro avg       0.98      0.96      0.97        89\n'
          'weighted avg       0.97      0.97      0.97        89\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
127
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.79      0.92      0.85        12\n'
         '           1       0.65      0.77      0.71        22\n'
         '           2       0.60      0.38      0.46        16\n'
         '\n'
         '    accuracy                           0.68        50\n'
         '   macro avg       0.68      0.69      0.67        50\n'
         'weighted avg       0.67      0.68      0.66        50\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.98      0.99        46\n'
          '           1       0.98      0.96      0.97        49\n'
          '           2       0.94      1.00      0.97        32\n'
          '\n'
          '    accuracy                           0.98       127\n'
          '   macro avg       0.97      0.98      0.98       127\n'
          'weighted avg       0.98      0.98      0.98       127\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
104
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.88      0.94        25\n'
         '           1       0.89      1.00      0.94        24\n'
         '           2       1.00      1.00      1.00        24\n'
         '\n'
         '    accuracy                           0.96        73\n'
         '   macro avg       0.96      0.96      0.96        73\n'
         'weighted avg       0.96      0.96      0.96        73\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        33\n'
          '           1       1.00      0.98      0.99        47\n'
          '           2       0.96      1.00      0.98        24\n'
          '\n'
          '    accuracy                           0.99       104\n'
          '   macro avg       0.99      0.99      0.99       104\n'
          'weighted avg       0.99      0.99      0.99       104\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
99
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.67      0.95      0.78        21\n'
         '           1       0.77      0.57      0.66        35\n'
         '           2       0.55      0.55      0.55        22\n'
         '\n'
         '    accuracy                           0.67        78\n'
         '   macro avg       0.66      0.69      0.66        78\n'
         'weighted avg       0.68      0.67      0.66        78\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.90      1.00      0.95        37\n'
          '           1       0.94      0.81      0.87        36\n'
          '           2       0.85      0.88      0.87        26\n'
          '\n'
          '    accuracy                           0.90        99\n'
          '   macro avg       0.90      0.90      0.89        99\n'
          'weighted avg       0.90      0.90      0.90        99\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
136
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       1.00      1.00      1.00        19\n'
         '           2       1.00      1.00      1.00         8\n'
         '\n'
         '    accuracy                           1.00        41\n'
         '   macro avg       1.00      1.00      1.00        41\n'
         'weighted avg       1.00      1.00      1.00        41\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        44\n'
          '           1       1.00      1.00      1.00        52\n'
          '           2       1.00      1.00      1.00        40\n'
          '\n'
          '    accuracy                           1.00       136\n'
          '   macro avg       1.00      1.00      1.00       136\n'
          'weighted avg       1.00      1.00      1.00       136\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
112
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      0.84      0.89        25\n'
         '           1       0.87      0.93      0.90        28\n'
         '           2       0.92      1.00      0.96        12\n'
         '\n'
         '    accuracy                           0.91        65\n'
         '   macro avg       0.91      0.92      0.92        65\n'
         'weighted avg       0.91      0.91      0.91        65\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.97      1.00      0.99        33\n'
          '           1       1.00      0.95      0.98        43\n'
          '           2       0.97      1.00      0.99        36\n'
          '\n'
          '    accuracy                           0.98       112\n'
          '   macro avg       0.98      0.98      0.98       112\n'
          'weighted avg       0.98      0.98      0.98       112\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
96
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.97      0.98        31\n'
         '           1       0.97      0.94      0.95        32\n'
         '           2       0.90      1.00      0.95        18\n'
         '\n'
         '    accuracy                           0.96        81\n'
         '   macro avg       0.96      0.97      0.96        81\n'
         'weighted avg       0.97      0.96      0.96        81\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.96      0.98        27\n'
          '           1       0.95      1.00      0.97        39\n'
          '           2       1.00      0.97      0.98        30\n'
          '\n'
          '    accuracy                           0.98        96\n'
          '   macro avg       0.98      0.98      0.98        96\n'
          'weighted avg       0.98      0.98      0.98        96\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
139
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.88      0.70      0.78        10\n'
         '           1       0.88      0.79      0.83        19\n'
         '           2       0.54      0.78      0.64         9\n'
         '\n'
         '    accuracy                           0.76        38\n'
         '   macro avg       0.77      0.76      0.75        38\n'
         'weighted avg       0.80      0.76      0.77        38\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        48\n'
          '           1       0.96      1.00      0.98        52\n'
          '           2       1.00      0.95      0.97        39\n'
          '\n'
          '    accuracy                           0.99       139\n'
          '   macro avg       0.99      0.98      0.98       139\n'
          'weighted avg       0.99      0.99      0.99       139\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
132
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      1.00      1.00        14\n'
         '           1       1.00      1.00      1.00        15\n'
         '           2       1.00      1.00      1.00        16\n'
         '\n'
         '    accuracy                           1.00        45\n'
         '   macro avg       1.00      1.00      1.00        45\n'
         'weighted avg       1.00      1.00      1.00        45\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      0.95      0.98        44\n'
          '           1       0.96      0.98      0.97        56\n'
          '           2       0.97      1.00      0.98        32\n'
          '\n'
          '    accuracy                           0.98       132\n'
          '   macro avg       0.98      0.98      0.98       132\n'
          'weighted avg       0.98      0.98      0.98       132\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
132
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.73      0.89      0.80         9\n'
         '           1       0.83      0.83      0.83        18\n'
         '           2       0.81      0.72      0.76        18\n'
         '\n'
         '    accuracy                           0.80        45\n'
         '   macro avg       0.79      0.81      0.80        45\n'
         'weighted avg       0.80      0.80      0.80        45\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        49\n'
          '           1       1.00      1.00      1.00        53\n'
          '           2       1.00      1.00      1.00        30\n'
          '\n'
          '    accuracy                           1.00       132\n'
          '   macro avg       1.00      1.00      1.00       132\n'
          'weighted avg       1.00      1.00      1.00       132\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
114
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       0.95      0.86      0.90        22\n'
         '           1       0.79      0.90      0.84        21\n'
         '           2       0.95      0.90      0.92        20\n'
         '\n'
         '    accuracy                           0.89        63\n'
         '   macro avg       0.90      0.89      0.89        63\n'
         'weighted avg       0.90      0.89      0.89        63\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       1.00      1.00      1.00        36\n'
          '           1       1.00      1.00      1.00        50\n'
          '           2       1.00      1.00      1.00        28\n'
          '\n'
          '    accuracy                           1.00       114\n'
          '   macro avg       1.00      1.00      1.00       114\n'
          'weighted avg       1.00      1.00      1.00       114\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wine', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='test_split')
129
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '           0       1.00      0.92      0.96        13\n'
         '           1       0.94      0.89      0.91        18\n'
         '           2       0.89      1.00      0.94        17\n'
         '\n'
         '    accuracy                           0.94        48\n'
         '   macro avg       0.95      0.94      0.94        48\n'
         'weighted avg       0.94      0.94      0.94        48\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '           0       0.98      1.00      0.99        45\n'
          '           1       1.00      0.94      0.97        53\n'
          '           2       0.94      1.00      0.97        31\n'
          '\n'
          '    accuracy                           0.98       129\n'
          '   macro avg       0.97      0.98      0.98       129\n'
          'weighted avg       0.98      0.98      0.98       129\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.12      1.00      0.21        18\n'
         '         1.0       1.00      0.72      0.84       489\n'
         '\n'
         '    accuracy                           0.73       507\n'
         '   macro avg       0.56      0.86      0.52       507\n'
         'weighted avg       0.97      0.73      0.81       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      0.99       490\n'
          '         1.0       1.00      0.63      0.77        19\n'
          '\n'
          '    accuracy                           0.99       509\n'
          '   macro avg       0.99      0.82      0.88       509\n'
          'weighted avg       0.99      0.99      0.98       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
695
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.03      1.00      0.06         4\n'
         '         1.0       1.00      0.59      0.74       317\n'
         '\n'
         '    accuracy                           0.60       321\n'
         '   macro avg       0.52      0.80      0.40       321\n'
         'weighted avg       0.99      0.60      0.74       321\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       504\n'
          '         1.0       1.00      1.00      1.00       191\n'
          '\n'
          '    accuracy                           1.00       695\n'
          '   macro avg       1.00      1.00      1.00       695\n'
          'weighted avg       1.00      1.00      1.00       695\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
852
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       151\n'
         '         1.0       1.00      1.00      1.00        13\n'
         '\n'
         '    accuracy                           1.00       164\n'
         '   macro avg       1.00      1.00      1.00       164\n'
         'weighted avg       1.00      1.00      1.00       164\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.99      0.99       357\n'
          '         1.0       0.99      1.00      0.99       495\n'
          '\n'
          '    accuracy                           0.99       852\n'
          '   macro avg       0.99      0.99      0.99       852\n'
          'weighted avg       0.99      0.99      0.99       852\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
695
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.69      0.82       317\n'
         '         1.0       0.04      1.00      0.08         4\n'
         '\n'
         '    accuracy                           0.69       321\n'
         '   macro avg       0.52      0.85      0.45       321\n'
         'weighted avg       0.99      0.69      0.81       321\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       191\n'
          '         1.0       1.00      1.00      1.00       504\n'
          '\n'
          '    accuracy                           1.00       695\n'
          '   macro avg       1.00      1.00      1.00       695\n'
          'weighted avg       1.00      1.00      1.00       695\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        18\n'
         '         1.0       1.00      1.00      1.00       489\n'
         '\n'
         '    accuracy                           1.00       507\n'
         '   macro avg       1.00      1.00      1.00       507\n'
         'weighted avg       1.00      1.00      1.00       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       490\n'
          '         1.0       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00       509\n'
          '   macro avg       1.00      1.00      1.00       509\n'
          'weighted avg       1.00      1.00      1.00       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00       490\n'
         '         1.0       0.04      1.00      0.07        19\n'
         '\n'
         '    accuracy                           0.04       509\n'
         '   macro avg       0.02      0.50      0.04       509\n'
         'weighted avg       0.00      0.04      0.00       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.00      0.00      0.00        18\n'
          '         1.0       0.96      1.00      0.98       489\n'
          '\n'
          '    accuracy                           0.96       507\n'
          '   macro avg       0.48      0.50      0.49       507\n'
          'weighted avg       0.93      0.96      0.95       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.12      1.00      0.21        18\n'
         '         1.0       1.00      0.72      0.84       489\n'
         '\n'
         '    accuracy                           0.73       507\n'
         '   macro avg       0.56      0.86      0.52       507\n'
         'weighted avg       0.97      0.73      0.81       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      0.99       490\n'
          '         1.0       1.00      0.63      0.77        19\n'
          '\n'
          '    accuracy                           0.99       509\n'
          '   macro avg       0.99      0.82      0.88       509\n'
          'weighted avg       0.99      0.99      0.98       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.05      1.00      0.09        18\n'
         '         1.0       1.00      0.23      0.38       489\n'
         '\n'
         '    accuracy                           0.26       507\n'
         '   macro avg       0.52      0.62      0.23       507\n'
         'weighted avg       0.97      0.26      0.37       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       490\n'
          '         1.0       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00       509\n'
          '   macro avg       1.00      1.00      1.00       509\n'
          'weighted avg       1.00      1.00      1.00       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
695
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.04      1.00      0.07         4\n'
         '         1.0       1.00      0.65      0.79       317\n'
         '\n'
         '    accuracy                           0.66       321\n'
         '   macro avg       0.52      0.83      0.43       321\n'
         'weighted avg       0.99      0.66      0.78       321\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      1.00       504\n'
          '         1.0       1.00      0.97      0.99       191\n'
          '\n'
          '    accuracy                           0.99       695\n'
          '   macro avg       1.00      0.99      0.99       695\n'
          'weighted avg       0.99      0.99      0.99       695\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
826
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        95\n'
         '         1.0       1.00      1.00      1.00        95\n'
         '\n'
         '    accuracy                           1.00       190\n'
         '   macro avg       1.00      1.00      1.00       190\n'
         'weighted avg       1.00      1.00      1.00       190\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       413\n'
          '         1.0       1.00      1.00      1.00       413\n'
          '\n'
          '    accuracy                           1.00       826\n'
          '   macro avg       1.00      1.00      1.00       826\n'
          'weighted avg       1.00      1.00      1.00       826\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
817
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       185\n'
         '         1.0       1.00      1.00      1.00        14\n'
         '\n'
         '    accuracy                           1.00       199\n'
         '   macro avg       1.00      1.00      1.00       199\n'
         'weighted avg       1.00      1.00      1.00       199\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       323\n'
          '         1.0       1.00      1.00      1.00       494\n'
          '\n'
          '    accuracy                           1.00       817\n'
          '   macro avg       1.00      1.00      1.00       817\n'
          'weighted avg       1.00      1.00      1.00       817\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00       490\n'
         '         1.0       0.04      1.00      0.07        19\n'
         '\n'
         '    accuracy                           0.04       509\n'
         '   macro avg       0.02      0.50      0.04       509\n'
         'weighted avg       0.00      0.04      0.00       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.00      0.00      0.00        18\n'
          '         1.0       0.96      1.00      0.98       489\n'
          '\n'
          '    accuracy                           0.96       507\n'
          '   macro avg       0.48      0.50      0.49       507\n'
          'weighted avg       0.93      0.96      0.95       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
695
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.99      1.00       317\n'
         '         1.0       0.67      1.00      0.80         4\n'
         '\n'
         '    accuracy                           0.99       321\n'
         '   macro avg       0.83      1.00      0.90       321\n'
         'weighted avg       1.00      0.99      0.99       321\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       191\n'
          '         1.0       1.00      1.00      1.00       504\n'
          '\n'
          '    accuracy                           1.00       695\n'
          '   macro avg       1.00      1.00      1.00       695\n'
          'weighted avg       1.00      1.00      1.00       695\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.22      0.36       490\n'
         '         1.0       0.05      1.00      0.09        19\n'
         '\n'
         '    accuracy                           0.25       509\n'
         '   macro avg       0.52      0.61      0.22       509\n'
         'weighted avg       0.96      0.25      0.35       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        18\n'
          '         1.0       1.00      1.00      1.00       489\n'
          '\n'
          '    accuracy                           1.00       507\n'
          '   macro avg       1.00      1.00      1.00       507\n'
          'weighted avg       1.00      1.00      1.00       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.01      0.03       490\n'
         '         1.0       0.04      1.00      0.07        19\n'
         '\n'
         '    accuracy                           0.05       509\n'
         '   macro avg       0.52      0.51      0.05       509\n'
         'weighted avg       0.96      0.05      0.03       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.89      0.94        18\n'
          '         1.0       1.00      1.00      1.00       489\n'
          '\n'
          '    accuracy                           1.00       507\n'
          '   macro avg       1.00      0.94      0.97       507\n'
          'weighted avg       1.00      1.00      1.00       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.35      0.52       490\n'
         '         1.0       0.06      1.00      0.11        19\n'
         '\n'
         '    accuracy                           0.38       509\n'
         '   macro avg       0.53      0.68      0.31       509\n'
         'weighted avg       0.96      0.38      0.51       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        18\n'
          '         1.0       1.00      1.00      1.00       489\n'
          '\n'
          '    accuracy                           1.00       507\n'
          '   macro avg       1.00      1.00      1.00       507\n'
          'weighted avg       1.00      1.00      1.00       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
676
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        31\n'
         '         1.0       1.00      1.00      1.00       309\n'
         '\n'
         '    accuracy                           1.00       340\n'
         '   macro avg       1.00      1.00      1.00       340\n'
         'weighted avg       1.00      1.00      1.00       340\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       477\n'
          '         1.0       1.00      1.00      1.00       199\n'
          '\n'
          '    accuracy                           1.00       676\n'
          '   macro avg       1.00      1.00      1.00       676\n'
          'weighted avg       1.00      1.00      1.00       676\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.04      1.00      0.07        18\n'
         '         1.0       0.00      0.00      0.00       489\n'
         '\n'
         '    accuracy                           0.04       507\n'
         '   macro avg       0.02      0.50      0.03       507\n'
         'weighted avg       0.00      0.04      0.00       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.96      1.00      0.98       490\n'
          '         1.0       0.00      0.00      0.00        19\n'
          '\n'
          '    accuracy                           0.96       509\n'
          '   macro avg       0.48      0.50      0.49       509\n'
          'weighted avg       0.93      0.96      0.94       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
829
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.99      1.00       187\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.99       187\n'
         '   macro avg       0.50      0.50      0.50       187\n'
         'weighted avg       1.00      0.99      1.00       187\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.99      0.99       321\n'
          '         1.0       0.99      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       829\n'
          '   macro avg       1.00      0.99      0.99       829\n'
          'weighted avg       1.00      1.00      1.00       829\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
539
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.24      0.38       477\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.24       477\n'
         '   macro avg       0.50      0.12      0.19       477\n'
         'weighted avg       1.00      0.24      0.38       477\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        31\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       539\n'
          '   macro avg       1.00      1.00      1.00       539\n'
          'weighted avg       1.00      1.00      1.00       539\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.04      1.00      0.07        18\n'
         '         1.0       1.00      0.02      0.03       489\n'
         '\n'
         '    accuracy                           0.05       507\n'
         '   macro avg       0.52      0.51      0.05       507\n'
         'weighted avg       0.97      0.05      0.03       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      1.00       490\n'
          '         1.0       1.00      0.84      0.91        19\n'
          '\n'
          '    accuracy                           0.99       509\n'
          '   macro avg       1.00      0.92      0.96       509\n'
          'weighted avg       0.99      0.99      0.99       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
829
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.94      0.97       187\n'
         '\n'
         '    accuracy                           0.94       187\n'
         '   macro avg       0.50      0.47      0.48       187\n'
         'weighted avg       1.00      0.94      0.97       187\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       508\n'
          '         1.0       1.00      1.00      1.00       321\n'
          '\n'
          '    accuracy                           1.00       829\n'
          '   macro avg       1.00      1.00      1.00       829\n'
          'weighted avg       1.00      1.00      1.00       829\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
946
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        70\n'
         '\n'
         '    accuracy                           1.00        70\n'
         '   macro avg       1.00      1.00      1.00        70\n'
         'weighted avg       1.00      1.00      1.00        70\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       438\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       946\n'
          '   macro avg       1.00      1.00      1.00       946\n'
          'weighted avg       1.00      1.00      1.00       946\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
539
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00     477.0\n'
         '         1.0       0.00      0.00      0.00       0.0\n'
         '\n'
         '    accuracy                           0.00     477.0\n'
         '   macro avg       0.00      0.00      0.00     477.0\n'
         'weighted avg       0.00      0.00      0.00     477.0\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.00      0.00      0.00        31\n'
          '         1.0       0.94      1.00      0.97       508\n'
          '\n'
          '    accuracy                           0.94       539\n'
          '   macro avg       0.47      0.50      0.49       539\n'
          'weighted avg       0.89      0.94      0.91       539\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.12      1.00      0.21        18\n'
         '         1.0       1.00      0.72      0.84       489\n'
         '\n'
         '    accuracy                           0.73       507\n'
         '   macro avg       0.56      0.86      0.52       507\n'
         'weighted avg       0.97      0.73      0.81       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      0.99       490\n'
          '         1.0       1.00      0.63      0.77        19\n'
          '\n'
          '    accuracy                           0.99       509\n'
          '   macro avg       0.99      0.82      0.88       509\n'
          'weighted avg       0.99      0.99      0.98       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
817
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.67      0.80       199\n'
         '\n'
         '    accuracy                           0.67       199\n'
         '   macro avg       0.50      0.33      0.40       199\n'
         'weighted avg       1.00      0.67      0.80       199\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       508\n'
          '         1.0       1.00      1.00      1.00       309\n'
          '\n'
          '    accuracy                           1.00       817\n'
          '   macro avg       1.00      1.00      1.00       817\n'
          'weighted avg       1.00      1.00      1.00       817\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
938
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        78\n'
         '\n'
         '    accuracy                           1.00        78\n'
         '   macro avg       1.00      1.00      1.00        78\n'
         'weighted avg       1.00      1.00      1.00        78\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      0.98      0.98       430\n'
          '         1.0       0.98      0.99      0.99       508\n'
          '\n'
          '    accuracy                           0.98       938\n'
          '   macro avg       0.98      0.98      0.98       938\n'
          'weighted avg       0.98      0.98      0.98       938\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
852
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.68      1.00      0.81        13\n'
         '         1.0       1.00      0.96      0.98       151\n'
         '\n'
         '    accuracy                           0.96       164\n'
         '   macro avg       0.84      0.98      0.90       164\n'
         'weighted avg       0.97      0.96      0.97       164\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       495\n'
          '         1.0       1.00      1.00      1.00       357\n'
          '\n'
          '    accuracy                           1.00       852\n'
          '   macro avg       1.00      1.00      1.00       852\n'
          'weighted avg       1.00      1.00      1.00       852\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
899
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00       117\n'
         '\n'
         '    accuracy                           1.00       117\n'
         '   macro avg       1.00      1.00      1.00       117\n'
         'weighted avg       1.00      1.00      1.00       117\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       508\n'
          '         1.0       1.00      1.00      1.00       391\n'
          '\n'
          '    accuracy                           1.00       899\n'
          '   macro avg       1.00      1.00      1.00       899\n'
          'weighted avg       1.00      1.00      1.00       899\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00       490\n'
         '         1.0       0.04      1.00      0.07        19\n'
         '\n'
         '    accuracy                           0.04       509\n'
         '   macro avg       0.02      0.50      0.04       509\n'
         'weighted avg       0.00      0.04      0.00       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.00      0.00      0.00        18\n'
          '         1.0       0.96      1.00      0.98       489\n'
          '\n'
          '    accuracy                           0.96       507\n'
          '   macro avg       0.48      0.50      0.49       507\n'
          'weighted avg       0.93      0.96      0.95       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
829
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.99      1.00       187\n'
         '\n'
         '    accuracy                           0.99       187\n'
         '   macro avg       0.50      0.50      0.50       187\n'
         'weighted avg       1.00      0.99      1.00       187\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      1.00       508\n'
          '         1.0       1.00      0.99      0.99       321\n'
          '\n'
          '    accuracy                           1.00       829\n'
          '   macro avg       1.00      0.99      0.99       829\n'
          'weighted avg       1.00      1.00      1.00       829\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
829
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       187\n'
         '\n'
         '    accuracy                           1.00       187\n'
         '   macro avg       1.00      1.00      1.00       187\n'
         'weighted avg       1.00      1.00      1.00       187\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       321\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       829\n'
          '   macro avg       1.00      1.00      1.00       829\n'
          'weighted avg       1.00      1.00      1.00       829\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
676
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.77      0.87       309\n'
         '         1.0       0.30      1.00      0.47        31\n'
         '\n'
         '    accuracy                           0.79       340\n'
         '   macro avg       0.65      0.89      0.67       340\n'
         'weighted avg       0.94      0.79      0.83       340\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.97      0.99       199\n'
          '         1.0       0.99      1.00      0.99       477\n'
          '\n'
          '    accuracy                           0.99       676\n'
          '   macro avg       0.99      0.99      0.99       676\n'
          'weighted avg       0.99      0.99      0.99       676\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.35      0.52       490\n'
         '         1.0       0.06      1.00      0.11        19\n'
         '\n'
         '    accuracy                           0.38       509\n'
         '   macro avg       0.53      0.68      0.31       509\n'
         'weighted avg       0.96      0.38      0.51       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        18\n'
          '         1.0       1.00      1.00      1.00       489\n'
          '\n'
          '    accuracy                           1.00       507\n'
          '   macro avg       1.00      1.00      1.00       507\n'
          'weighted avg       1.00      1.00      1.00       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
884
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       132\n'
         '\n'
         '    accuracy                           1.00       132\n'
         '   macro avg       1.00      1.00      1.00       132\n'
         'weighted avg       1.00      1.00      1.00       132\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       376\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       884\n'
          '   macro avg       1.00      1.00      1.00       884\n'
          'weighted avg       1.00      1.00      1.00       884\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
876
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       140\n'
         '\n'
         '    accuracy                           1.00       140\n'
         '   macro avg       1.00      1.00      1.00       140\n'
         'weighted avg       1.00      1.00      1.00       140\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       368\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       876\n'
          '   macro avg       1.00      1.00      1.00       876\n'
          'weighted avg       1.00      1.00      1.00       876\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
829
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.99      1.00       187\n'
         '\n'
         '    accuracy                           0.99       187\n'
         '   macro avg       0.50      0.50      0.50       187\n'
         'weighted avg       1.00      0.99      1.00       187\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      1.00       508\n'
          '         1.0       1.00      0.99      0.99       321\n'
          '\n'
          '    accuracy                           1.00       829\n'
          '   macro avg       1.00      0.99      0.99       829\n'
          'weighted avg       1.00      1.00      1.00       829\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.22      0.36       490\n'
         '         1.0       0.05      1.00      0.09        19\n'
         '\n'
         '    accuracy                           0.25       509\n'
         '   macro avg       0.52      0.61      0.22       509\n'
         'weighted avg       0.96      0.25      0.35       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        18\n'
          '         1.0       1.00      1.00      1.00       489\n'
          '\n'
          '    accuracy                           1.00       507\n'
          '   macro avg       1.00      1.00      1.00       507\n'
          'weighted avg       1.00      1.00      1.00       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.04      1.00      0.07        18\n'
         '         1.0       1.00      0.02      0.03       489\n'
         '\n'
         '    accuracy                           0.05       507\n'
         '   macro avg       0.52      0.51      0.05       507\n'
         'weighted avg       0.97      0.05      0.03       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      1.00       490\n'
          '         1.0       1.00      0.84      0.91        19\n'
          '\n'
          '    accuracy                           0.99       509\n'
          '   macro avg       1.00      0.92      0.96       509\n'
          'weighted avg       0.99      0.99      0.99       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
695
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.69      0.82       317\n'
         '         1.0       0.04      1.00      0.08         4\n'
         '\n'
         '    accuracy                           0.69       321\n'
         '   macro avg       0.52      0.85      0.45       321\n'
         'weighted avg       0.99      0.69      0.81       321\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       191\n'
          '         1.0       1.00      1.00      1.00       504\n'
          '\n'
          '    accuracy                           1.00       695\n'
          '   macro avg       1.00      1.00      1.00       695\n'
          'weighted avg       1.00      1.00      1.00       695\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
743
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       269\n'
         '         1.0       1.00      1.00      1.00         4\n'
         '\n'
         '    accuracy                           1.00       273\n'
         '   macro avg       1.00      1.00      1.00       273\n'
         'weighted avg       1.00      1.00      1.00       273\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       239\n'
          '         1.0       1.00      1.00      1.00       504\n'
          '\n'
          '    accuracy                           1.00       743\n'
          '   macro avg       1.00      1.00      1.00       743\n'
          'weighted avg       1.00      1.00      1.00       743\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
829
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       187\n'
         '\n'
         '    accuracy                           1.00       187\n'
         '   macro avg       1.00      1.00      1.00       187\n'
         'weighted avg       1.00      1.00      1.00       187\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       321\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       829\n'
          '   macro avg       1.00      1.00      1.00       829\n'
          'weighted avg       1.00      1.00      1.00       829\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
917
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00        99\n'
         '\n'
         '    accuracy                           1.00        99\n'
         '   macro avg       1.00      1.00      1.00        99\n'
         'weighted avg       1.00      1.00      1.00        99\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       508\n'
          '         1.0       1.00      1.00      1.00       409\n'
          '\n'
          '    accuracy                           1.00       917\n'
          '   macro avg       1.00      1.00      1.00       917\n'
          'weighted avg       1.00      1.00      1.00       917\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
889
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00       127\n'
         '\n'
         '    accuracy                           1.00       127\n'
         '   macro avg       1.00      1.00      1.00       127\n'
         'weighted avg       1.00      1.00      1.00       127\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       508\n'
          '         1.0       1.00      1.00      1.00       381\n'
          '\n'
          '    accuracy                           1.00       889\n'
          '   macro avg       1.00      1.00      1.00       889\n'
          'weighted avg       1.00      1.00      1.00       889\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.04      1.00      0.07        18\n'
         '         1.0       1.00      0.02      0.03       489\n'
         '\n'
         '    accuracy                           0.05       507\n'
         '   macro avg       0.52      0.51      0.05       507\n'
         'weighted avg       0.97      0.05      0.03       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.99      1.00      1.00       490\n'
          '         1.0       1.00      0.84      0.91        19\n'
          '\n'
          '    accuracy                           0.99       509\n'
          '   macro avg       1.00      0.92      0.96       509\n'
          'weighted avg       0.99      0.99      0.99       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
867
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.94      1.00      0.97        15\n'
         '         1.0       1.00      0.99      1.00       134\n'
         '\n'
         '    accuracy                           0.99       149\n'
         '   macro avg       0.97      1.00      0.98       149\n'
         'weighted avg       0.99      0.99      0.99       149\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       493\n'
          '         1.0       1.00      1.00      1.00       374\n'
          '\n'
          '    accuracy                           1.00       867\n'
          '   macro avg       1.00      1.00      1.00       867\n'
          'weighted avg       1.00      1.00      1.00       867\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        18\n'
         '         1.0       1.00      1.00      1.00       489\n'
         '\n'
         '    accuracy                           1.00       507\n'
         '   macro avg       1.00      1.00      1.00       507\n'
         'weighted avg       1.00      1.00      1.00       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       490\n'
          '         1.0       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00       509\n'
          '   macro avg       1.00      1.00      1.00       509\n'
          'weighted avg       1.00      1.00      1.00       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00       490\n'
         '         1.0       0.04      1.00      0.07        19\n'
         '\n'
         '    accuracy                           0.04       509\n'
         '   macro avg       0.02      0.50      0.04       509\n'
         'weighted avg       0.00      0.04      0.00       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.00      0.00      0.00        18\n'
          '         1.0       0.96      1.00      0.98       489\n'
          '\n'
          '    accuracy                           0.96       507\n'
          '   macro avg       0.48      0.50      0.49       507\n'
          'weighted avg       0.93      0.96      0.95       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
817
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.00      0.00      0.00         0\n'
         '         1.0       1.00      0.93      0.96       199\n'
         '\n'
         '    accuracy                           0.93       199\n'
         '   macro avg       0.50      0.46      0.48       199\n'
         'weighted avg       1.00      0.93      0.96       199\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       508\n'
          '         1.0       0.99      1.00      1.00       309\n'
          '\n'
          '    accuracy                           1.00       817\n'
          '   macro avg       1.00      1.00      1.00       817\n'
          'weighted avg       1.00      1.00      1.00       817\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
860
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00       156\n'
         '\n'
         '    accuracy                           1.00       156\n'
         '   macro avg       1.00      1.00      1.00       156\n'
         'weighted avg       1.00      1.00      1.00       156\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       508\n'
          '         1.0       1.00      1.00      1.00       352\n'
          '\n'
          '    accuracy                           1.00       860\n'
          '   macro avg       1.00      1.00      1.00       860\n'
          'weighted avg       1.00      1.00      1.00       860\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
817
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.51      0.68       199\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.51       199\n'
         '   macro avg       0.50      0.26      0.34       199\n'
         'weighted avg       1.00      0.51      0.68       199\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.97      0.99      0.98       309\n'
          '         1.0       0.99      0.98      0.99       508\n'
          '\n'
          '    accuracy                           0.99       817\n'
          '   macro avg       0.98      0.99      0.99       817\n'
          'weighted avg       0.99      0.99      0.99       817\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
881
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       135\n'
         '\n'
         '    accuracy                           1.00       135\n'
         '   macro avg       1.00      1.00      1.00       135\n'
         'weighted avg       1.00      1.00      1.00       135\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       373\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       881\n'
          '   macro avg       1.00      1.00      1.00       881\n'
          'weighted avg       1.00      1.00      1.00       881\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        18\n'
         '         1.0       1.00      1.00      1.00       489\n'
         '\n'
         '    accuracy                           1.00       507\n'
         '   macro avg       1.00      1.00      1.00       507\n'
         'weighted avg       1.00      1.00      1.00       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       490\n'
          '         1.0       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00       509\n'
          '   macro avg       1.00      1.00      1.00       509\n'
          'weighted avg       1.00      1.00      1.00       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
826
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        95\n'
         '         1.0       1.00      1.00      1.00        95\n'
         '\n'
         '    accuracy                           1.00       190\n'
         '   macro avg       1.00      1.00      1.00       190\n'
         'weighted avg       1.00      1.00      1.00       190\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       413\n'
          '         1.0       1.00      1.00      1.00       413\n'
          '\n'
          '    accuracy                           1.00       826\n'
          '   macro avg       1.00      1.00      1.00       826\n'
          'weighted avg       1.00      1.00      1.00       826\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.68      0.81       490\n'
         '         1.0       0.11      1.00      0.19        19\n'
         '\n'
         '    accuracy                           0.69       509\n'
         '   macro avg       0.55      0.84      0.50       509\n'
         'weighted avg       0.97      0.69      0.79       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.61      0.76        18\n'
          '         1.0       0.99      1.00      0.99       489\n'
          '\n'
          '    accuracy                           0.99       507\n'
          '   macro avg       0.99      0.81      0.88       507\n'
          'weighted avg       0.99      0.99      0.98       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.05      1.00      0.09        18\n'
         '         1.0       1.00      0.23      0.38       489\n'
         '\n'
         '    accuracy                           0.26       507\n'
         '   macro avg       0.52      0.62      0.23       507\n'
         'weighted avg       0.97      0.26      0.37       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       490\n'
          '         1.0       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00       509\n'
          '   macro avg       1.00      1.00      1.00       509\n'
          'weighted avg       1.00      1.00      1.00       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
538
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.04      0.08       478\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.04       478\n'
         '   macro avg       0.50      0.02      0.04       478\n'
         'weighted avg       1.00      0.04      0.08       478\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.90      0.95        30\n'
          '         1.0       0.99      1.00      1.00       508\n'
          '\n'
          '    accuracy                           0.99       538\n'
          '   macro avg       1.00      0.95      0.97       538\n'
          'weighted avg       0.99      0.99      0.99       538\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
879
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.78      0.88       137\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.78       137\n'
         '   macro avg       0.50      0.39      0.44       137\n'
         'weighted avg       1.00      0.78      0.88       137\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       371\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       879\n'
          '   macro avg       1.00      1.00      1.00       879\n'
          'weighted avg       1.00      1.00      1.00       879\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
829
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00       187\n'
         '\n'
         '    accuracy                           1.00       187\n'
         '   macro avg       1.00      1.00      1.00       187\n'
         'weighted avg       1.00      1.00      1.00       187\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       508\n'
          '         1.0       1.00      1.00      1.00       321\n'
          '\n'
          '    accuracy                           1.00       829\n'
          '   macro avg       1.00      1.00      1.00       829\n'
          'weighted avg       1.00      1.00      1.00       829\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.04      1.00      0.07        18\n'
         '         1.0       0.00      0.00      0.00       489\n'
         '\n'
         '    accuracy                           0.04       507\n'
         '   macro avg       0.02      0.50      0.03       507\n'
         'weighted avg       0.00      0.04      0.00       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.96      1.00      0.98       490\n'
          '         1.0       0.00      0.00      0.00        19\n'
          '\n'
          '    accuracy                           0.96       509\n'
          '   macro avg       0.48      0.50      0.49       509\n'
          'weighted avg       0.93      0.96      0.94       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
743
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00         4\n'
         '         1.0       1.00      1.00      1.00       269\n'
         '\n'
         '    accuracy                           1.00       273\n'
         '   macro avg       1.00      1.00      1.00       273\n'
         'weighted avg       1.00      1.00      1.00       273\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       504\n'
          '         1.0       1.00      1.00      1.00       239\n'
          '\n'
          '    accuracy                           1.00       743\n'
          '   macro avg       1.00      1.00      1.00       743\n'
          'weighted avg       1.00      1.00      1.00       743\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.22      0.36       490\n'
         '         1.0       0.05      1.00      0.09        19\n'
         '\n'
         '    accuracy                           0.25       509\n'
         '   macro avg       0.52      0.61      0.22       509\n'
         'weighted avg       0.96      0.25      0.35       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        18\n'
          '         1.0       1.00      1.00      1.00       489\n'
          '\n'
          '    accuracy                           1.00       507\n'
          '   macro avg       1.00      1.00      1.00       507\n'
          'weighted avg       1.00      1.00      1.00       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
891
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         1.0       1.00      1.00      1.00       125\n'
         '\n'
         '    accuracy                           1.00       125\n'
         '   macro avg       1.00      1.00      1.00       125\n'
         'weighted avg       1.00      1.00      1.00       125\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.99      1.00       508\n'
          '         1.0       0.99      1.00      0.99       383\n'
          '\n'
          '    accuracy                           0.99       891\n'
          '   macro avg       0.99      0.99      0.99       891\n'
          'weighted avg       0.99      0.99      0.99       891\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
507
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.35      0.52       490\n'
         '         1.0       0.06      1.00      0.11        19\n'
         '\n'
         '    accuracy                           0.38       509\n'
         '   macro avg       0.53      0.68      0.31       509\n'
         'weighted avg       0.96      0.38      0.51       509\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        18\n'
          '         1.0       1.00      1.00      1.00       489\n'
          '\n'
          '    accuracy                           1.00       507\n'
          '   macro avg       1.00      1.00      1.00       507\n'
          'weighted avg       1.00      1.00      1.00       507\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
539
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00       477\n'
         '\n'
         '    accuracy                           1.00       477\n'
         '   macro avg       1.00      1.00      1.00       477\n'
         'weighted avg       1.00      1.00      1.00       477\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00        31\n'
          '         1.0       1.00      1.00      1.00       508\n'
          '\n'
          '    accuracy                           1.00       539\n'
          '   macro avg       1.00      1.00      1.00       539\n'
          'weighted avg       1.00      1.00      1.00       539\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
676
{'cls': 'xgboost',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.10      1.00      0.18        31\n'
         '         1.0       1.00      0.11      0.20       309\n'
         '\n'
         '    accuracy                           0.19       340\n'
         '   macro avg       0.55      0.56      0.19       340\n'
         'weighted avg       0.92      0.19      0.20       340\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       477\n'
          '         1.0       1.00      0.99      0.99       199\n'
          '\n'
          '    accuracy                           1.00       676\n'
          '   macro avg       1.00      0.99      1.00       676\n'
          'weighted avg       1.00      1.00      1.00       676\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='lg', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
539
{'cls': 'lg',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.72      0.84       477\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.72       477\n'
         '   macro avg       0.50      0.36      0.42       477\n'
         'weighted avg       1.00      0.72      0.84       477\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      0.84      0.91        31\n'
          '         1.0       0.99      1.00      1.00       508\n'
          '\n'
          '    accuracy                           0.99       539\n'
          '   macro avg       1.00      0.92      0.95       539\n'
          'weighted avg       0.99      0.99      0.99       539\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='svm', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'svm',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       0.05      1.00      0.09        18\n'
         '         1.0       1.00      0.23      0.38       489\n'
         '\n'
         '    accuracy                           0.26       507\n'
         '   macro avg       0.52      0.62      0.23       507\n'
         'weighted avg       0.97      0.26      0.37       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       490\n'
          '         1.0       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00       509\n'
          '   macro avg       1.00      1.00      1.00       509\n'
          'weighted avg       1.00      1.00      1.00       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='nb', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
884
{'cls': 'nb',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.95      0.98       132\n'
         '         1.0       0.00      0.00      0.00         0\n'
         '\n'
         '    accuracy                           0.95       132\n'
         '   macro avg       0.50      0.48      0.49       132\n'
         'weighted avg       1.00      0.95      0.98       132\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       0.98      0.95      0.96       376\n'
          '         1.0       0.96      0.98      0.97       508\n'
          '\n'
          '    accuracy                           0.97       884\n'
          '   macro avg       0.97      0.97      0.97       884\n'
          'weighted avg       0.97      0.97      0.97       884\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='knn', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
745
{'cls': 'knn',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      0.96      0.98       265\n'
         '         1.0       0.35      1.00      0.52         6\n'
         '\n'
         '    accuracy                           0.96       271\n'
         '   macro avg       0.68      0.98      0.75       271\n'
         'weighted avg       0.99      0.96      0.97       271\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       243\n'
          '         1.0       1.00      1.00      1.00       502\n'
          '\n'
          '    accuracy                           1.00       745\n'
          '   macro avg       1.00      1.00      1.00       745\n'
          'weighted avg       1.00      1.00      1.00       745\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='dt', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
509
{'cls': 'dt',
 'test': '              precision    recall  f1-score   support\n'
         '\n'
         '         0.0       1.00      1.00      1.00        18\n'
         '         1.0       1.00      1.00      1.00       489\n'
         '\n'
         '    accuracy                           1.00       507\n'
         '   macro avg       1.00      1.00      1.00       507\n'
         'weighted avg       1.00      1.00      1.00       507\n',
 'train': '              precision    recall  f1-score   support\n'
          '\n'
          '         0.0       1.00      1.00      1.00       490\n'
          '         1.0       1.00      1.00      1.00        19\n'
          '\n'
          '    accuracy                           1.00       509\n'
          '   macro avg       1.00      1.00      1.00       509\n'
          'weighted avg       1.00      1.00      1.00       509\n'}
Python 3.5.2 (default, Oct  8 2019, 13:06:37) 
[GCC 5.4.0 20160609] on linux
Namespace(classifier='xgboost', data_type='Continuous', file1='wing_nut', file2='', log_name='classifier', proportiontocut=0.01, read=False, stats_type1='brightness', stats_type2='brightness', test_type='two_sample_t_test', type='cluster_removal')
826
